{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "M-FIAqfPCx3w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "# Load the ResNet-18 model pretrained on ImageNet\n",
        "resnet18 = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQG-_v1XKFwS",
        "outputId": "f6b3a5f5-0cac-4719-c4e5-55c4fda48a5a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQ8gfIW9018",
        "outputId": "9238a4c4-1b98-4051-d6af-6816b381db3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set size: 50000\n",
            "Validation set size: 10000\n",
            "CIFAR-10 classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "# Load in dataset: CIFAR-10\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "train_transforms = [\n",
        "    transforms.RandomCrop(32, padding=4),  # Data Augmentation: Random crop with padding\n",
        "    transforms.RandomHorizontalFlip(),    # Data Augmentation: Random horizontal flip\n",
        "    transforms.ToTensor(),                # Convert PIL.Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "]\n",
        "\n",
        "val_transforms = [\n",
        "    transforms.ToTensor(),                # Convert PIL.Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "]\n",
        "\n",
        "def get_datasets(train_transforms=(), val_transforms=()):\n",
        "    r\"\"\"\n",
        "    Returns the CIFAR-10 training and validation datasets with corresponding\n",
        "    transforms.\n",
        "\n",
        "    `*_transforms` represent optional transformations, e.g., conversion to\n",
        "    PyTorch tensors, preprocessing, etc.\n",
        "    \"\"\"\n",
        "    train_set = torchvision.datasets.CIFAR10(\n",
        "        './data', train=True, download=True,\n",
        "        transform=torchvision.transforms.Compose(train_transforms))\n",
        "    val_set = torchvision.datasets.CIFAR10(\n",
        "        './data', train=False, download=True,\n",
        "        transform=torchvision.transforms.Compose(val_transforms))\n",
        "    return train_set, val_set\n",
        "\n",
        "train_set, val_set = get_datasets(train_transforms, val_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=False, num_workers=4)\n",
        "\n",
        "print(f\"Training set size: {len(train_set)}\")\n",
        "print(f\"Validation set size: {len(val_set)}\")\n",
        "\n",
        "class_names = train_set.classes\n",
        "\n",
        "print(f'CIFAR-10 classes: {class_names}')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = '/content/drive/MyDrive/MIT/6.7960 Deep Learning/models/resnet18_basic_trained.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihCmpyNmDBmH",
        "outputId": "e2b546a4-a142-4789-bb6e-034b94a8e9ff"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DDPs4oqDJACn",
        "outputId": "b4da3d7f-f7b9-432a-d000-b79da08fb54a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:9ug6vp8k) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-half-frozen-training</strong> at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/9ug6vp8k' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/9ug6vp8k</a><br/> View project at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241209_225301-9ug6vp8k/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:9ug6vp8k). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_233929-73x61otb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/73x61otb' target=\"_blank\">resnet18-basic-training</a></strong> to <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/73x61otb' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/73x61otb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1.0572, Accuracy = 63.45%\n",
            "Validation Loss = 0.7645, Accuracy = 73.48%\n",
            "Model Saved!\n",
            "Epoch 2: Loss = 0.7068, Accuracy = 75.76%\n",
            "Validation Loss = 0.6469, Accuracy = 77.83%\n",
            "Model Saved!\n",
            "Epoch 3: Loss = 0.6228, Accuracy = 78.61%\n",
            "Validation Loss = 0.6290, Accuracy = 78.82%\n",
            "Model Saved!\n",
            "Epoch 4: Loss = 0.5659, Accuracy = 80.45%\n",
            "Validation Loss = 0.5738, Accuracy = 80.39%\n",
            "Model Saved!\n",
            "Epoch 5: Loss = 0.5314, Accuracy = 81.54%\n",
            "Validation Loss = 0.7124, Accuracy = 77.50%\n",
            "Epoch 6: Loss = 0.4954, Accuracy = 82.75%\n",
            "Validation Loss = 0.5308, Accuracy = 82.51%\n",
            "Model Saved!\n",
            "Epoch 7: Loss = 0.4792, Accuracy = 83.24%\n",
            "Validation Loss = 0.6052, Accuracy = 79.86%\n",
            "Epoch 8: Loss = 0.4493, Accuracy = 84.50%\n",
            "Validation Loss = 0.5158, Accuracy = 83.26%\n",
            "Model Saved!\n",
            "Epoch 9: Loss = 0.4354, Accuracy = 84.86%\n",
            "Validation Loss = 0.4930, Accuracy = 83.28%\n",
            "Model Saved!\n",
            "Epoch 10: Loss = 0.4218, Accuracy = 85.33%\n",
            "Validation Loss = 0.5217, Accuracy = 82.61%\n",
            "Epoch 11: Loss = 0.4017, Accuracy = 86.09%\n",
            "Validation Loss = 0.5054, Accuracy = 83.26%\n",
            "Epoch 12: Loss = 0.3906, Accuracy = 86.46%\n",
            "Validation Loss = 0.4841, Accuracy = 84.05%\n",
            "Model Saved!\n",
            "Epoch 13: Loss = 0.3803, Accuracy = 86.63%\n",
            "Validation Loss = 0.5456, Accuracy = 82.10%\n",
            "Epoch 14: Loss = 0.3759, Accuracy = 86.77%\n",
            "Validation Loss = 0.4915, Accuracy = 83.94%\n",
            "Epoch 15: Loss = 0.3656, Accuracy = 87.11%\n",
            "Validation Loss = 0.4906, Accuracy = 83.85%\n",
            "Epoch 16: Loss = 0.3494, Accuracy = 87.62%\n",
            "Validation Loss = 0.5367, Accuracy = 82.50%\n",
            "Epoch 17: Loss = 0.3471, Accuracy = 87.71%\n",
            "Validation Loss = 0.4794, Accuracy = 83.78%\n",
            "Epoch 18: Loss = 0.3379, Accuracy = 88.23%\n",
            "Validation Loss = 0.4810, Accuracy = 84.45%\n",
            "Model Saved!\n",
            "Epoch 19: Loss = 0.3293, Accuracy = 88.23%\n",
            "Validation Loss = 0.5806, Accuracy = 81.98%\n",
            "Epoch 20: Loss = 0.3240, Accuracy = 88.67%\n",
            "Validation Loss = 0.5289, Accuracy = 82.69%\n",
            "Best Validation Accuracy: 84.45%\n",
            "<wandb.sdk.data_types.table.Table object at 0x7d1f572fe5c0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▄▅▄▇▅▇▇▇▇█▇██▇██▆▇</td></tr><tr><td>val_loss</td><td>█▅▅▃▇▂▄▂▁▂▂▁▃▁▁▂▁▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>84.45</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>train_accuracy</td><td>88.67</td></tr><tr><td>train_loss</td><td>0.32405</td></tr><tr><td>val_accuracy</td><td>82.69</td></tr><tr><td>val_loss</td><td>0.5289</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-basic-training</strong> at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/73x61otb' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/73x61otb</a><br/> View project at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241209_233929-73x61otb/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Modify the Fully Connected Layer for CIFAR-10 (10 classes)\n",
        "num_classes = 10\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
        "\n",
        "# Move Model to Device\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Set up a Wandb instance\n",
        "wandb.init(project=\"layer-freezing-adversarial-training\", name=\"resnet18-basic-training\")\n",
        "table = wandb.Table(columns=[\"epoch\", \"train_loss\", \"val_loss\", \"train_accuracy\", \"val_accuracy\"])\n",
        "\n",
        "# Training Function\n",
        "def train(model, loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    loss = running_loss / len(loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f\"Epoch {epoch}: Loss = {loss:.4f}, \"\n",
        "          f\"Accuracy = {accuracy:.2f}%\")\n",
        "    return loss, accuracy\n",
        "\n",
        "# Validation Function\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    loss = running_loss / len(loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f\"Validation Loss = {loss:.4f}, \"\n",
        "          f\"Accuracy = {accuracy:.2f}%\")\n",
        "    return loss, accuracy\n",
        "\n",
        "# Training Loop: takes about 9 minutes with 20 epochs\n",
        "num_epochs = 20\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_accuracy = train(resnet18, train_loader, criterion, optimizer, epoch)\n",
        "    val_loss, val_accuracy = evaluate(resnet18, val_loader, criterion)\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        torch.save(resnet18, model_path)\n",
        "        print(\"Model Saved!\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_accuracy\": val_accuracy\n",
        "    })\n",
        "    table.add_data(epoch, train_loss, val_loss, train_accuracy, val_accuracy)\n",
        "\n",
        "print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")\n",
        "wandb.log({\"best_accuracy\": best_accuracy})\n",
        "wandb.log({\"metrics_table\": table})\n",
        "print(table)\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6IQNl8Vt13F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffd9bd9-5f3a-4263-d823-fef879cd0177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.20.1+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.66.6)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.26.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchattacks\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Methods for Training and Validating with an Adversarial Training scheme; Consistent across all experiments\n",
        "\n",
        "# Number of Batches: 391\n",
        "\n",
        "# Training function with adversarial examples\n",
        "def adversarial_train(epoch, model):\n",
        "    print(f'\\n[ Train epoch: {epoch} ]')\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_inputs = adversary(inputs, targets)\n",
        "\n",
        "        # Forward pass on adversarial examples\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(adv_inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Batch {batch_idx}: Loss = {loss.item():.4f}, Accuracy = {100. * correct / total:.2f}%')\n",
        "\n",
        "    total_loss = train_loss / len(train_loader)\n",
        "    total_accuracy = 100. * correct / total\n",
        "    print(f'Epoch {epoch}: Total Loss = {total_loss:.4f}, Total Accuracy = {total_accuracy:.2f}%')\n",
        "    return total_loss, total_accuracy\n",
        "\n",
        "# Testing function for adversarial and clean examples\n",
        "def adversarial_test(epoch, model):\n",
        "    print(f'\\n[ Test epoch: {epoch} ]')\n",
        "    model.eval()\n",
        "    benign_loss = 0.0\n",
        "    adv_loss = 0.0\n",
        "    benign_correct = 0\n",
        "    adv_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "        with torch.no_grad():\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            total += targets.size(0)\n",
        "\n",
        "            # Test on benign examples\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            benign_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            benign_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        adv_inputs = inputs.clone().detach().requires_grad_(True)\n",
        "        adv_inputs = adversary(adv_inputs, targets)\n",
        "        with torch.no_grad():\n",
        "            # Test on adversarial examples\n",
        "            adv_outputs = model(adv_inputs)\n",
        "            loss = criterion(adv_outputs, targets)\n",
        "            adv_loss += loss.item()\n",
        "            _, predicted = adv_outputs.max(1)\n",
        "            adv_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Batch {batch_idx}: Benign Loss = {loss.item():.4f}, Adversarial Loss = {loss.item():.4f}')\n",
        "\n",
        "    benign_accuracy = 100. * benign_correct / total\n",
        "    adv_accuracy = 100. * adv_correct / total\n",
        "    benign_loss = benign_loss / len(val_loader)\n",
        "    adv_loss = adv_loss / len(val_loader)\n",
        "    print(f'Epoch {epoch}: Benign Accuracy = {benign_accuracy:.2f}%, Adversarial Accuracy = {adv_accuracy:.2f}%')\n",
        "    print(f'Benign Loss = {benign_loss:.4f}, Adversarial Loss = {adv_loss:.4f}')\n",
        "    return benign_accuracy, adv_accuracy, benign_loss, adv_loss\n"
      ],
      "metadata": {
        "id": "Y4ghjxzRRx1R"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Methods for Evaluating Benign and Adversarial Accuracy after Training\n",
        "\n",
        "def evaluate(model):\n",
        "    # Initialize PGD attack\n",
        "    attack = torchattacks.PGD(model, eps=0.03, alpha=0.01, steps=40)\n",
        "\n",
        "    # Generate adversarial examples\n",
        "    # Get one batch of test data\n",
        "    inputs, labels = next(iter(val_loader))\n",
        "\n",
        "    # Move to the same device as the model (e.g., GPU if available)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        benign_outputs = model(inputs)  # Forward pass on clean inputs\n",
        "        _, benign_predicted = benign_outputs.max(1)  # Get predictions\n",
        "        benign_accuracy = (benign_predicted == labels).float().mean().item() * 100\n",
        "        print(f\"Benign Accuracy: {benign_accuracy:.2f}%\")\n",
        "\n",
        "    adv_inputs = attack(inputs, labels)\n",
        "\n",
        "    # Evaluate the model on adversarial examples\n",
        "    with torch.no_grad():\n",
        "      outputs = model(adv_inputs)\n",
        "      _, predicted = outputs.max(1)\n",
        "      adv_accuracy = (predicted == labels).float().mean().item() * 100\n",
        "      print(f\"Adversarial Accuracy: {adv_accuracy:.2f}%\")\n",
        "\n",
        "    return benign_accuracy, adv_accuracy"
      ],
      "metadata": {
        "id": "4NujPyUPWi4t"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT 1: CONTROL\n",
        "\n",
        "wandb.init(project=\"layer-freezing-adversarial-training\", name=\"resnet18-control-training\")\n",
        "table = wandb.Table(columns=[\"epoch\", \"train_adv_accuracy\", \"train_adv_loss\", \"test_benign_accuracy\", \"test_adv_accuracy\", \"test_benign_loss\", \"test_adv_loss\"])\n",
        "\n",
        "# Model and device setup\n",
        "resnet18_control = torch.load(model_path)\n",
        "\n",
        "# Reinitialize to ensure no conflicts when model reloaded in\n",
        "for param in resnet18_control.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet18_control = resnet18_control.to(device)\n",
        "resnet18_control = torch.nn.DataParallel(resnet18_control)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# Define adversary (PGD Attack)\n",
        "adversary = PGD(resnet18_control, eps=0.03, alpha=0.01, steps=40)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18_control.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Adjust learning rate\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.01\n",
        "    if epoch >= 30:\n",
        "        lr /= 10\n",
        "    if epoch >= 40:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Training and testing loop\n",
        "start_time = time.time()\n",
        "for epoch in range(0, 25):  # Train for 25 epochs- 2 epochs takes around 8 minutes\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_adv_accuracy, train_adv_loss = adversarial_train(epoch, resnet18_control) # trained on adversarial examples\n",
        "    test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss = adversarial_test(epoch, resnet18_control)\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_adv_accuracy\": train_adv_accuracy,\n",
        "        \"train_adv_loss\": train_adv_loss,\n",
        "        \"test_benign_accuracy\": test_benign_accuracy,\n",
        "        \"test_adv_accuracy\": test_adv_accuracy,\n",
        "        \"test_benign_loss\": test_benign_loss,\n",
        "        \"test_adv_loss\": test_adv_loss\n",
        "    })\n",
        "    table.add_data(epoch, train_adv_accuracy, train_adv_loss, test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Training complete in {end_time - start_time:.2f} seconds')\n",
        "\n",
        "model_control_path = '/content/drive/MyDrive/MIT/6.7960 Deep Learning/models/resnet18_control_trained.pt'\n",
        "torch.save(resnet18_control, model_control_path)\n",
        "\n",
        "wandb.log({\"metrics_table\": table})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Zznrdc_5ryc",
        "outputId": "be1443ef-457a-433c-bd8c-89f855a2b25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_194746-y1v1rtod</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/y1v1rtod' target=\"_blank\">resnet18-control-training</a></strong> to <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/y1v1rtod' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/y1v1rtod</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-b7af7cb2a7e9>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet18_control = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n",
            "Batch 0: Loss = 1.7801, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.8482, Accuracy = 48.58%\n",
            "Batch 20: Loss = 1.7701, Accuracy = 45.16%\n",
            "Batch 30: Loss = 1.5640, Accuracy = 44.88%\n",
            "Batch 40: Loss = 1.4490, Accuracy = 45.05%\n",
            "Batch 50: Loss = 1.4562, Accuracy = 45.28%\n",
            "Batch 60: Loss = 1.5080, Accuracy = 45.39%\n",
            "Batch 70: Loss = 1.4968, Accuracy = 45.88%\n",
            "Batch 80: Loss = 1.3792, Accuracy = 46.06%\n",
            "Batch 90: Loss = 1.3446, Accuracy = 46.69%\n",
            "Batch 100: Loss = 1.3725, Accuracy = 47.01%\n",
            "Batch 110: Loss = 1.1665, Accuracy = 47.59%\n",
            "Batch 120: Loss = 1.3161, Accuracy = 47.82%\n",
            "Batch 130: Loss = 1.2760, Accuracy = 48.14%\n",
            "Batch 140: Loss = 1.2977, Accuracy = 48.37%\n",
            "Batch 150: Loss = 1.1884, Accuracy = 48.72%\n",
            "Batch 160: Loss = 1.1451, Accuracy = 48.87%\n",
            "Batch 170: Loss = 1.3081, Accuracy = 49.29%\n",
            "Batch 180: Loss = 1.2475, Accuracy = 49.77%\n",
            "Batch 190: Loss = 1.2184, Accuracy = 49.87%\n",
            "Batch 200: Loss = 1.2804, Accuracy = 50.09%\n",
            "Batch 210: Loss = 1.1352, Accuracy = 50.27%\n",
            "Batch 220: Loss = 1.2397, Accuracy = 50.41%\n",
            "Batch 230: Loss = 1.1310, Accuracy = 50.51%\n",
            "Batch 240: Loss = 1.2154, Accuracy = 50.62%\n",
            "Batch 250: Loss = 1.1880, Accuracy = 50.78%\n",
            "Batch 260: Loss = 1.2742, Accuracy = 50.99%\n",
            "Batch 270: Loss = 1.3470, Accuracy = 51.12%\n",
            "Batch 280: Loss = 1.2266, Accuracy = 51.36%\n",
            "Batch 290: Loss = 1.2555, Accuracy = 51.50%\n",
            "Batch 300: Loss = 1.1969, Accuracy = 51.70%\n",
            "Batch 310: Loss = 1.3113, Accuracy = 51.77%\n",
            "Batch 320: Loss = 1.1777, Accuracy = 51.86%\n",
            "Batch 330: Loss = 1.2014, Accuracy = 51.94%\n",
            "Batch 340: Loss = 1.1037, Accuracy = 52.08%\n",
            "Batch 350: Loss = 1.1999, Accuracy = 52.17%\n",
            "Batch 360: Loss = 1.2868, Accuracy = 52.23%\n",
            "Batch 370: Loss = 0.9989, Accuracy = 52.34%\n",
            "Batch 380: Loss = 1.0828, Accuracy = 52.44%\n",
            "Batch 390: Loss = 1.0962, Accuracy = 52.47%\n",
            "Epoch 0: Total Loss = 1.3140, Total Accuracy = 52.47%\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "Batch 0: Benign Loss = 1.2278, Adversarial Loss = 1.2278\n",
            "Batch 10: Benign Loss = 1.3527, Adversarial Loss = 1.3527\n",
            "Batch 20: Benign Loss = 1.2934, Adversarial Loss = 1.2934\n",
            "Batch 30: Benign Loss = 1.1836, Adversarial Loss = 1.1836\n",
            "Batch 40: Benign Loss = 1.2196, Adversarial Loss = 1.2196\n",
            "Batch 50: Benign Loss = 1.2367, Adversarial Loss = 1.2367\n",
            "Batch 60: Benign Loss = 1.2310, Adversarial Loss = 1.2310\n",
            "Batch 70: Benign Loss = 1.2485, Adversarial Loss = 1.2485\n",
            "Batch 80: Benign Loss = 1.1491, Adversarial Loss = 1.1491\n",
            "Batch 90: Benign Loss = 1.1646, Adversarial Loss = 1.1646\n",
            "Epoch 0: Benign Accuracy = 34.61%, Adversarial Accuracy = 55.83%\n",
            "Benign Loss = 3.8538, Adversarial Loss = 1.2005\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "Batch 0: Loss = 1.1739, Accuracy = 53.91%\n",
            "Batch 10: Loss = 1.1981, Accuracy = 57.10%\n",
            "Batch 20: Loss = 1.2194, Accuracy = 57.48%\n",
            "Batch 30: Loss = 1.1127, Accuracy = 57.18%\n",
            "Batch 40: Loss = 1.1285, Accuracy = 57.26%\n",
            "Batch 50: Loss = 1.3232, Accuracy = 57.26%\n",
            "Batch 60: Loss = 1.0076, Accuracy = 57.01%\n",
            "Batch 70: Loss = 1.0143, Accuracy = 57.27%\n",
            "Batch 80: Loss = 1.3338, Accuracy = 57.19%\n",
            "Batch 90: Loss = 1.0289, Accuracy = 57.48%\n",
            "Batch 100: Loss = 1.2223, Accuracy = 57.50%\n",
            "Batch 110: Loss = 0.9390, Accuracy = 57.64%\n",
            "Batch 120: Loss = 1.2289, Accuracy = 57.41%\n",
            "Batch 130: Loss = 1.0091, Accuracy = 57.32%\n",
            "Batch 140: Loss = 1.2984, Accuracy = 57.15%\n",
            "Batch 150: Loss = 1.0267, Accuracy = 57.21%\n",
            "Batch 160: Loss = 1.2231, Accuracy = 57.30%\n",
            "Batch 170: Loss = 1.1929, Accuracy = 57.46%\n",
            "Batch 180: Loss = 1.0649, Accuracy = 57.54%\n",
            "Batch 190: Loss = 1.0239, Accuracy = 57.43%\n",
            "Batch 200: Loss = 1.1326, Accuracy = 57.37%\n",
            "Batch 210: Loss = 1.1042, Accuracy = 57.35%\n",
            "Batch 220: Loss = 1.3417, Accuracy = 57.29%\n",
            "Batch 230: Loss = 1.0932, Accuracy = 57.25%\n",
            "Batch 240: Loss = 1.2530, Accuracy = 57.25%\n",
            "Batch 250: Loss = 1.1503, Accuracy = 57.21%\n",
            "Batch 260: Loss = 1.1277, Accuracy = 57.33%\n",
            "Batch 270: Loss = 1.2309, Accuracy = 57.37%\n",
            "Batch 280: Loss = 1.1341, Accuracy = 57.41%\n",
            "Batch 290: Loss = 1.1277, Accuracy = 57.45%\n",
            "Batch 300: Loss = 1.0866, Accuracy = 57.50%\n",
            "Batch 310: Loss = 1.0244, Accuracy = 57.51%\n",
            "Batch 320: Loss = 1.1829, Accuracy = 57.47%\n",
            "Batch 330: Loss = 1.0019, Accuracy = 57.60%\n",
            "Batch 340: Loss = 1.1728, Accuracy = 57.64%\n",
            "Batch 350: Loss = 1.2300, Accuracy = 57.61%\n",
            "Batch 360: Loss = 1.0716, Accuracy = 57.62%\n",
            "Batch 370: Loss = 1.0981, Accuracy = 57.62%\n",
            "Batch 380: Loss = 0.9226, Accuracy = 57.67%\n",
            "Batch 390: Loss = 0.9174, Accuracy = 57.77%\n",
            "Epoch 1: Total Loss = 1.1441, Total Accuracy = 57.77%\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "Batch 0: Benign Loss = 1.1343, Adversarial Loss = 1.1343\n",
            "Batch 10: Benign Loss = 1.1460, Adversarial Loss = 1.1460\n",
            "Batch 20: Benign Loss = 1.2718, Adversarial Loss = 1.2718\n",
            "Batch 30: Benign Loss = 1.2472, Adversarial Loss = 1.2472\n",
            "Batch 40: Benign Loss = 1.1492, Adversarial Loss = 1.1492\n",
            "Batch 50: Benign Loss = 1.2723, Adversarial Loss = 1.2723\n",
            "Batch 60: Benign Loss = 1.2703, Adversarial Loss = 1.2703\n",
            "Batch 70: Benign Loss = 1.2892, Adversarial Loss = 1.2892\n",
            "Batch 80: Benign Loss = 1.2219, Adversarial Loss = 1.2219\n",
            "Batch 90: Benign Loss = 1.1478, Adversarial Loss = 1.1478\n",
            "Epoch 1: Benign Accuracy = 27.47%, Adversarial Accuracy = 56.85%\n",
            "Benign Loss = 5.9159, Adversarial Loss = 1.1878\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "Batch 0: Loss = 1.0609, Accuracy = 59.38%\n",
            "Batch 10: Loss = 1.1194, Accuracy = 61.29%\n",
            "Batch 20: Loss = 1.1154, Accuracy = 59.93%\n",
            "Batch 30: Loss = 1.1038, Accuracy = 59.90%\n",
            "Batch 40: Loss = 0.9511, Accuracy = 60.25%\n",
            "Batch 50: Loss = 1.0414, Accuracy = 60.08%\n",
            "Batch 60: Loss = 1.0601, Accuracy = 60.44%\n",
            "Batch 70: Loss = 0.9677, Accuracy = 60.22%\n",
            "Batch 80: Loss = 1.2112, Accuracy = 60.18%\n",
            "Batch 90: Loss = 1.1488, Accuracy = 60.33%\n",
            "Batch 100: Loss = 1.1922, Accuracy = 60.10%\n",
            "Batch 110: Loss = 1.0475, Accuracy = 60.03%\n",
            "Batch 120: Loss = 1.1408, Accuracy = 60.01%\n",
            "Batch 130: Loss = 0.9039, Accuracy = 59.98%\n",
            "Batch 140: Loss = 1.1751, Accuracy = 59.93%\n",
            "Batch 150: Loss = 1.1283, Accuracy = 60.03%\n",
            "Batch 160: Loss = 0.9971, Accuracy = 60.05%\n",
            "Batch 170: Loss = 1.1483, Accuracy = 59.97%\n",
            "Batch 180: Loss = 1.1519, Accuracy = 59.91%\n",
            "Batch 190: Loss = 1.0638, Accuracy = 59.98%\n",
            "Batch 200: Loss = 1.2724, Accuracy = 59.98%\n",
            "Batch 210: Loss = 1.0008, Accuracy = 60.05%\n",
            "Batch 220: Loss = 1.1517, Accuracy = 60.09%\n",
            "Batch 230: Loss = 1.0020, Accuracy = 60.08%\n",
            "Batch 240: Loss = 1.1052, Accuracy = 60.01%\n",
            "Batch 250: Loss = 1.0240, Accuracy = 60.05%\n",
            "Batch 260: Loss = 1.0845, Accuracy = 60.02%\n",
            "Batch 270: Loss = 1.0979, Accuracy = 60.02%\n",
            "Batch 280: Loss = 0.9451, Accuracy = 60.01%\n",
            "Batch 290: Loss = 1.2575, Accuracy = 60.11%\n",
            "Batch 300: Loss = 1.2455, Accuracy = 60.17%\n",
            "Batch 310: Loss = 1.1228, Accuracy = 60.12%\n",
            "Batch 320: Loss = 1.2592, Accuracy = 60.05%\n",
            "Batch 330: Loss = 1.1183, Accuracy = 60.02%\n",
            "Batch 340: Loss = 1.0042, Accuracy = 60.00%\n",
            "Batch 350: Loss = 1.0663, Accuracy = 59.96%\n",
            "Batch 360: Loss = 1.0349, Accuracy = 59.99%\n",
            "Batch 370: Loss = 1.1112, Accuracy = 59.99%\n",
            "Batch 380: Loss = 1.1376, Accuracy = 59.88%\n",
            "Batch 390: Loss = 0.7900, Accuracy = 59.93%\n",
            "Epoch 2: Total Loss = 1.0894, Total Accuracy = 59.93%\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "Batch 0: Benign Loss = 1.1637, Adversarial Loss = 1.1637\n",
            "Batch 10: Benign Loss = 1.1379, Adversarial Loss = 1.1379\n",
            "Batch 20: Benign Loss = 1.1914, Adversarial Loss = 1.1914\n",
            "Batch 30: Benign Loss = 1.2442, Adversarial Loss = 1.2442\n",
            "Batch 40: Benign Loss = 1.0889, Adversarial Loss = 1.0889\n",
            "Batch 50: Benign Loss = 1.2772, Adversarial Loss = 1.2772\n",
            "Batch 60: Benign Loss = 1.0989, Adversarial Loss = 1.0989\n",
            "Batch 70: Benign Loss = 1.3186, Adversarial Loss = 1.3186\n",
            "Batch 80: Benign Loss = 1.1405, Adversarial Loss = 1.1405\n",
            "Batch 90: Benign Loss = 1.1519, Adversarial Loss = 1.1519\n",
            "Epoch 2: Benign Accuracy = 32.08%, Adversarial Accuracy = 57.86%\n",
            "Benign Loss = 5.2213, Adversarial Loss = 1.1423\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "Batch 0: Loss = 1.0645, Accuracy = 59.38%\n",
            "Batch 10: Loss = 1.0438, Accuracy = 61.15%\n",
            "Batch 20: Loss = 1.0278, Accuracy = 61.53%\n",
            "Batch 30: Loss = 0.9792, Accuracy = 61.49%\n",
            "Batch 40: Loss = 1.0204, Accuracy = 61.62%\n",
            "Batch 50: Loss = 1.0385, Accuracy = 61.92%\n",
            "Batch 60: Loss = 1.0623, Accuracy = 62.04%\n",
            "Batch 70: Loss = 1.1156, Accuracy = 61.85%\n",
            "Batch 80: Loss = 1.2934, Accuracy = 61.82%\n",
            "Batch 90: Loss = 1.0490, Accuracy = 61.74%\n",
            "Batch 100: Loss = 0.9440, Accuracy = 61.56%\n",
            "Batch 110: Loss = 1.1162, Accuracy = 61.42%\n",
            "Batch 120: Loss = 1.1011, Accuracy = 61.25%\n",
            "Batch 130: Loss = 1.0013, Accuracy = 61.31%\n",
            "Batch 140: Loss = 1.0078, Accuracy = 61.29%\n",
            "Batch 150: Loss = 1.0852, Accuracy = 61.36%\n",
            "Batch 160: Loss = 0.9131, Accuracy = 61.51%\n",
            "Batch 170: Loss = 1.0552, Accuracy = 61.47%\n",
            "Batch 180: Loss = 1.0053, Accuracy = 61.48%\n",
            "Batch 190: Loss = 0.9702, Accuracy = 61.50%\n",
            "Batch 200: Loss = 1.0750, Accuracy = 61.53%\n",
            "Batch 210: Loss = 1.0505, Accuracy = 61.53%\n",
            "Batch 220: Loss = 0.9785, Accuracy = 61.47%\n",
            "Batch 230: Loss = 1.1271, Accuracy = 61.42%\n",
            "Batch 240: Loss = 0.9392, Accuracy = 61.61%\n",
            "Batch 250: Loss = 0.9841, Accuracy = 61.57%\n",
            "Batch 260: Loss = 1.0132, Accuracy = 61.55%\n",
            "Batch 270: Loss = 1.1483, Accuracy = 61.54%\n",
            "Batch 280: Loss = 1.0778, Accuracy = 61.50%\n",
            "Batch 290: Loss = 1.0190, Accuracy = 61.49%\n",
            "Batch 300: Loss = 1.0505, Accuracy = 61.45%\n",
            "Batch 310: Loss = 1.0947, Accuracy = 61.36%\n",
            "Batch 320: Loss = 1.0345, Accuracy = 61.44%\n",
            "Batch 330: Loss = 1.0370, Accuracy = 61.47%\n",
            "Batch 340: Loss = 0.9714, Accuracy = 61.46%\n",
            "Batch 350: Loss = 1.1649, Accuracy = 61.42%\n",
            "Batch 360: Loss = 0.8790, Accuracy = 61.44%\n",
            "Batch 370: Loss = 1.0419, Accuracy = 61.48%\n",
            "Batch 380: Loss = 0.9506, Accuracy = 61.47%\n",
            "Batch 390: Loss = 1.1605, Accuracy = 61.44%\n",
            "Epoch 3: Total Loss = 1.0448, Total Accuracy = 61.44%\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "Batch 0: Benign Loss = 1.2148, Adversarial Loss = 1.2148\n",
            "Batch 10: Benign Loss = 1.2441, Adversarial Loss = 1.2441\n",
            "Batch 20: Benign Loss = 1.1720, Adversarial Loss = 1.1720\n",
            "Batch 30: Benign Loss = 1.2399, Adversarial Loss = 1.2399\n",
            "Batch 40: Benign Loss = 1.0874, Adversarial Loss = 1.0874\n",
            "Batch 50: Benign Loss = 1.1812, Adversarial Loss = 1.1812\n",
            "Batch 60: Benign Loss = 1.1742, Adversarial Loss = 1.1742\n",
            "Batch 70: Benign Loss = 1.2671, Adversarial Loss = 1.2671\n",
            "Batch 80: Benign Loss = 1.0153, Adversarial Loss = 1.0153\n",
            "Batch 90: Benign Loss = 1.1311, Adversarial Loss = 1.1311\n",
            "Epoch 3: Benign Accuracy = 27.50%, Adversarial Accuracy = 57.87%\n",
            "Benign Loss = 6.0375, Adversarial Loss = 1.1598\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "Batch 0: Loss = 0.8589, Accuracy = 71.09%\n",
            "Batch 10: Loss = 0.9972, Accuracy = 64.56%\n",
            "Batch 20: Loss = 0.9098, Accuracy = 63.58%\n",
            "Batch 30: Loss = 0.8656, Accuracy = 63.71%\n",
            "Batch 40: Loss = 0.9740, Accuracy = 63.32%\n",
            "Batch 50: Loss = 1.1452, Accuracy = 63.36%\n",
            "Batch 60: Loss = 1.0076, Accuracy = 63.37%\n",
            "Batch 70: Loss = 0.9562, Accuracy = 63.47%\n",
            "Batch 80: Loss = 1.1176, Accuracy = 63.24%\n",
            "Batch 90: Loss = 1.0482, Accuracy = 63.16%\n",
            "Batch 100: Loss = 0.9765, Accuracy = 62.97%\n",
            "Batch 110: Loss = 0.9640, Accuracy = 62.86%\n",
            "Batch 120: Loss = 1.1407, Accuracy = 62.83%\n",
            "Batch 130: Loss = 1.0216, Accuracy = 62.75%\n",
            "Batch 140: Loss = 1.0604, Accuracy = 62.67%\n",
            "Batch 150: Loss = 0.9519, Accuracy = 62.65%\n",
            "Batch 160: Loss = 0.9310, Accuracy = 62.58%\n",
            "Batch 170: Loss = 1.0576, Accuracy = 62.56%\n",
            "Batch 180: Loss = 1.1479, Accuracy = 62.49%\n",
            "Batch 190: Loss = 1.1766, Accuracy = 62.50%\n",
            "Batch 200: Loss = 1.0795, Accuracy = 62.29%\n",
            "Batch 210: Loss = 1.1463, Accuracy = 62.18%\n",
            "Batch 220: Loss = 1.0620, Accuracy = 62.13%\n",
            "Batch 230: Loss = 1.1277, Accuracy = 62.01%\n",
            "Batch 240: Loss = 1.1445, Accuracy = 61.91%\n",
            "Batch 250: Loss = 0.9986, Accuracy = 61.91%\n",
            "Batch 260: Loss = 1.1106, Accuracy = 61.94%\n",
            "Batch 270: Loss = 0.9856, Accuracy = 61.97%\n",
            "Batch 280: Loss = 1.2106, Accuracy = 61.90%\n",
            "Batch 290: Loss = 0.8956, Accuracy = 61.95%\n",
            "Batch 300: Loss = 1.0134, Accuracy = 61.94%\n",
            "Batch 310: Loss = 0.9029, Accuracy = 61.95%\n",
            "Batch 320: Loss = 1.0307, Accuracy = 61.94%\n",
            "Batch 330: Loss = 0.9387, Accuracy = 61.99%\n",
            "Batch 340: Loss = 1.0255, Accuracy = 61.92%\n",
            "Batch 350: Loss = 1.1078, Accuracy = 61.89%\n",
            "Batch 360: Loss = 1.1004, Accuracy = 61.89%\n",
            "Batch 370: Loss = 1.1201, Accuracy = 61.92%\n",
            "Batch 380: Loss = 0.8981, Accuracy = 61.89%\n",
            "Batch 390: Loss = 1.1020, Accuracy = 61.90%\n",
            "Epoch 4: Total Loss = 1.0289, Total Accuracy = 61.90%\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "Batch 0: Benign Loss = 1.1779, Adversarial Loss = 1.1779\n",
            "Batch 10: Benign Loss = 1.1547, Adversarial Loss = 1.1547\n",
            "Batch 20: Benign Loss = 1.0712, Adversarial Loss = 1.0712\n",
            "Batch 30: Benign Loss = 1.1470, Adversarial Loss = 1.1470\n",
            "Batch 40: Benign Loss = 1.1193, Adversarial Loss = 1.1193\n",
            "Batch 50: Benign Loss = 1.1871, Adversarial Loss = 1.1871\n",
            "Batch 60: Benign Loss = 1.1332, Adversarial Loss = 1.1332\n",
            "Batch 70: Benign Loss = 1.2160, Adversarial Loss = 1.2160\n",
            "Batch 80: Benign Loss = 1.1394, Adversarial Loss = 1.1394\n",
            "Batch 90: Benign Loss = 1.1673, Adversarial Loss = 1.1673\n",
            "Epoch 4: Benign Accuracy = 19.94%, Adversarial Accuracy = 59.05%\n",
            "Benign Loss = 8.2616, Adversarial Loss = 1.1260\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "Batch 0: Loss = 1.0705, Accuracy = 62.50%\n",
            "Batch 10: Loss = 1.0689, Accuracy = 61.29%\n",
            "Batch 20: Loss = 0.9408, Accuracy = 62.20%\n",
            "Batch 30: Loss = 0.8285, Accuracy = 63.48%\n",
            "Batch 40: Loss = 0.8274, Accuracy = 63.32%\n",
            "Batch 50: Loss = 0.9767, Accuracy = 63.57%\n",
            "Batch 60: Loss = 1.0572, Accuracy = 63.50%\n",
            "Batch 70: Loss = 0.8575, Accuracy = 63.22%\n",
            "Batch 80: Loss = 0.9607, Accuracy = 63.06%\n",
            "Batch 90: Loss = 0.9132, Accuracy = 63.17%\n",
            "Batch 100: Loss = 1.0025, Accuracy = 63.27%\n",
            "Batch 110: Loss = 1.0881, Accuracy = 63.27%\n",
            "Batch 120: Loss = 1.0891, Accuracy = 63.15%\n",
            "Batch 130: Loss = 1.0400, Accuracy = 63.21%\n",
            "Batch 140: Loss = 0.8575, Accuracy = 63.15%\n",
            "Batch 150: Loss = 0.8825, Accuracy = 63.21%\n",
            "Batch 160: Loss = 1.0665, Accuracy = 63.12%\n",
            "Batch 170: Loss = 1.0183, Accuracy = 63.13%\n",
            "Batch 180: Loss = 1.0963, Accuracy = 63.16%\n",
            "Batch 190: Loss = 0.8405, Accuracy = 63.15%\n",
            "Batch 200: Loss = 1.1292, Accuracy = 63.11%\n",
            "Batch 210: Loss = 0.9199, Accuracy = 63.13%\n",
            "Batch 220: Loss = 1.0938, Accuracy = 63.06%\n",
            "Batch 230: Loss = 0.9311, Accuracy = 63.09%\n",
            "Batch 240: Loss = 0.9034, Accuracy = 62.97%\n",
            "Batch 250: Loss = 0.9048, Accuracy = 62.95%\n",
            "Batch 260: Loss = 1.0800, Accuracy = 62.88%\n",
            "Batch 270: Loss = 0.9500, Accuracy = 62.95%\n",
            "Batch 280: Loss = 1.0138, Accuracy = 62.94%\n",
            "Batch 290: Loss = 0.9269, Accuracy = 62.92%\n",
            "Batch 300: Loss = 1.1435, Accuracy = 62.87%\n",
            "Batch 310: Loss = 0.9803, Accuracy = 62.87%\n",
            "Batch 320: Loss = 1.0111, Accuracy = 62.86%\n",
            "Batch 330: Loss = 1.1145, Accuracy = 62.82%\n",
            "Batch 340: Loss = 1.0687, Accuracy = 62.79%\n",
            "Batch 350: Loss = 0.9140, Accuracy = 62.76%\n",
            "Batch 360: Loss = 1.0801, Accuracy = 62.74%\n",
            "Batch 370: Loss = 0.8823, Accuracy = 62.76%\n",
            "Batch 380: Loss = 1.1545, Accuracy = 62.78%\n",
            "Batch 390: Loss = 1.1276, Accuracy = 62.74%\n",
            "Epoch 5: Total Loss = 1.0023, Total Accuracy = 62.74%\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "Batch 0: Benign Loss = 1.1746, Adversarial Loss = 1.1746\n",
            "Batch 10: Benign Loss = 1.2574, Adversarial Loss = 1.2574\n",
            "Batch 20: Benign Loss = 1.1649, Adversarial Loss = 1.1649\n",
            "Batch 30: Benign Loss = 1.1483, Adversarial Loss = 1.1483\n",
            "Batch 40: Benign Loss = 1.1203, Adversarial Loss = 1.1203\n",
            "Batch 50: Benign Loss = 1.2371, Adversarial Loss = 1.2371\n",
            "Batch 60: Benign Loss = 1.1466, Adversarial Loss = 1.1466\n",
            "Batch 70: Benign Loss = 1.2787, Adversarial Loss = 1.2787\n",
            "Batch 80: Benign Loss = 1.1128, Adversarial Loss = 1.1128\n",
            "Batch 90: Benign Loss = 1.1850, Adversarial Loss = 1.1850\n",
            "Epoch 5: Benign Accuracy = 15.91%, Adversarial Accuracy = 58.90%\n",
            "Benign Loss = 7.4396, Adversarial Loss = 1.1404\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "Batch 0: Loss = 0.9604, Accuracy = 64.84%\n",
            "Batch 10: Loss = 0.8961, Accuracy = 65.13%\n",
            "Batch 20: Loss = 1.0278, Accuracy = 64.47%\n",
            "Batch 30: Loss = 1.0998, Accuracy = 64.47%\n",
            "Batch 40: Loss = 0.8524, Accuracy = 64.02%\n",
            "Batch 50: Loss = 0.9406, Accuracy = 63.74%\n",
            "Batch 60: Loss = 0.8248, Accuracy = 64.08%\n",
            "Batch 70: Loss = 0.7872, Accuracy = 64.11%\n",
            "Batch 80: Loss = 0.8075, Accuracy = 64.20%\n",
            "Batch 90: Loss = 0.9184, Accuracy = 64.31%\n",
            "Batch 100: Loss = 0.9982, Accuracy = 64.07%\n",
            "Batch 110: Loss = 1.0908, Accuracy = 63.96%\n",
            "Batch 120: Loss = 0.9755, Accuracy = 63.97%\n",
            "Batch 130: Loss = 0.9770, Accuracy = 63.96%\n",
            "Batch 140: Loss = 0.9143, Accuracy = 63.96%\n",
            "Batch 150: Loss = 1.0524, Accuracy = 63.82%\n",
            "Batch 160: Loss = 0.9442, Accuracy = 63.90%\n",
            "Batch 170: Loss = 0.9800, Accuracy = 63.87%\n",
            "Batch 180: Loss = 0.9951, Accuracy = 63.86%\n",
            "Batch 190: Loss = 1.1402, Accuracy = 63.77%\n",
            "Batch 200: Loss = 0.9634, Accuracy = 63.86%\n",
            "Batch 210: Loss = 0.8955, Accuracy = 63.87%\n",
            "Batch 220: Loss = 0.8458, Accuracy = 64.00%\n",
            "Batch 230: Loss = 1.0630, Accuracy = 63.97%\n",
            "Batch 240: Loss = 1.1107, Accuracy = 63.89%\n",
            "Batch 250: Loss = 0.8531, Accuracy = 63.91%\n",
            "Batch 260: Loss = 0.8920, Accuracy = 63.84%\n",
            "Batch 270: Loss = 0.9713, Accuracy = 63.75%\n",
            "Batch 280: Loss = 1.0010, Accuracy = 63.80%\n",
            "Batch 290: Loss = 1.1460, Accuracy = 63.80%\n",
            "Batch 300: Loss = 1.0134, Accuracy = 63.76%\n",
            "Batch 310: Loss = 0.9372, Accuracy = 63.86%\n",
            "Batch 320: Loss = 0.9582, Accuracy = 63.84%\n",
            "Batch 330: Loss = 1.0488, Accuracy = 63.84%\n",
            "Batch 340: Loss = 0.9412, Accuracy = 63.77%\n",
            "Batch 350: Loss = 0.9190, Accuracy = 63.77%\n",
            "Batch 360: Loss = 1.0524, Accuracy = 63.80%\n",
            "Batch 370: Loss = 1.0614, Accuracy = 63.80%\n",
            "Batch 380: Loss = 0.9494, Accuracy = 63.74%\n",
            "Batch 390: Loss = 1.0423, Accuracy = 63.76%\n",
            "Epoch 6: Total Loss = 0.9819, Total Accuracy = 63.76%\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "Batch 0: Benign Loss = 1.1443, Adversarial Loss = 1.1443\n",
            "Batch 10: Benign Loss = 1.2710, Adversarial Loss = 1.2710\n",
            "Batch 20: Benign Loss = 1.2290, Adversarial Loss = 1.2290\n",
            "Batch 30: Benign Loss = 1.3114, Adversarial Loss = 1.3114\n",
            "Batch 40: Benign Loss = 1.1238, Adversarial Loss = 1.1238\n",
            "Batch 50: Benign Loss = 1.1784, Adversarial Loss = 1.1784\n",
            "Batch 60: Benign Loss = 1.0976, Adversarial Loss = 1.0976\n",
            "Batch 70: Benign Loss = 1.1915, Adversarial Loss = 1.1915\n",
            "Batch 80: Benign Loss = 0.9610, Adversarial Loss = 0.9610\n",
            "Batch 90: Benign Loss = 1.1314, Adversarial Loss = 1.1314\n",
            "Epoch 6: Benign Accuracy = 12.76%, Adversarial Accuracy = 58.87%\n",
            "Benign Loss = 10.7787, Adversarial Loss = 1.1444\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "Batch 0: Loss = 0.8089, Accuracy = 69.53%\n",
            "Batch 10: Loss = 0.8593, Accuracy = 64.84%\n",
            "Batch 20: Loss = 0.8576, Accuracy = 64.92%\n",
            "Batch 30: Loss = 0.8977, Accuracy = 65.20%\n",
            "Batch 40: Loss = 0.8306, Accuracy = 64.56%\n",
            "Batch 50: Loss = 0.9959, Accuracy = 64.87%\n",
            "Batch 60: Loss = 0.8690, Accuracy = 65.30%\n",
            "Batch 70: Loss = 0.9720, Accuracy = 65.61%\n",
            "Batch 80: Loss = 0.9453, Accuracy = 65.33%\n",
            "Batch 90: Loss = 0.8006, Accuracy = 65.51%\n",
            "Batch 100: Loss = 0.8263, Accuracy = 65.66%\n",
            "Batch 110: Loss = 0.8702, Accuracy = 65.59%\n",
            "Batch 120: Loss = 0.8632, Accuracy = 65.63%\n",
            "Batch 130: Loss = 0.9776, Accuracy = 65.38%\n",
            "Batch 140: Loss = 0.9595, Accuracy = 65.28%\n",
            "Batch 150: Loss = 0.9704, Accuracy = 65.19%\n",
            "Batch 160: Loss = 1.1005, Accuracy = 65.12%\n",
            "Batch 170: Loss = 0.9563, Accuracy = 65.10%\n",
            "Batch 180: Loss = 1.0104, Accuracy = 64.96%\n",
            "Batch 190: Loss = 1.1027, Accuracy = 64.88%\n",
            "Batch 200: Loss = 0.9680, Accuracy = 64.80%\n",
            "Batch 210: Loss = 1.0469, Accuracy = 64.77%\n",
            "Batch 220: Loss = 0.9470, Accuracy = 64.73%\n",
            "Batch 230: Loss = 0.9283, Accuracy = 64.59%\n",
            "Batch 240: Loss = 0.9695, Accuracy = 64.59%\n",
            "Batch 250: Loss = 0.9542, Accuracy = 64.58%\n",
            "Batch 260: Loss = 0.9875, Accuracy = 64.60%\n",
            "Batch 270: Loss = 1.0851, Accuracy = 64.59%\n",
            "Batch 280: Loss = 1.1419, Accuracy = 64.60%\n",
            "Batch 290: Loss = 1.0162, Accuracy = 64.56%\n",
            "Batch 300: Loss = 0.9510, Accuracy = 64.54%\n",
            "Batch 310: Loss = 0.9632, Accuracy = 64.62%\n",
            "Batch 320: Loss = 1.0037, Accuracy = 64.61%\n",
            "Batch 330: Loss = 0.8354, Accuracy = 64.61%\n",
            "Batch 340: Loss = 1.0205, Accuracy = 64.61%\n",
            "Batch 350: Loss = 0.8961, Accuracy = 64.64%\n",
            "Batch 360: Loss = 1.0222, Accuracy = 64.62%\n",
            "Batch 370: Loss = 0.9276, Accuracy = 64.62%\n",
            "Batch 380: Loss = 0.9546, Accuracy = 64.50%\n",
            "Batch 390: Loss = 1.0226, Accuracy = 64.47%\n",
            "Epoch 7: Total Loss = 0.9583, Total Accuracy = 64.47%\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "Batch 0: Benign Loss = 1.1556, Adversarial Loss = 1.1556\n",
            "Batch 10: Benign Loss = 1.2601, Adversarial Loss = 1.2601\n",
            "Batch 20: Benign Loss = 1.1425, Adversarial Loss = 1.1425\n",
            "Batch 30: Benign Loss = 1.1797, Adversarial Loss = 1.1797\n",
            "Batch 40: Benign Loss = 1.0007, Adversarial Loss = 1.0007\n",
            "Batch 50: Benign Loss = 1.1916, Adversarial Loss = 1.1916\n",
            "Batch 60: Benign Loss = 1.1427, Adversarial Loss = 1.1427\n",
            "Batch 70: Benign Loss = 1.2195, Adversarial Loss = 1.2195\n",
            "Batch 80: Benign Loss = 1.0235, Adversarial Loss = 1.0235\n",
            "Batch 90: Benign Loss = 1.0688, Adversarial Loss = 1.0688\n",
            "Epoch 7: Benign Accuracy = 13.13%, Adversarial Accuracy = 60.16%\n",
            "Benign Loss = 10.7187, Adversarial Loss = 1.1109\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "Batch 0: Loss = 1.1628, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.1112, Accuracy = 63.64%\n",
            "Batch 20: Loss = 0.9257, Accuracy = 65.44%\n",
            "Batch 30: Loss = 0.9542, Accuracy = 65.78%\n",
            "Batch 40: Loss = 0.9929, Accuracy = 65.00%\n",
            "Batch 50: Loss = 0.8123, Accuracy = 65.13%\n",
            "Batch 60: Loss = 1.1112, Accuracy = 65.20%\n",
            "Batch 70: Loss = 0.9498, Accuracy = 65.18%\n",
            "Batch 80: Loss = 0.8245, Accuracy = 65.05%\n",
            "Batch 90: Loss = 1.0305, Accuracy = 65.01%\n",
            "Batch 100: Loss = 0.9911, Accuracy = 65.08%\n",
            "Batch 110: Loss = 1.0177, Accuracy = 65.17%\n",
            "Batch 120: Loss = 1.2027, Accuracy = 65.03%\n",
            "Batch 130: Loss = 0.8554, Accuracy = 64.97%\n",
            "Batch 140: Loss = 1.0783, Accuracy = 65.01%\n",
            "Batch 150: Loss = 0.8516, Accuracy = 65.12%\n",
            "Batch 160: Loss = 0.8996, Accuracy = 65.16%\n",
            "Batch 170: Loss = 0.8672, Accuracy = 65.15%\n",
            "Batch 180: Loss = 0.8927, Accuracy = 65.23%\n",
            "Batch 190: Loss = 0.9732, Accuracy = 65.15%\n",
            "Batch 200: Loss = 0.9664, Accuracy = 65.03%\n",
            "Batch 210: Loss = 0.6858, Accuracy = 65.08%\n",
            "Batch 220: Loss = 0.7735, Accuracy = 65.03%\n",
            "Batch 230: Loss = 1.1729, Accuracy = 65.09%\n",
            "Batch 240: Loss = 0.8216, Accuracy = 65.17%\n",
            "Batch 250: Loss = 1.0570, Accuracy = 65.20%\n",
            "Batch 260: Loss = 0.9832, Accuracy = 65.12%\n",
            "Batch 270: Loss = 0.9188, Accuracy = 65.22%\n",
            "Batch 280: Loss = 1.0116, Accuracy = 65.24%\n",
            "Batch 290: Loss = 1.0382, Accuracy = 65.22%\n",
            "Batch 300: Loss = 0.8653, Accuracy = 65.21%\n",
            "Batch 310: Loss = 0.8828, Accuracy = 65.23%\n",
            "Batch 320: Loss = 1.0468, Accuracy = 65.14%\n",
            "Batch 330: Loss = 0.9571, Accuracy = 65.16%\n",
            "Batch 340: Loss = 0.9081, Accuracy = 65.07%\n",
            "Batch 350: Loss = 0.9772, Accuracy = 65.04%\n",
            "Batch 360: Loss = 0.9625, Accuracy = 65.08%\n",
            "Batch 370: Loss = 0.9468, Accuracy = 65.08%\n",
            "Batch 380: Loss = 1.0369, Accuracy = 65.04%\n",
            "Batch 390: Loss = 0.9760, Accuracy = 65.06%\n",
            "Epoch 8: Total Loss = 0.9448, Total Accuracy = 65.06%\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "Batch 0: Benign Loss = 1.1230, Adversarial Loss = 1.1230\n",
            "Batch 10: Benign Loss = 1.1955, Adversarial Loss = 1.1955\n",
            "Batch 20: Benign Loss = 1.1099, Adversarial Loss = 1.1099\n",
            "Batch 30: Benign Loss = 1.1853, Adversarial Loss = 1.1853\n",
            "Batch 40: Benign Loss = 1.0699, Adversarial Loss = 1.0699\n",
            "Batch 50: Benign Loss = 1.3140, Adversarial Loss = 1.3140\n",
            "Batch 60: Benign Loss = 1.0846, Adversarial Loss = 1.0846\n",
            "Batch 70: Benign Loss = 1.3241, Adversarial Loss = 1.3241\n",
            "Batch 80: Benign Loss = 1.0479, Adversarial Loss = 1.0479\n",
            "Batch 90: Benign Loss = 1.0122, Adversarial Loss = 1.0122\n",
            "Epoch 8: Benign Accuracy = 12.29%, Adversarial Accuracy = 59.60%\n",
            "Benign Loss = 10.7990, Adversarial Loss = 1.1305\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "Batch 0: Loss = 0.9598, Accuracy = 65.62%\n",
            "Batch 10: Loss = 0.7540, Accuracy = 66.34%\n",
            "Batch 20: Loss = 0.8126, Accuracy = 66.89%\n",
            "Batch 30: Loss = 0.8018, Accuracy = 66.56%\n",
            "Batch 40: Loss = 0.7758, Accuracy = 66.10%\n",
            "Batch 50: Loss = 0.9122, Accuracy = 65.55%\n",
            "Batch 60: Loss = 1.0178, Accuracy = 65.56%\n",
            "Batch 70: Loss = 0.9882, Accuracy = 65.45%\n",
            "Batch 80: Loss = 0.8846, Accuracy = 65.31%\n",
            "Batch 90: Loss = 0.9931, Accuracy = 65.23%\n",
            "Batch 100: Loss = 0.6841, Accuracy = 65.26%\n",
            "Batch 110: Loss = 0.9818, Accuracy = 65.14%\n",
            "Batch 120: Loss = 0.9797, Accuracy = 65.17%\n",
            "Batch 130: Loss = 0.7864, Accuracy = 65.02%\n",
            "Batch 140: Loss = 0.8342, Accuracy = 65.08%\n",
            "Batch 150: Loss = 0.8444, Accuracy = 65.02%\n",
            "Batch 160: Loss = 0.9472, Accuracy = 65.09%\n",
            "Batch 170: Loss = 0.8204, Accuracy = 65.03%\n",
            "Batch 180: Loss = 0.7635, Accuracy = 65.11%\n",
            "Batch 190: Loss = 0.9258, Accuracy = 65.10%\n",
            "Batch 200: Loss = 1.1492, Accuracy = 64.91%\n",
            "Batch 210: Loss = 1.1231, Accuracy = 64.90%\n",
            "Batch 220: Loss = 0.9840, Accuracy = 64.94%\n",
            "Batch 230: Loss = 0.7838, Accuracy = 64.97%\n",
            "Batch 240: Loss = 0.8071, Accuracy = 65.02%\n",
            "Batch 250: Loss = 0.8586, Accuracy = 64.97%\n",
            "Batch 260: Loss = 0.9257, Accuracy = 64.91%\n",
            "Batch 270: Loss = 1.0031, Accuracy = 64.86%\n",
            "Batch 280: Loss = 0.8231, Accuracy = 64.92%\n",
            "Batch 290: Loss = 1.0448, Accuracy = 64.83%\n",
            "Batch 300: Loss = 0.9850, Accuracy = 64.72%\n",
            "Batch 310: Loss = 0.8669, Accuracy = 64.69%\n",
            "Batch 320: Loss = 0.9956, Accuracy = 64.72%\n",
            "Batch 330: Loss = 0.8751, Accuracy = 64.71%\n",
            "Batch 340: Loss = 1.1651, Accuracy = 64.69%\n",
            "Batch 350: Loss = 0.8780, Accuracy = 64.71%\n",
            "Batch 360: Loss = 0.8003, Accuracy = 64.71%\n",
            "Batch 370: Loss = 1.0619, Accuracy = 64.74%\n",
            "Batch 380: Loss = 1.0865, Accuracy = 64.68%\n",
            "Batch 390: Loss = 0.9601, Accuracy = 64.70%\n",
            "Epoch 9: Total Loss = 0.9432, Total Accuracy = 64.70%\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "Batch 0: Benign Loss = 1.2767, Adversarial Loss = 1.2767\n",
            "Batch 10: Benign Loss = 1.3441, Adversarial Loss = 1.3441\n",
            "Batch 20: Benign Loss = 1.1805, Adversarial Loss = 1.1805\n",
            "Batch 30: Benign Loss = 1.2467, Adversarial Loss = 1.2467\n",
            "Batch 40: Benign Loss = 1.1002, Adversarial Loss = 1.1002\n",
            "Batch 50: Benign Loss = 1.1643, Adversarial Loss = 1.1643\n",
            "Batch 60: Benign Loss = 1.2153, Adversarial Loss = 1.2153\n",
            "Batch 70: Benign Loss = 1.3318, Adversarial Loss = 1.3318\n",
            "Batch 80: Benign Loss = 1.0443, Adversarial Loss = 1.0443\n",
            "Batch 90: Benign Loss = 1.0475, Adversarial Loss = 1.0475\n",
            "Epoch 9: Benign Accuracy = 13.85%, Adversarial Accuracy = 59.66%\n",
            "Benign Loss = 11.7725, Adversarial Loss = 1.1415\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "Batch 0: Loss = 0.8794, Accuracy = 67.97%\n",
            "Batch 10: Loss = 0.9102, Accuracy = 65.55%\n",
            "Batch 20: Loss = 0.8157, Accuracy = 66.18%\n",
            "Batch 30: Loss = 0.9565, Accuracy = 66.13%\n",
            "Batch 40: Loss = 0.9709, Accuracy = 66.39%\n",
            "Batch 50: Loss = 1.0509, Accuracy = 66.19%\n",
            "Batch 60: Loss = 0.8084, Accuracy = 66.66%\n",
            "Batch 70: Loss = 0.9850, Accuracy = 66.49%\n",
            "Batch 80: Loss = 0.8512, Accuracy = 66.66%\n",
            "Batch 90: Loss = 0.9773, Accuracy = 66.77%\n",
            "Batch 100: Loss = 0.8876, Accuracy = 66.66%\n",
            "Batch 110: Loss = 0.9177, Accuracy = 66.32%\n",
            "Batch 120: Loss = 0.8548, Accuracy = 66.28%\n",
            "Batch 130: Loss = 1.0753, Accuracy = 66.33%\n",
            "Batch 140: Loss = 0.8772, Accuracy = 66.35%\n",
            "Batch 150: Loss = 0.8223, Accuracy = 66.30%\n",
            "Batch 160: Loss = 0.9060, Accuracy = 66.31%\n",
            "Batch 170: Loss = 0.9523, Accuracy = 66.29%\n",
            "Batch 180: Loss = 0.9341, Accuracy = 66.14%\n",
            "Batch 190: Loss = 0.9075, Accuracy = 66.07%\n",
            "Batch 200: Loss = 0.8379, Accuracy = 66.09%\n",
            "Batch 210: Loss = 0.9992, Accuracy = 65.98%\n",
            "Batch 220: Loss = 0.9721, Accuracy = 66.04%\n",
            "Batch 230: Loss = 0.9697, Accuracy = 65.99%\n",
            "Batch 240: Loss = 0.9854, Accuracy = 66.03%\n",
            "Batch 250: Loss = 0.9661, Accuracy = 65.95%\n",
            "Batch 260: Loss = 0.9797, Accuracy = 65.87%\n",
            "Batch 270: Loss = 1.0493, Accuracy = 65.77%\n",
            "Batch 280: Loss = 0.9856, Accuracy = 65.80%\n",
            "Batch 290: Loss = 0.7425, Accuracy = 65.86%\n",
            "Batch 300: Loss = 0.9354, Accuracy = 65.86%\n",
            "Batch 310: Loss = 0.8875, Accuracy = 65.84%\n",
            "Batch 320: Loss = 1.0396, Accuracy = 65.79%\n",
            "Batch 330: Loss = 1.0474, Accuracy = 65.72%\n",
            "Batch 340: Loss = 1.0038, Accuracy = 65.64%\n",
            "Batch 350: Loss = 1.0520, Accuracy = 65.68%\n",
            "Batch 360: Loss = 0.8957, Accuracy = 65.73%\n",
            "Batch 370: Loss = 0.9478, Accuracy = 65.70%\n",
            "Batch 380: Loss = 1.0240, Accuracy = 65.65%\n",
            "Batch 390: Loss = 0.9858, Accuracy = 65.64%\n",
            "Epoch 10: Total Loss = 0.9260, Total Accuracy = 65.64%\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "Batch 0: Benign Loss = 1.1012, Adversarial Loss = 1.1012\n",
            "Batch 10: Benign Loss = 1.2548, Adversarial Loss = 1.2548\n",
            "Batch 20: Benign Loss = 1.1624, Adversarial Loss = 1.1624\n",
            "Batch 30: Benign Loss = 1.1689, Adversarial Loss = 1.1689\n",
            "Batch 40: Benign Loss = 1.1564, Adversarial Loss = 1.1564\n",
            "Batch 50: Benign Loss = 1.2073, Adversarial Loss = 1.2073\n",
            "Batch 60: Benign Loss = 1.1948, Adversarial Loss = 1.1948\n",
            "Batch 70: Benign Loss = 1.3278, Adversarial Loss = 1.3278\n",
            "Batch 80: Benign Loss = 1.0536, Adversarial Loss = 1.0536\n",
            "Batch 90: Benign Loss = 1.0987, Adversarial Loss = 1.0987\n",
            "Epoch 10: Benign Accuracy = 11.97%, Adversarial Accuracy = 59.88%\n",
            "Benign Loss = 9.9293, Adversarial Loss = 1.1374\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "Batch 0: Loss = 0.9144, Accuracy = 68.75%\n",
            "Batch 10: Loss = 0.8525, Accuracy = 67.61%\n",
            "Batch 20: Loss = 1.0374, Accuracy = 66.44%\n",
            "Batch 30: Loss = 1.1340, Accuracy = 66.41%\n",
            "Batch 40: Loss = 1.0938, Accuracy = 66.65%\n",
            "Batch 50: Loss = 0.8794, Accuracy = 66.85%\n",
            "Batch 60: Loss = 0.8851, Accuracy = 66.71%\n",
            "Batch 70: Loss = 0.9189, Accuracy = 66.51%\n",
            "Batch 80: Loss = 0.8784, Accuracy = 66.34%\n",
            "Batch 90: Loss = 0.8362, Accuracy = 66.47%\n",
            "Batch 100: Loss = 0.9712, Accuracy = 66.27%\n",
            "Batch 110: Loss = 0.8635, Accuracy = 66.27%\n",
            "Batch 120: Loss = 0.8079, Accuracy = 66.23%\n",
            "Batch 130: Loss = 0.8753, Accuracy = 66.38%\n",
            "Batch 140: Loss = 0.8348, Accuracy = 66.22%\n",
            "Batch 150: Loss = 0.9021, Accuracy = 66.09%\n",
            "Batch 160: Loss = 0.7646, Accuracy = 66.20%\n",
            "Batch 170: Loss = 0.8475, Accuracy = 66.19%\n",
            "Batch 180: Loss = 0.9601, Accuracy = 66.22%\n",
            "Batch 190: Loss = 0.8220, Accuracy = 66.15%\n",
            "Batch 200: Loss = 0.9214, Accuracy = 66.08%\n",
            "Batch 210: Loss = 0.8673, Accuracy = 66.18%\n",
            "Batch 220: Loss = 0.8354, Accuracy = 66.22%\n",
            "Batch 230: Loss = 0.8353, Accuracy = 66.28%\n",
            "Batch 240: Loss = 0.8459, Accuracy = 66.30%\n",
            "Batch 250: Loss = 0.9108, Accuracy = 66.23%\n",
            "Batch 260: Loss = 0.9570, Accuracy = 66.19%\n",
            "Batch 270: Loss = 0.8597, Accuracy = 66.20%\n",
            "Batch 280: Loss = 0.9044, Accuracy = 66.19%\n",
            "Batch 290: Loss = 0.9065, Accuracy = 66.25%\n",
            "Batch 300: Loss = 0.7193, Accuracy = 66.21%\n",
            "Batch 310: Loss = 0.7266, Accuracy = 66.18%\n",
            "Batch 320: Loss = 1.0554, Accuracy = 66.10%\n",
            "Batch 330: Loss = 0.9088, Accuracy = 66.09%\n",
            "Batch 340: Loss = 0.9026, Accuracy = 66.03%\n",
            "Batch 350: Loss = 1.0585, Accuracy = 65.99%\n",
            "Batch 360: Loss = 0.8889, Accuracy = 66.02%\n",
            "Batch 370: Loss = 0.9164, Accuracy = 66.01%\n",
            "Batch 380: Loss = 0.9764, Accuracy = 66.04%\n",
            "Batch 390: Loss = 0.5953, Accuracy = 66.05%\n",
            "Epoch 11: Total Loss = 0.9059, Total Accuracy = 66.05%\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "Batch 0: Benign Loss = 1.1004, Adversarial Loss = 1.1004\n",
            "Batch 10: Benign Loss = 1.2716, Adversarial Loss = 1.2716\n",
            "Batch 20: Benign Loss = 1.1971, Adversarial Loss = 1.1971\n",
            "Batch 30: Benign Loss = 1.2408, Adversarial Loss = 1.2408\n",
            "Batch 40: Benign Loss = 1.0742, Adversarial Loss = 1.0742\n",
            "Batch 50: Benign Loss = 1.1518, Adversarial Loss = 1.1518\n",
            "Batch 60: Benign Loss = 1.1313, Adversarial Loss = 1.1313\n",
            "Batch 70: Benign Loss = 1.1566, Adversarial Loss = 1.1566\n",
            "Batch 80: Benign Loss = 1.0236, Adversarial Loss = 1.0236\n",
            "Batch 90: Benign Loss = 1.1249, Adversarial Loss = 1.1249\n",
            "Epoch 11: Benign Accuracy = 12.03%, Adversarial Accuracy = 60.40%\n",
            "Benign Loss = 11.5310, Adversarial Loss = 1.1107\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "Batch 0: Loss = 0.9991, Accuracy = 64.84%\n",
            "Batch 10: Loss = 0.9077, Accuracy = 68.25%\n",
            "Batch 20: Loss = 0.9359, Accuracy = 68.04%\n",
            "Batch 30: Loss = 0.7117, Accuracy = 67.74%\n",
            "Batch 40: Loss = 0.9149, Accuracy = 68.12%\n",
            "Batch 50: Loss = 0.7793, Accuracy = 68.05%\n",
            "Batch 60: Loss = 0.9633, Accuracy = 68.02%\n",
            "Batch 70: Loss = 0.8136, Accuracy = 67.90%\n",
            "Batch 80: Loss = 0.9354, Accuracy = 67.72%\n",
            "Batch 90: Loss = 0.8193, Accuracy = 67.66%\n",
            "Batch 100: Loss = 0.9306, Accuracy = 67.74%\n",
            "Batch 110: Loss = 0.9834, Accuracy = 67.69%\n",
            "Batch 120: Loss = 0.8733, Accuracy = 67.68%\n",
            "Batch 130: Loss = 0.8894, Accuracy = 67.50%\n",
            "Batch 140: Loss = 0.8861, Accuracy = 67.49%\n",
            "Batch 150: Loss = 0.8837, Accuracy = 67.42%\n",
            "Batch 160: Loss = 0.8865, Accuracy = 67.19%\n",
            "Batch 170: Loss = 0.9492, Accuracy = 67.15%\n",
            "Batch 180: Loss = 0.9415, Accuracy = 67.15%\n",
            "Batch 190: Loss = 0.8316, Accuracy = 67.25%\n",
            "Batch 200: Loss = 0.9473, Accuracy = 67.16%\n",
            "Batch 210: Loss = 0.8116, Accuracy = 67.09%\n",
            "Batch 220: Loss = 0.9556, Accuracy = 66.99%\n",
            "Batch 230: Loss = 1.1395, Accuracy = 66.88%\n",
            "Batch 240: Loss = 0.8712, Accuracy = 66.94%\n",
            "Batch 250: Loss = 0.8835, Accuracy = 66.85%\n",
            "Batch 260: Loss = 0.8046, Accuracy = 66.85%\n",
            "Batch 270: Loss = 0.9779, Accuracy = 66.75%\n",
            "Batch 280: Loss = 0.9590, Accuracy = 66.76%\n",
            "Batch 290: Loss = 0.8536, Accuracy = 66.68%\n",
            "Batch 300: Loss = 1.0078, Accuracy = 66.65%\n",
            "Batch 310: Loss = 1.0363, Accuracy = 66.57%\n",
            "Batch 320: Loss = 0.9460, Accuracy = 66.60%\n",
            "Batch 330: Loss = 1.0359, Accuracy = 66.56%\n",
            "Batch 340: Loss = 1.0305, Accuracy = 66.53%\n",
            "Batch 350: Loss = 0.7715, Accuracy = 66.60%\n",
            "Batch 360: Loss = 0.7667, Accuracy = 66.61%\n",
            "Batch 370: Loss = 0.8953, Accuracy = 66.61%\n",
            "Batch 380: Loss = 0.8881, Accuracy = 66.61%\n",
            "Batch 390: Loss = 1.0000, Accuracy = 66.59%\n",
            "Epoch 12: Total Loss = 0.8919, Total Accuracy = 66.59%\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "Batch 0: Benign Loss = 1.2487, Adversarial Loss = 1.2487\n",
            "Batch 10: Benign Loss = 1.2037, Adversarial Loss = 1.2037\n",
            "Batch 20: Benign Loss = 1.3961, Adversarial Loss = 1.3961\n",
            "Batch 30: Benign Loss = 1.2764, Adversarial Loss = 1.2764\n",
            "Batch 40: Benign Loss = 1.1362, Adversarial Loss = 1.1362\n",
            "Batch 50: Benign Loss = 1.1754, Adversarial Loss = 1.1754\n",
            "Batch 60: Benign Loss = 1.3698, Adversarial Loss = 1.3698\n",
            "Batch 70: Benign Loss = 1.3034, Adversarial Loss = 1.3034\n",
            "Batch 80: Benign Loss = 1.1326, Adversarial Loss = 1.1326\n",
            "Batch 90: Benign Loss = 1.0528, Adversarial Loss = 1.0528\n",
            "Epoch 12: Benign Accuracy = 12.08%, Adversarial Accuracy = 58.95%\n",
            "Benign Loss = 18.6750, Adversarial Loss = 1.1810\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "Batch 0: Loss = 0.7700, Accuracy = 72.66%\n",
            "Batch 10: Loss = 0.9438, Accuracy = 69.32%\n",
            "Batch 20: Loss = 0.8263, Accuracy = 68.30%\n",
            "Batch 30: Loss = 0.8751, Accuracy = 68.02%\n",
            "Batch 40: Loss = 0.6926, Accuracy = 68.06%\n",
            "Batch 50: Loss = 1.0088, Accuracy = 68.09%\n",
            "Batch 60: Loss = 0.8508, Accuracy = 68.37%\n",
            "Batch 70: Loss = 0.7683, Accuracy = 68.12%\n",
            "Batch 80: Loss = 0.9233, Accuracy = 68.07%\n",
            "Batch 90: Loss = 0.9885, Accuracy = 67.99%\n",
            "Batch 100: Loss = 0.9318, Accuracy = 67.95%\n",
            "Batch 110: Loss = 0.9003, Accuracy = 67.82%\n",
            "Batch 120: Loss = 0.8038, Accuracy = 67.60%\n",
            "Batch 130: Loss = 0.9410, Accuracy = 67.55%\n",
            "Batch 140: Loss = 0.9358, Accuracy = 67.46%\n",
            "Batch 150: Loss = 1.0114, Accuracy = 67.45%\n",
            "Batch 160: Loss = 0.7702, Accuracy = 67.27%\n",
            "Batch 170: Loss = 0.9356, Accuracy = 67.10%\n",
            "Batch 180: Loss = 0.9551, Accuracy = 67.08%\n",
            "Batch 190: Loss = 0.8700, Accuracy = 67.07%\n",
            "Batch 200: Loss = 0.7577, Accuracy = 67.14%\n",
            "Batch 210: Loss = 0.7412, Accuracy = 67.13%\n",
            "Batch 220: Loss = 0.8747, Accuracy = 67.17%\n",
            "Batch 230: Loss = 0.9672, Accuracy = 67.05%\n",
            "Batch 240: Loss = 0.9177, Accuracy = 67.04%\n",
            "Batch 250: Loss = 0.9223, Accuracy = 67.08%\n",
            "Batch 260: Loss = 0.7512, Accuracy = 67.15%\n",
            "Batch 270: Loss = 1.1464, Accuracy = 67.04%\n",
            "Batch 280: Loss = 0.8666, Accuracy = 67.14%\n",
            "Batch 290: Loss = 0.9199, Accuracy = 67.09%\n",
            "Batch 300: Loss = 1.0044, Accuracy = 67.04%\n",
            "Batch 310: Loss = 0.8521, Accuracy = 67.08%\n",
            "Batch 320: Loss = 0.8371, Accuracy = 67.11%\n",
            "Batch 330: Loss = 0.7418, Accuracy = 66.99%\n",
            "Batch 340: Loss = 0.8843, Accuracy = 66.91%\n",
            "Batch 350: Loss = 0.9450, Accuracy = 66.91%\n",
            "Batch 360: Loss = 0.6925, Accuracy = 66.95%\n",
            "Batch 370: Loss = 0.9916, Accuracy = 66.99%\n",
            "Batch 380: Loss = 0.9476, Accuracy = 66.97%\n",
            "Batch 390: Loss = 0.9217, Accuracy = 66.98%\n",
            "Epoch 13: Total Loss = 0.8835, Total Accuracy = 66.98%\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "Batch 0: Benign Loss = 1.1456, Adversarial Loss = 1.1456\n",
            "Batch 10: Benign Loss = 1.4136, Adversarial Loss = 1.4136\n",
            "Batch 20: Benign Loss = 1.1080, Adversarial Loss = 1.1080\n",
            "Batch 30: Benign Loss = 1.2524, Adversarial Loss = 1.2524\n",
            "Batch 40: Benign Loss = 1.0691, Adversarial Loss = 1.0691\n",
            "Batch 50: Benign Loss = 1.2799, Adversarial Loss = 1.2799\n",
            "Batch 60: Benign Loss = 1.1208, Adversarial Loss = 1.1208\n",
            "Batch 70: Benign Loss = 1.3951, Adversarial Loss = 1.3951\n",
            "Batch 80: Benign Loss = 1.1087, Adversarial Loss = 1.1087\n",
            "Batch 90: Benign Loss = 1.1300, Adversarial Loss = 1.1300\n",
            "Epoch 13: Benign Accuracy = 10.49%, Adversarial Accuracy = 60.02%\n",
            "Benign Loss = 11.1896, Adversarial Loss = 1.1581\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "Batch 0: Loss = 0.8389, Accuracy = 70.31%\n",
            "Batch 10: Loss = 0.7890, Accuracy = 67.47%\n",
            "Batch 20: Loss = 0.8964, Accuracy = 67.11%\n",
            "Batch 30: Loss = 0.8121, Accuracy = 67.54%\n",
            "Batch 40: Loss = 0.9812, Accuracy = 67.95%\n",
            "Batch 50: Loss = 0.9120, Accuracy = 67.74%\n",
            "Batch 60: Loss = 0.9497, Accuracy = 67.43%\n",
            "Batch 70: Loss = 0.8676, Accuracy = 67.66%\n",
            "Batch 80: Loss = 0.7804, Accuracy = 67.81%\n",
            "Batch 90: Loss = 0.9458, Accuracy = 67.87%\n",
            "Batch 100: Loss = 0.8437, Accuracy = 67.58%\n",
            "Batch 110: Loss = 0.7917, Accuracy = 67.48%\n",
            "Batch 120: Loss = 0.9983, Accuracy = 67.31%\n",
            "Batch 130: Loss = 0.7981, Accuracy = 67.21%\n",
            "Batch 140: Loss = 0.8210, Accuracy = 67.14%\n",
            "Batch 150: Loss = 0.8063, Accuracy = 67.16%\n",
            "Batch 160: Loss = 0.7558, Accuracy = 67.21%\n",
            "Batch 170: Loss = 0.8715, Accuracy = 67.34%\n",
            "Batch 180: Loss = 0.9360, Accuracy = 67.38%\n",
            "Batch 190: Loss = 0.9587, Accuracy = 67.26%\n",
            "Batch 200: Loss = 1.0119, Accuracy = 67.25%\n",
            "Batch 210: Loss = 0.9933, Accuracy = 67.25%\n",
            "Batch 220: Loss = 0.8814, Accuracy = 67.15%\n",
            "Batch 230: Loss = 0.8689, Accuracy = 67.10%\n",
            "Batch 240: Loss = 0.8920, Accuracy = 67.18%\n",
            "Batch 250: Loss = 0.6958, Accuracy = 67.23%\n",
            "Batch 260: Loss = 0.8590, Accuracy = 67.28%\n",
            "Batch 270: Loss = 0.8732, Accuracy = 67.33%\n",
            "Batch 280: Loss = 0.8573, Accuracy = 67.28%\n",
            "Batch 290: Loss = 0.7857, Accuracy = 67.31%\n",
            "Batch 300: Loss = 0.8297, Accuracy = 67.27%\n",
            "Batch 310: Loss = 0.8084, Accuracy = 67.25%\n",
            "Batch 320: Loss = 0.8892, Accuracy = 67.29%\n",
            "Batch 330: Loss = 0.8825, Accuracy = 67.30%\n",
            "Batch 340: Loss = 0.8922, Accuracy = 67.30%\n",
            "Batch 350: Loss = 0.8596, Accuracy = 67.33%\n",
            "Batch 360: Loss = 0.8304, Accuracy = 67.34%\n",
            "Batch 370: Loss = 1.0900, Accuracy = 67.28%\n",
            "Batch 380: Loss = 0.7811, Accuracy = 67.31%\n",
            "Batch 390: Loss = 0.7411, Accuracy = 67.32%\n",
            "Epoch 14: Total Loss = 0.8727, Total Accuracy = 67.32%\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "Batch 0: Benign Loss = 1.0872, Adversarial Loss = 1.0872\n",
            "Batch 10: Benign Loss = 1.2143, Adversarial Loss = 1.2143\n",
            "Batch 20: Benign Loss = 1.1524, Adversarial Loss = 1.1524\n",
            "Batch 30: Benign Loss = 1.2433, Adversarial Loss = 1.2433\n",
            "Batch 40: Benign Loss = 1.0984, Adversarial Loss = 1.0984\n",
            "Batch 50: Benign Loss = 1.2886, Adversarial Loss = 1.2886\n",
            "Batch 60: Benign Loss = 1.2431, Adversarial Loss = 1.2431\n",
            "Batch 70: Benign Loss = 1.2845, Adversarial Loss = 1.2845\n",
            "Batch 80: Benign Loss = 1.0801, Adversarial Loss = 1.0801\n",
            "Batch 90: Benign Loss = 1.0542, Adversarial Loss = 1.0542\n",
            "Epoch 14: Benign Accuracy = 10.78%, Adversarial Accuracy = 59.49%\n",
            "Benign Loss = 23.1495, Adversarial Loss = 1.1557\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "Batch 0: Loss = 0.8193, Accuracy = 68.75%\n",
            "Batch 10: Loss = 0.7558, Accuracy = 69.89%\n",
            "Batch 20: Loss = 0.8825, Accuracy = 69.42%\n",
            "Batch 30: Loss = 0.7470, Accuracy = 69.38%\n",
            "Batch 40: Loss = 0.8557, Accuracy = 69.30%\n",
            "Batch 50: Loss = 0.8667, Accuracy = 69.30%\n",
            "Batch 60: Loss = 0.8099, Accuracy = 68.89%\n",
            "Batch 70: Loss = 0.8133, Accuracy = 68.43%\n",
            "Batch 80: Loss = 0.8799, Accuracy = 68.32%\n",
            "Batch 90: Loss = 0.7722, Accuracy = 68.15%\n",
            "Batch 100: Loss = 0.7981, Accuracy = 68.36%\n",
            "Batch 110: Loss = 0.9323, Accuracy = 68.59%\n",
            "Batch 120: Loss = 0.8498, Accuracy = 68.47%\n",
            "Batch 130: Loss = 0.8440, Accuracy = 68.35%\n",
            "Batch 140: Loss = 0.8216, Accuracy = 68.14%\n",
            "Batch 150: Loss = 0.9607, Accuracy = 68.16%\n",
            "Batch 160: Loss = 1.0354, Accuracy = 68.09%\n",
            "Batch 170: Loss = 0.7674, Accuracy = 68.17%\n",
            "Batch 180: Loss = 0.8682, Accuracy = 68.04%\n",
            "Batch 190: Loss = 0.6633, Accuracy = 68.11%\n",
            "Batch 200: Loss = 0.8006, Accuracy = 68.05%\n",
            "Batch 210: Loss = 1.0047, Accuracy = 68.03%\n",
            "Batch 220: Loss = 0.7037, Accuracy = 68.09%\n",
            "Batch 230: Loss = 0.7944, Accuracy = 68.02%\n",
            "Batch 240: Loss = 0.8153, Accuracy = 68.05%\n",
            "Batch 250: Loss = 0.8271, Accuracy = 67.97%\n",
            "Batch 260: Loss = 0.9139, Accuracy = 67.91%\n",
            "Batch 270: Loss = 0.8179, Accuracy = 67.90%\n",
            "Batch 280: Loss = 1.1193, Accuracy = 67.85%\n",
            "Batch 290: Loss = 0.7937, Accuracy = 67.81%\n",
            "Batch 300: Loss = 0.8240, Accuracy = 67.78%\n",
            "Batch 310: Loss = 0.7126, Accuracy = 67.78%\n",
            "Batch 320: Loss = 0.9776, Accuracy = 67.71%\n",
            "Batch 330: Loss = 0.8831, Accuracy = 67.68%\n",
            "Batch 340: Loss = 0.8192, Accuracy = 67.61%\n",
            "Batch 350: Loss = 0.7748, Accuracy = 67.69%\n",
            "Batch 360: Loss = 0.8005, Accuracy = 67.67%\n",
            "Batch 370: Loss = 0.8580, Accuracy = 67.62%\n",
            "Batch 380: Loss = 0.7585, Accuracy = 67.58%\n",
            "Batch 390: Loss = 0.8719, Accuracy = 67.54%\n",
            "Epoch 15: Total Loss = 0.8668, Total Accuracy = 67.54%\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "Batch 0: Benign Loss = 1.1405, Adversarial Loss = 1.1405\n",
            "Batch 10: Benign Loss = 1.2629, Adversarial Loss = 1.2629\n",
            "Batch 20: Benign Loss = 1.1544, Adversarial Loss = 1.1544\n",
            "Batch 30: Benign Loss = 1.4146, Adversarial Loss = 1.4146\n",
            "Batch 40: Benign Loss = 1.2672, Adversarial Loss = 1.2672\n",
            "Batch 50: Benign Loss = 1.2571, Adversarial Loss = 1.2571\n",
            "Batch 60: Benign Loss = 1.2666, Adversarial Loss = 1.2666\n",
            "Batch 70: Benign Loss = 1.2759, Adversarial Loss = 1.2759\n",
            "Batch 80: Benign Loss = 1.2815, Adversarial Loss = 1.2815\n",
            "Batch 90: Benign Loss = 1.2410, Adversarial Loss = 1.2410\n",
            "Epoch 15: Benign Accuracy = 11.67%, Adversarial Accuracy = 57.98%\n",
            "Benign Loss = 31.7210, Adversarial Loss = 1.2123\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "Batch 0: Loss = 0.9716, Accuracy = 67.19%\n",
            "Batch 10: Loss = 0.7615, Accuracy = 68.75%\n",
            "Batch 20: Loss = 0.8424, Accuracy = 68.30%\n",
            "Batch 30: Loss = 0.7509, Accuracy = 68.27%\n",
            "Batch 40: Loss = 0.9218, Accuracy = 68.27%\n",
            "Batch 50: Loss = 0.9574, Accuracy = 68.73%\n",
            "Batch 60: Loss = 0.7757, Accuracy = 68.39%\n",
            "Batch 70: Loss = 0.7478, Accuracy = 68.52%\n",
            "Batch 80: Loss = 0.8447, Accuracy = 68.54%\n",
            "Batch 90: Loss = 0.9799, Accuracy = 68.30%\n",
            "Batch 100: Loss = 0.6993, Accuracy = 68.22%\n",
            "Batch 110: Loss = 0.7472, Accuracy = 68.43%\n",
            "Batch 120: Loss = 0.9004, Accuracy = 68.40%\n",
            "Batch 130: Loss = 0.9079, Accuracy = 68.30%\n",
            "Batch 140: Loss = 0.8769, Accuracy = 68.12%\n",
            "Batch 150: Loss = 0.8218, Accuracy = 68.03%\n",
            "Batch 160: Loss = 0.8163, Accuracy = 68.01%\n",
            "Batch 170: Loss = 0.8838, Accuracy = 68.06%\n",
            "Batch 180: Loss = 0.9052, Accuracy = 68.12%\n",
            "Batch 190: Loss = 0.8257, Accuracy = 68.21%\n",
            "Batch 200: Loss = 0.8587, Accuracy = 68.30%\n",
            "Batch 210: Loss = 0.7535, Accuracy = 68.32%\n",
            "Batch 220: Loss = 0.8065, Accuracy = 68.23%\n",
            "Batch 230: Loss = 1.0213, Accuracy = 68.26%\n",
            "Batch 240: Loss = 0.8636, Accuracy = 68.13%\n",
            "Batch 250: Loss = 0.8537, Accuracy = 68.01%\n",
            "Batch 260: Loss = 0.8804, Accuracy = 68.01%\n",
            "Batch 270: Loss = 0.8839, Accuracy = 67.99%\n",
            "Batch 280: Loss = 0.9582, Accuracy = 68.00%\n",
            "Batch 290: Loss = 0.9589, Accuracy = 68.00%\n",
            "Batch 300: Loss = 0.7297, Accuracy = 68.00%\n",
            "Batch 310: Loss = 0.9846, Accuracy = 67.95%\n",
            "Batch 320: Loss = 0.8699, Accuracy = 67.91%\n",
            "Batch 330: Loss = 0.9433, Accuracy = 67.79%\n",
            "Batch 340: Loss = 0.9658, Accuracy = 67.73%\n",
            "Batch 350: Loss = 0.8698, Accuracy = 67.74%\n",
            "Batch 360: Loss = 0.9645, Accuracy = 67.70%\n",
            "Batch 370: Loss = 0.9076, Accuracy = 67.67%\n",
            "Batch 380: Loss = 1.2380, Accuracy = 67.62%\n",
            "Batch 390: Loss = 0.9178, Accuracy = 67.54%\n",
            "Epoch 16: Total Loss = 0.8605, Total Accuracy = 67.54%\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "Batch 0: Benign Loss = 1.2134, Adversarial Loss = 1.2134\n",
            "Batch 10: Benign Loss = 1.1278, Adversarial Loss = 1.1278\n",
            "Batch 20: Benign Loss = 1.1303, Adversarial Loss = 1.1303\n",
            "Batch 30: Benign Loss = 1.3566, Adversarial Loss = 1.3566\n",
            "Batch 40: Benign Loss = 1.0891, Adversarial Loss = 1.0891\n",
            "Batch 50: Benign Loss = 1.1973, Adversarial Loss = 1.1973\n",
            "Batch 60: Benign Loss = 1.1876, Adversarial Loss = 1.1876\n",
            "Batch 70: Benign Loss = 1.2694, Adversarial Loss = 1.2694\n",
            "Batch 80: Benign Loss = 1.1078, Adversarial Loss = 1.1078\n",
            "Batch 90: Benign Loss = 1.0930, Adversarial Loss = 1.0930\n",
            "Epoch 16: Benign Accuracy = 11.73%, Adversarial Accuracy = 58.31%\n",
            "Benign Loss = 36.1922, Adversarial Loss = 1.1787\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "Batch 0: Loss = 0.9536, Accuracy = 68.75%\n",
            "Batch 10: Loss = 0.8504, Accuracy = 70.45%\n",
            "Batch 20: Loss = 0.8834, Accuracy = 69.87%\n",
            "Batch 30: Loss = 0.7684, Accuracy = 69.00%\n",
            "Batch 40: Loss = 0.9234, Accuracy = 68.94%\n",
            "Batch 50: Loss = 0.8410, Accuracy = 68.96%\n",
            "Batch 60: Loss = 0.7359, Accuracy = 68.74%\n",
            "Batch 70: Loss = 0.7688, Accuracy = 68.67%\n",
            "Batch 80: Loss = 0.7943, Accuracy = 68.88%\n",
            "Batch 90: Loss = 0.9396, Accuracy = 68.60%\n",
            "Batch 100: Loss = 0.8141, Accuracy = 68.53%\n",
            "Batch 110: Loss = 0.8649, Accuracy = 68.43%\n",
            "Batch 120: Loss = 0.7213, Accuracy = 68.45%\n",
            "Batch 130: Loss = 0.7982, Accuracy = 68.49%\n",
            "Batch 140: Loss = 0.8261, Accuracy = 68.36%\n",
            "Batch 150: Loss = 1.1543, Accuracy = 68.37%\n",
            "Batch 160: Loss = 0.8900, Accuracy = 68.35%\n",
            "Batch 170: Loss = 0.9083, Accuracy = 68.32%\n",
            "Batch 180: Loss = 0.9562, Accuracy = 68.31%\n",
            "Batch 190: Loss = 0.9691, Accuracy = 68.19%\n",
            "Batch 200: Loss = 0.8086, Accuracy = 68.26%\n",
            "Batch 210: Loss = 0.7380, Accuracy = 68.16%\n",
            "Batch 220: Loss = 0.7911, Accuracy = 68.10%\n",
            "Batch 230: Loss = 0.9119, Accuracy = 68.09%\n",
            "Batch 240: Loss = 0.8780, Accuracy = 68.02%\n",
            "Batch 250: Loss = 0.9694, Accuracy = 68.02%\n",
            "Batch 260: Loss = 0.7633, Accuracy = 68.15%\n",
            "Batch 270: Loss = 0.8540, Accuracy = 68.24%\n",
            "Batch 280: Loss = 0.8500, Accuracy = 68.24%\n",
            "Batch 290: Loss = 0.8333, Accuracy = 68.23%\n",
            "Batch 300: Loss = 0.6506, Accuracy = 68.37%\n",
            "Batch 310: Loss = 0.8569, Accuracy = 68.35%\n",
            "Batch 320: Loss = 0.9311, Accuracy = 68.31%\n",
            "Batch 330: Loss = 0.8348, Accuracy = 68.30%\n",
            "Batch 340: Loss = 0.9117, Accuracy = 68.32%\n",
            "Batch 350: Loss = 0.7897, Accuracy = 68.31%\n",
            "Batch 360: Loss = 0.7631, Accuracy = 68.33%\n",
            "Batch 370: Loss = 0.8550, Accuracy = 68.33%\n",
            "Batch 380: Loss = 0.8370, Accuracy = 68.31%\n",
            "Batch 390: Loss = 0.8839, Accuracy = 68.29%\n",
            "Epoch 17: Total Loss = 0.8489, Total Accuracy = 68.29%\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "Batch 0: Benign Loss = 1.2428, Adversarial Loss = 1.2428\n",
            "Batch 10: Benign Loss = 1.2872, Adversarial Loss = 1.2872\n",
            "Batch 20: Benign Loss = 1.3427, Adversarial Loss = 1.3427\n",
            "Batch 30: Benign Loss = 1.3069, Adversarial Loss = 1.3069\n",
            "Batch 40: Benign Loss = 1.2159, Adversarial Loss = 1.2159\n",
            "Batch 50: Benign Loss = 1.2306, Adversarial Loss = 1.2306\n",
            "Batch 60: Benign Loss = 1.3102, Adversarial Loss = 1.3102\n",
            "Batch 70: Benign Loss = 1.3993, Adversarial Loss = 1.3993\n",
            "Batch 80: Benign Loss = 1.1929, Adversarial Loss = 1.1929\n",
            "Batch 90: Benign Loss = 1.1578, Adversarial Loss = 1.1578\n",
            "Epoch 17: Benign Accuracy = 11.05%, Adversarial Accuracy = 59.90%\n",
            "Benign Loss = 15.0160, Adversarial Loss = 1.2039\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "Batch 0: Loss = 0.8358, Accuracy = 70.31%\n",
            "Batch 10: Loss = 0.7596, Accuracy = 69.96%\n",
            "Batch 20: Loss = 0.8410, Accuracy = 70.42%\n",
            "Batch 30: Loss = 0.7718, Accuracy = 69.83%\n",
            "Batch 40: Loss = 0.8855, Accuracy = 70.08%\n",
            "Batch 50: Loss = 0.8520, Accuracy = 69.65%\n",
            "Batch 60: Loss = 0.7136, Accuracy = 69.94%\n",
            "Batch 70: Loss = 0.9420, Accuracy = 69.64%\n",
            "Batch 80: Loss = 0.9228, Accuracy = 69.61%\n",
            "Batch 90: Loss = 0.8979, Accuracy = 69.41%\n",
            "Batch 100: Loss = 0.8178, Accuracy = 69.22%\n",
            "Batch 110: Loss = 0.8700, Accuracy = 69.24%\n",
            "Batch 120: Loss = 0.8232, Accuracy = 69.17%\n",
            "Batch 130: Loss = 0.9947, Accuracy = 68.98%\n",
            "Batch 140: Loss = 0.7858, Accuracy = 69.09%\n",
            "Batch 150: Loss = 0.8068, Accuracy = 69.20%\n",
            "Batch 160: Loss = 0.8374, Accuracy = 69.12%\n",
            "Batch 170: Loss = 0.8632, Accuracy = 69.17%\n",
            "Batch 180: Loss = 0.8701, Accuracy = 69.13%\n",
            "Batch 190: Loss = 0.8485, Accuracy = 69.23%\n",
            "Batch 200: Loss = 0.9515, Accuracy = 69.20%\n",
            "Batch 210: Loss = 0.8183, Accuracy = 69.20%\n",
            "Batch 220: Loss = 1.0107, Accuracy = 69.20%\n",
            "Batch 230: Loss = 0.8742, Accuracy = 69.08%\n",
            "Batch 240: Loss = 0.9137, Accuracy = 69.00%\n",
            "Batch 250: Loss = 1.0076, Accuracy = 68.96%\n",
            "Batch 260: Loss = 0.8966, Accuracy = 68.98%\n",
            "Batch 270: Loss = 0.6866, Accuracy = 68.97%\n",
            "Batch 280: Loss = 0.7592, Accuracy = 68.99%\n",
            "Batch 290: Loss = 0.7455, Accuracy = 68.96%\n",
            "Batch 300: Loss = 0.7221, Accuracy = 68.93%\n",
            "Batch 310: Loss = 0.8724, Accuracy = 68.93%\n",
            "Batch 320: Loss = 0.9906, Accuracy = 68.95%\n",
            "Batch 330: Loss = 0.9469, Accuracy = 68.95%\n",
            "Batch 340: Loss = 0.7709, Accuracy = 68.91%\n",
            "Batch 350: Loss = 0.7733, Accuracy = 68.89%\n",
            "Batch 360: Loss = 0.7469, Accuracy = 68.90%\n",
            "Batch 370: Loss = 0.9486, Accuracy = 68.78%\n",
            "Batch 380: Loss = 1.0454, Accuracy = 68.75%\n",
            "Batch 390: Loss = 0.8452, Accuracy = 68.70%\n",
            "Epoch 18: Total Loss = 0.8336, Total Accuracy = 68.70%\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "Batch 0: Benign Loss = 1.0724, Adversarial Loss = 1.0724\n",
            "Batch 10: Benign Loss = 1.1644, Adversarial Loss = 1.1644\n",
            "Batch 20: Benign Loss = 1.0991, Adversarial Loss = 1.0991\n",
            "Batch 30: Benign Loss = 1.2946, Adversarial Loss = 1.2946\n",
            "Batch 40: Benign Loss = 1.1254, Adversarial Loss = 1.1254\n",
            "Batch 50: Benign Loss = 1.2996, Adversarial Loss = 1.2996\n",
            "Batch 60: Benign Loss = 1.2189, Adversarial Loss = 1.2189\n",
            "Batch 70: Benign Loss = 1.3005, Adversarial Loss = 1.3005\n",
            "Batch 80: Benign Loss = 0.9937, Adversarial Loss = 0.9937\n",
            "Batch 90: Benign Loss = 1.0704, Adversarial Loss = 1.0704\n",
            "Epoch 18: Benign Accuracy = 11.82%, Adversarial Accuracy = 60.89%\n",
            "Benign Loss = 23.5948, Adversarial Loss = 1.1302\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "Batch 0: Loss = 0.8825, Accuracy = 65.62%\n",
            "Batch 10: Loss = 0.7007, Accuracy = 71.80%\n",
            "Batch 20: Loss = 0.6550, Accuracy = 71.39%\n",
            "Batch 30: Loss = 0.7840, Accuracy = 71.07%\n",
            "Batch 40: Loss = 0.7555, Accuracy = 71.11%\n",
            "Batch 50: Loss = 0.7721, Accuracy = 71.06%\n",
            "Batch 60: Loss = 0.7728, Accuracy = 71.11%\n",
            "Batch 70: Loss = 0.8736, Accuracy = 70.96%\n",
            "Batch 80: Loss = 0.6961, Accuracy = 71.05%\n",
            "Batch 90: Loss = 0.8023, Accuracy = 70.81%\n",
            "Batch 100: Loss = 0.8296, Accuracy = 70.68%\n",
            "Batch 110: Loss = 0.8047, Accuracy = 70.69%\n",
            "Batch 120: Loss = 0.8139, Accuracy = 70.54%\n",
            "Batch 130: Loss = 0.8818, Accuracy = 70.33%\n",
            "Batch 140: Loss = 0.8872, Accuracy = 70.07%\n",
            "Batch 150: Loss = 0.7219, Accuracy = 69.99%\n",
            "Batch 160: Loss = 0.9679, Accuracy = 69.99%\n",
            "Batch 170: Loss = 1.0069, Accuracy = 69.81%\n",
            "Batch 180: Loss = 0.8645, Accuracy = 69.64%\n",
            "Batch 190: Loss = 0.8153, Accuracy = 69.67%\n",
            "Batch 200: Loss = 0.8133, Accuracy = 69.53%\n",
            "Batch 210: Loss = 0.7222, Accuracy = 69.47%\n",
            "Batch 220: Loss = 0.8181, Accuracy = 69.47%\n",
            "Batch 230: Loss = 0.8725, Accuracy = 69.50%\n",
            "Batch 240: Loss = 0.9291, Accuracy = 69.38%\n",
            "Batch 250: Loss = 0.9061, Accuracy = 69.34%\n",
            "Batch 260: Loss = 0.8907, Accuracy = 69.29%\n",
            "Batch 270: Loss = 1.0680, Accuracy = 69.23%\n",
            "Batch 280: Loss = 0.7323, Accuracy = 69.23%\n",
            "Batch 290: Loss = 0.8481, Accuracy = 69.17%\n",
            "Batch 300: Loss = 0.7145, Accuracy = 69.17%\n",
            "Batch 310: Loss = 0.8131, Accuracy = 69.18%\n",
            "Batch 320: Loss = 0.8041, Accuracy = 69.27%\n",
            "Batch 330: Loss = 0.7909, Accuracy = 69.20%\n",
            "Batch 340: Loss = 0.7547, Accuracy = 69.16%\n",
            "Batch 350: Loss = 0.9698, Accuracy = 69.07%\n",
            "Batch 360: Loss = 0.8828, Accuracy = 68.99%\n",
            "Batch 370: Loss = 0.9369, Accuracy = 69.00%\n",
            "Batch 380: Loss = 0.8794, Accuracy = 68.90%\n",
            "Batch 390: Loss = 0.9416, Accuracy = 68.90%\n",
            "Epoch 19: Total Loss = 0.8291, Total Accuracy = 68.90%\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "Batch 0: Benign Loss = 1.1232, Adversarial Loss = 1.1232\n",
            "Batch 10: Benign Loss = 1.2375, Adversarial Loss = 1.2375\n",
            "Batch 20: Benign Loss = 1.1518, Adversarial Loss = 1.1518\n",
            "Batch 30: Benign Loss = 1.2529, Adversarial Loss = 1.2529\n",
            "Batch 40: Benign Loss = 1.0271, Adversarial Loss = 1.0271\n",
            "Batch 50: Benign Loss = 1.1572, Adversarial Loss = 1.1572\n",
            "Batch 60: Benign Loss = 1.1828, Adversarial Loss = 1.1828\n",
            "Batch 70: Benign Loss = 1.2516, Adversarial Loss = 1.2516\n",
            "Batch 80: Benign Loss = 0.9569, Adversarial Loss = 0.9569\n",
            "Batch 90: Benign Loss = 1.0966, Adversarial Loss = 1.0966\n",
            "Epoch 19: Benign Accuracy = 11.28%, Adversarial Accuracy = 61.29%\n",
            "Benign Loss = 28.6818, Adversarial Loss = 1.1171\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "Batch 0: Loss = 0.7895, Accuracy = 68.75%\n",
            "Batch 10: Loss = 0.7793, Accuracy = 72.44%\n",
            "Batch 20: Loss = 0.8587, Accuracy = 72.14%\n",
            "Batch 30: Loss = 0.7895, Accuracy = 71.37%\n",
            "Batch 40: Loss = 0.6746, Accuracy = 71.30%\n",
            "Batch 50: Loss = 0.7045, Accuracy = 70.77%\n",
            "Batch 60: Loss = 0.6492, Accuracy = 70.47%\n",
            "Batch 70: Loss = 0.8033, Accuracy = 70.57%\n",
            "Batch 80: Loss = 0.8857, Accuracy = 70.53%\n",
            "Batch 90: Loss = 0.8141, Accuracy = 70.61%\n",
            "Batch 100: Loss = 0.8488, Accuracy = 70.39%\n",
            "Batch 110: Loss = 0.8868, Accuracy = 70.15%\n",
            "Batch 120: Loss = 0.7808, Accuracy = 70.19%\n",
            "Batch 130: Loss = 0.6581, Accuracy = 70.06%\n",
            "Batch 140: Loss = 0.7284, Accuracy = 70.05%\n",
            "Batch 150: Loss = 0.8703, Accuracy = 69.91%\n",
            "Batch 160: Loss = 0.9233, Accuracy = 69.83%\n",
            "Batch 170: Loss = 0.9323, Accuracy = 69.76%\n",
            "Batch 180: Loss = 0.7983, Accuracy = 69.70%\n",
            "Batch 190: Loss = 0.7938, Accuracy = 69.71%\n",
            "Batch 200: Loss = 0.8564, Accuracy = 69.79%\n",
            "Batch 210: Loss = 0.7921, Accuracy = 69.81%\n",
            "Batch 220: Loss = 0.7687, Accuracy = 69.88%\n",
            "Batch 230: Loss = 0.9760, Accuracy = 69.81%\n",
            "Batch 240: Loss = 0.8494, Accuracy = 69.71%\n",
            "Batch 250: Loss = 0.6526, Accuracy = 69.67%\n",
            "Batch 260: Loss = 0.7505, Accuracy = 69.73%\n",
            "Batch 270: Loss = 0.7893, Accuracy = 69.68%\n",
            "Batch 280: Loss = 0.8715, Accuracy = 69.62%\n",
            "Batch 290: Loss = 0.8381, Accuracy = 69.49%\n",
            "Batch 300: Loss = 1.0143, Accuracy = 69.41%\n",
            "Batch 310: Loss = 0.8482, Accuracy = 69.34%\n",
            "Batch 320: Loss = 0.7643, Accuracy = 69.34%\n",
            "Batch 330: Loss = 0.7305, Accuracy = 69.31%\n",
            "Batch 340: Loss = 0.8177, Accuracy = 69.28%\n",
            "Batch 350: Loss = 0.9850, Accuracy = 69.24%\n",
            "Batch 360: Loss = 1.0262, Accuracy = 69.22%\n",
            "Batch 370: Loss = 0.8343, Accuracy = 69.15%\n",
            "Batch 380: Loss = 0.7390, Accuracy = 69.15%\n",
            "Batch 390: Loss = 0.8157, Accuracy = 69.14%\n",
            "Epoch 20: Total Loss = 0.8203, Total Accuracy = 69.14%\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "Batch 0: Benign Loss = 1.2350, Adversarial Loss = 1.2350\n",
            "Batch 10: Benign Loss = 1.2238, Adversarial Loss = 1.2238\n",
            "Batch 20: Benign Loss = 1.1971, Adversarial Loss = 1.1971\n",
            "Batch 30: Benign Loss = 1.2689, Adversarial Loss = 1.2689\n",
            "Batch 40: Benign Loss = 1.1146, Adversarial Loss = 1.1146\n",
            "Batch 50: Benign Loss = 1.2910, Adversarial Loss = 1.2910\n",
            "Batch 60: Benign Loss = 1.2200, Adversarial Loss = 1.2200\n",
            "Batch 70: Benign Loss = 1.3340, Adversarial Loss = 1.3340\n",
            "Batch 80: Benign Loss = 1.1129, Adversarial Loss = 1.1129\n",
            "Batch 90: Benign Loss = 1.1648, Adversarial Loss = 1.1648\n",
            "Epoch 20: Benign Accuracy = 11.31%, Adversarial Accuracy = 61.10%\n",
            "Benign Loss = 25.1488, Adversarial Loss = 1.1519\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "Batch 0: Loss = 0.8144, Accuracy = 67.97%\n",
            "Batch 10: Loss = 0.7126, Accuracy = 71.80%\n",
            "Batch 20: Loss = 0.7712, Accuracy = 71.17%\n",
            "Batch 30: Loss = 0.7884, Accuracy = 71.45%\n",
            "Batch 40: Loss = 0.8163, Accuracy = 70.98%\n",
            "Batch 50: Loss = 0.8037, Accuracy = 70.89%\n",
            "Batch 60: Loss = 0.7214, Accuracy = 70.97%\n",
            "Batch 70: Loss = 0.6504, Accuracy = 70.98%\n",
            "Batch 80: Loss = 0.8395, Accuracy = 70.75%\n",
            "Batch 90: Loss = 0.8231, Accuracy = 70.52%\n",
            "Batch 100: Loss = 0.8321, Accuracy = 70.68%\n",
            "Batch 110: Loss = 0.8714, Accuracy = 70.53%\n",
            "Batch 120: Loss = 0.6723, Accuracy = 70.47%\n",
            "Batch 130: Loss = 0.8221, Accuracy = 70.40%\n",
            "Batch 140: Loss = 0.8350, Accuracy = 70.29%\n",
            "Batch 150: Loss = 0.8014, Accuracy = 70.14%\n",
            "Batch 160: Loss = 0.8605, Accuracy = 70.14%\n",
            "Batch 170: Loss = 0.7713, Accuracy = 70.11%\n",
            "Batch 180: Loss = 1.0154, Accuracy = 69.97%\n",
            "Batch 190: Loss = 0.7549, Accuracy = 69.74%\n",
            "Batch 200: Loss = 0.8936, Accuracy = 69.79%\n",
            "Batch 210: Loss = 0.8137, Accuracy = 69.84%\n",
            "Batch 220: Loss = 0.8219, Accuracy = 69.79%\n",
            "Batch 230: Loss = 0.8575, Accuracy = 69.85%\n",
            "Batch 240: Loss = 0.8516, Accuracy = 69.79%\n",
            "Batch 250: Loss = 0.9452, Accuracy = 69.75%\n",
            "Batch 260: Loss = 0.8264, Accuracy = 69.70%\n",
            "Batch 270: Loss = 0.8935, Accuracy = 69.64%\n",
            "Batch 280: Loss = 0.8387, Accuracy = 69.65%\n",
            "Batch 290: Loss = 0.7659, Accuracy = 69.58%\n",
            "Batch 300: Loss = 0.7627, Accuracy = 69.58%\n",
            "Batch 310: Loss = 0.7917, Accuracy = 69.59%\n",
            "Batch 320: Loss = 0.8428, Accuracy = 69.65%\n",
            "Batch 330: Loss = 0.8682, Accuracy = 69.61%\n",
            "Batch 340: Loss = 0.8323, Accuracy = 69.61%\n",
            "Batch 350: Loss = 0.8254, Accuracy = 69.54%\n",
            "Batch 360: Loss = 0.8727, Accuracy = 69.52%\n",
            "Batch 370: Loss = 0.8089, Accuracy = 69.47%\n",
            "Batch 380: Loss = 1.0169, Accuracy = 69.39%\n",
            "Batch 390: Loss = 0.7545, Accuracy = 69.43%\n",
            "Epoch 21: Total Loss = 0.8131, Total Accuracy = 69.43%\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "Batch 0: Benign Loss = 1.1176, Adversarial Loss = 1.1176\n",
            "Batch 10: Benign Loss = 1.1293, Adversarial Loss = 1.1293\n",
            "Batch 20: Benign Loss = 1.0946, Adversarial Loss = 1.0946\n",
            "Batch 30: Benign Loss = 1.3798, Adversarial Loss = 1.3798\n",
            "Batch 40: Benign Loss = 1.1706, Adversarial Loss = 1.1706\n",
            "Batch 50: Benign Loss = 1.2510, Adversarial Loss = 1.2510\n",
            "Batch 60: Benign Loss = 1.2306, Adversarial Loss = 1.2306\n",
            "Batch 70: Benign Loss = 1.4862, Adversarial Loss = 1.4862\n",
            "Batch 80: Benign Loss = 1.2075, Adversarial Loss = 1.2075\n",
            "Batch 90: Benign Loss = 1.2341, Adversarial Loss = 1.2341\n",
            "Epoch 21: Benign Accuracy = 10.55%, Adversarial Accuracy = 59.82%\n",
            "Benign Loss = 16.1797, Adversarial Loss = 1.1879\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "Batch 0: Loss = 0.6964, Accuracy = 71.88%\n",
            "Batch 10: Loss = 0.6852, Accuracy = 71.45%\n",
            "Batch 20: Loss = 0.8417, Accuracy = 71.28%\n",
            "Batch 30: Loss = 0.8786, Accuracy = 71.09%\n",
            "Batch 40: Loss = 0.8114, Accuracy = 70.56%\n",
            "Batch 50: Loss = 0.6856, Accuracy = 70.82%\n",
            "Batch 60: Loss = 0.8230, Accuracy = 70.67%\n",
            "Batch 70: Loss = 0.8247, Accuracy = 70.50%\n",
            "Batch 80: Loss = 0.7411, Accuracy = 70.67%\n",
            "Batch 90: Loss = 0.8163, Accuracy = 70.54%\n",
            "Batch 100: Loss = 0.8077, Accuracy = 70.50%\n",
            "Batch 110: Loss = 0.7544, Accuracy = 70.55%\n",
            "Batch 120: Loss = 0.7663, Accuracy = 70.69%\n",
            "Batch 130: Loss = 0.8275, Accuracy = 70.57%\n",
            "Batch 140: Loss = 0.7985, Accuracy = 70.58%\n",
            "Batch 150: Loss = 0.7607, Accuracy = 70.52%\n",
            "Batch 160: Loss = 0.7660, Accuracy = 70.55%\n",
            "Batch 170: Loss = 0.8677, Accuracy = 70.50%\n",
            "Batch 180: Loss = 0.8670, Accuracy = 70.47%\n",
            "Batch 190: Loss = 0.9230, Accuracy = 70.46%\n",
            "Batch 200: Loss = 0.9409, Accuracy = 70.33%\n",
            "Batch 210: Loss = 0.7176, Accuracy = 70.33%\n",
            "Batch 220: Loss = 0.8459, Accuracy = 70.26%\n",
            "Batch 230: Loss = 0.8086, Accuracy = 70.19%\n",
            "Batch 240: Loss = 0.9931, Accuracy = 70.11%\n",
            "Batch 250: Loss = 0.7055, Accuracy = 70.11%\n",
            "Batch 260: Loss = 0.7246, Accuracy = 70.09%\n",
            "Batch 270: Loss = 0.8417, Accuracy = 70.08%\n",
            "Batch 280: Loss = 0.6935, Accuracy = 70.13%\n",
            "Batch 290: Loss = 1.0287, Accuracy = 70.08%\n",
            "Batch 300: Loss = 0.7419, Accuracy = 70.07%\n",
            "Batch 310: Loss = 0.9366, Accuracy = 69.92%\n",
            "Batch 320: Loss = 0.8393, Accuracy = 69.85%\n",
            "Batch 330: Loss = 0.7036, Accuracy = 69.88%\n",
            "Batch 340: Loss = 0.7864, Accuracy = 69.93%\n",
            "Batch 350: Loss = 0.8032, Accuracy = 70.02%\n",
            "Batch 360: Loss = 0.8627, Accuracy = 69.99%\n",
            "Batch 370: Loss = 0.9620, Accuracy = 69.92%\n",
            "Batch 380: Loss = 0.7895, Accuracy = 69.89%\n",
            "Batch 390: Loss = 0.6568, Accuracy = 69.85%\n",
            "Epoch 22: Total Loss = 0.7965, Total Accuracy = 69.85%\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "Batch 0: Benign Loss = 1.2134, Adversarial Loss = 1.2134\n",
            "Batch 10: Benign Loss = 1.3673, Adversarial Loss = 1.3673\n",
            "Batch 20: Benign Loss = 1.2147, Adversarial Loss = 1.2147\n",
            "Batch 30: Benign Loss = 1.4996, Adversarial Loss = 1.4996\n",
            "Batch 40: Benign Loss = 1.0869, Adversarial Loss = 1.0869\n",
            "Batch 50: Benign Loss = 1.2492, Adversarial Loss = 1.2492\n",
            "Batch 60: Benign Loss = 1.2455, Adversarial Loss = 1.2455\n",
            "Batch 70: Benign Loss = 1.4822, Adversarial Loss = 1.4822\n",
            "Batch 80: Benign Loss = 1.1574, Adversarial Loss = 1.1574\n",
            "Batch 90: Benign Loss = 1.1109, Adversarial Loss = 1.1109\n",
            "Epoch 22: Benign Accuracy = 10.96%, Adversarial Accuracy = 60.30%\n",
            "Benign Loss = 16.7511, Adversarial Loss = 1.1788\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "Batch 0: Loss = 0.8194, Accuracy = 64.84%\n",
            "Batch 10: Loss = 0.7746, Accuracy = 71.02%\n",
            "Batch 20: Loss = 0.8281, Accuracy = 70.31%\n",
            "Batch 30: Loss = 0.7237, Accuracy = 70.74%\n",
            "Batch 40: Loss = 0.6566, Accuracy = 71.06%\n",
            "Batch 50: Loss = 0.8071, Accuracy = 71.35%\n",
            "Batch 60: Loss = 0.7624, Accuracy = 70.74%\n",
            "Batch 70: Loss = 0.7631, Accuracy = 70.93%\n",
            "Batch 80: Loss = 0.6839, Accuracy = 71.07%\n",
            "Batch 90: Loss = 0.7914, Accuracy = 70.81%\n",
            "Batch 100: Loss = 0.7502, Accuracy = 70.85%\n",
            "Batch 110: Loss = 0.7705, Accuracy = 70.85%\n",
            "Batch 120: Loss = 0.6732, Accuracy = 70.76%\n",
            "Batch 130: Loss = 0.6746, Accuracy = 70.59%\n",
            "Batch 140: Loss = 0.6914, Accuracy = 70.64%\n",
            "Batch 150: Loss = 0.7374, Accuracy = 70.57%\n",
            "Batch 160: Loss = 0.7805, Accuracy = 70.58%\n",
            "Batch 170: Loss = 0.8167, Accuracy = 70.57%\n",
            "Batch 180: Loss = 0.7132, Accuracy = 70.65%\n",
            "Batch 190: Loss = 0.6266, Accuracy = 70.52%\n",
            "Batch 200: Loss = 0.7620, Accuracy = 70.49%\n",
            "Batch 210: Loss = 0.7407, Accuracy = 70.35%\n",
            "Batch 220: Loss = 0.7734, Accuracy = 70.27%\n",
            "Batch 230: Loss = 0.6610, Accuracy = 70.35%\n",
            "Batch 240: Loss = 0.7426, Accuracy = 70.35%\n",
            "Batch 250: Loss = 0.8827, Accuracy = 70.34%\n",
            "Batch 260: Loss = 0.7574, Accuracy = 70.31%\n",
            "Batch 270: Loss = 0.9649, Accuracy = 70.15%\n",
            "Batch 280: Loss = 0.9270, Accuracy = 70.07%\n",
            "Batch 290: Loss = 0.6383, Accuracy = 70.14%\n",
            "Batch 300: Loss = 0.8761, Accuracy = 70.05%\n",
            "Batch 310: Loss = 0.8800, Accuracy = 70.01%\n",
            "Batch 320: Loss = 0.7989, Accuracy = 70.00%\n",
            "Batch 330: Loss = 0.8283, Accuracy = 69.95%\n",
            "Batch 340: Loss = 0.7990, Accuracy = 69.92%\n",
            "Batch 350: Loss = 0.6680, Accuracy = 69.87%\n",
            "Batch 360: Loss = 0.8386, Accuracy = 69.83%\n",
            "Batch 370: Loss = 0.8490, Accuracy = 69.86%\n",
            "Batch 380: Loss = 0.7650, Accuracy = 69.86%\n",
            "Batch 390: Loss = 1.0029, Accuracy = 69.85%\n",
            "Epoch 23: Total Loss = 0.7961, Total Accuracy = 69.85%\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "Batch 0: Benign Loss = 1.0799, Adversarial Loss = 1.0799\n",
            "Batch 10: Benign Loss = 1.1806, Adversarial Loss = 1.1806\n",
            "Batch 20: Benign Loss = 1.2580, Adversarial Loss = 1.2580\n",
            "Batch 30: Benign Loss = 1.1820, Adversarial Loss = 1.1820\n",
            "Batch 40: Benign Loss = 1.1224, Adversarial Loss = 1.1224\n",
            "Batch 50: Benign Loss = 1.3202, Adversarial Loss = 1.3202\n",
            "Batch 60: Benign Loss = 1.2721, Adversarial Loss = 1.2721\n",
            "Batch 70: Benign Loss = 1.3375, Adversarial Loss = 1.3375\n",
            "Batch 80: Benign Loss = 1.0466, Adversarial Loss = 1.0466\n",
            "Batch 90: Benign Loss = 1.0924, Adversarial Loss = 1.0924\n",
            "Epoch 23: Benign Accuracy = 10.90%, Adversarial Accuracy = 60.44%\n",
            "Benign Loss = 30.1480, Adversarial Loss = 1.1481\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "Batch 0: Loss = 0.6457, Accuracy = 75.78%\n",
            "Batch 10: Loss = 0.7311, Accuracy = 72.51%\n",
            "Batch 20: Loss = 0.6521, Accuracy = 72.06%\n",
            "Batch 30: Loss = 0.7665, Accuracy = 71.75%\n",
            "Batch 40: Loss = 0.7151, Accuracy = 71.74%\n",
            "Batch 50: Loss = 0.6278, Accuracy = 71.40%\n",
            "Batch 60: Loss = 0.6083, Accuracy = 71.76%\n",
            "Batch 70: Loss = 0.9180, Accuracy = 71.49%\n",
            "Batch 80: Loss = 0.7487, Accuracy = 71.29%\n",
            "Batch 90: Loss = 0.9902, Accuracy = 71.37%\n",
            "Batch 100: Loss = 0.7221, Accuracy = 71.14%\n",
            "Batch 110: Loss = 0.7877, Accuracy = 71.15%\n",
            "Batch 120: Loss = 0.7445, Accuracy = 71.03%\n",
            "Batch 130: Loss = 0.7949, Accuracy = 70.88%\n",
            "Batch 140: Loss = 0.9287, Accuracy = 70.92%\n",
            "Batch 150: Loss = 0.7528, Accuracy = 70.90%\n",
            "Batch 160: Loss = 0.7588, Accuracy = 70.81%\n",
            "Batch 170: Loss = 0.8809, Accuracy = 70.66%\n",
            "Batch 180: Loss = 0.8476, Accuracy = 70.81%\n",
            "Batch 190: Loss = 0.7216, Accuracy = 70.77%\n",
            "Batch 200: Loss = 0.7877, Accuracy = 70.79%\n",
            "Batch 210: Loss = 0.8945, Accuracy = 70.73%\n",
            "Batch 220: Loss = 0.9527, Accuracy = 70.62%\n",
            "Batch 230: Loss = 0.7049, Accuracy = 70.53%\n",
            "Batch 240: Loss = 0.7613, Accuracy = 70.45%\n",
            "Batch 250: Loss = 0.7792, Accuracy = 70.47%\n",
            "Batch 260: Loss = 0.8330, Accuracy = 70.48%\n",
            "Batch 270: Loss = 0.7359, Accuracy = 70.38%\n",
            "Batch 280: Loss = 0.7314, Accuracy = 70.41%\n",
            "Batch 290: Loss = 0.8098, Accuracy = 70.46%\n",
            "Batch 300: Loss = 0.7562, Accuracy = 70.37%\n",
            "Batch 310: Loss = 0.9359, Accuracy = 70.30%\n",
            "Batch 320: Loss = 0.8815, Accuracy = 70.24%\n",
            "Batch 330: Loss = 0.8915, Accuracy = 70.23%\n",
            "Batch 340: Loss = 0.8192, Accuracy = 70.27%\n",
            "Batch 350: Loss = 0.7852, Accuracy = 70.27%\n",
            "Batch 360: Loss = 0.9038, Accuracy = 70.29%\n",
            "Batch 370: Loss = 0.8259, Accuracy = 70.22%\n",
            "Batch 380: Loss = 0.6326, Accuracy = 70.24%\n",
            "Batch 390: Loss = 0.9814, Accuracy = 70.20%\n",
            "Epoch 24: Total Loss = 0.7875, Total Accuracy = 70.20%\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "Batch 0: Benign Loss = 1.2227, Adversarial Loss = 1.2227\n",
            "Batch 10: Benign Loss = 1.1997, Adversarial Loss = 1.1997\n",
            "Batch 20: Benign Loss = 1.1161, Adversarial Loss = 1.1161\n",
            "Batch 30: Benign Loss = 1.3465, Adversarial Loss = 1.3465\n",
            "Batch 40: Benign Loss = 1.1340, Adversarial Loss = 1.1340\n",
            "Batch 50: Benign Loss = 1.1637, Adversarial Loss = 1.1637\n",
            "Batch 60: Benign Loss = 1.1862, Adversarial Loss = 1.1862\n",
            "Batch 70: Benign Loss = 1.2844, Adversarial Loss = 1.2844\n",
            "Batch 80: Benign Loss = 1.1726, Adversarial Loss = 1.1726\n",
            "Batch 90: Benign Loss = 1.1305, Adversarial Loss = 1.1305\n",
            "Epoch 24: Benign Accuracy = 11.02%, Adversarial Accuracy = 59.51%\n",
            "Benign Loss = 24.3387, Adversarial Loss = 1.1843\n",
            "Training complete in 6868.41 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_adv_accuracy</td><td>▁▂▄▄▅▅▅▇▆▆▆▇▅▆▆▄▄▆▇██▆▇▇▆</td></tr><tr><td>test_adv_loss</td><td>▇▆▃▄▂▃▃▁▂▃▃▁▆▄▄█▆▇▂▁▄▆▆▄▆</td></tr><tr><td>test_benign_accuracy</td><td>█▆▇▆▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_benign_loss</td><td>▁▁▁▁▂▂▂▂▃▃▂▃▄▃▅▇█▃▅▆▆▄▄▇▅</td></tr><tr><td>train_adv_accuracy</td><td>█▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_adv_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>test_adv_accuracy</td><td>59.51</td></tr><tr><td>test_adv_loss</td><td>1.18432</td></tr><tr><td>test_benign_accuracy</td><td>11.02</td></tr><tr><td>test_benign_loss</td><td>24.33868</td></tr><tr><td>train_adv_accuracy</td><td>0.78749</td></tr><tr><td>train_adv_loss</td><td>0.31686</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-control-training</strong> at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/y1v1rtod' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/y1v1rtod</a><br/> View project at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241209_194746-y1v1rtod/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLfBC08mqwu7",
        "outputId": "59731d6c-588f-4624-f592-68ac25d8b958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benign Accuracy: 10.00%\n",
            "Adversarial Accuracy: 58.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.999999403953552, 57.999998331069946)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "evaluate(resnet18_control)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT 2: HALF FROZEN LAYERS\n",
        "\n",
        "wandb.init(project=\"layer-freezing-adversarial-training\", name=\"resnet18-half-frozen-training\")\n",
        "table = wandb.Table(columns=[\"epoch\", \"train_adv_accuracy\", \"train_adv_loss\", \"test_benign_accuracy\", \"test_adv_accuracy\", \"test_benign_loss\", \"test_adv_loss\"])\n",
        "\n",
        "# Model and device setup\n",
        "resnet18_half_frozen = torch.load(model_path)\n",
        "\n",
        "for param in resnet18_half_frozen.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet18_half_frozen = torch.nn.DataParallel(resnet18_half_frozen)\n",
        "\n",
        "# Freeze first 9 layers\n",
        "child_counter = 0\n",
        "for child in resnet18_half_frozen.module.children():\n",
        "    child_counter += 1\n",
        "    if child_counter <= 2:  # Freeze the first 9 layers\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Check that only the fc layer is trainable\n",
        "for name, param in resnet18_half_frozen.named_parameters():\n",
        "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# Define adversary (PGD Attack)\n",
        "adversary = PGD(resnet18, eps=0.03, alpha=0.01, steps=40)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, resnet18.parameters()),\n",
        "                      lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Adjust learning rate\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.01\n",
        "    if epoch >= 30:\n",
        "        lr /= 10\n",
        "    if epoch >= 40:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Training and testing loop\n",
        "start_time = time.time()\n",
        "for epoch in range(0, 25):  # Train for 25 epochs\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_adv_accuracy, train_adv_loss = adversarial_train(epoch, resnet18_half_frozen)\n",
        "    test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss = adversarial_test(epoch, resnet18_half_frozen)\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_adv_accuracy\": train_adv_accuracy,\n",
        "        \"train_adv_loss\": train_adv_loss,\n",
        "        \"test_benign_accuracy\": test_benign_accuracy,\n",
        "        \"test_adv_accuracy\": test_adv_accuracy,\n",
        "        \"test_benign_loss\": test_benign_loss,\n",
        "        \"test_adv_loss\": test_adv_loss\n",
        "    })\n",
        "    table.add_data(epoch, train_adv_accuracy, train_adv_loss, test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Training complete in {end_time - start_time:.2f} seconds')\n",
        "\n",
        "model_frozen_path = '/content/drive/MyDrive/MIT/6.7960 Deep Learning/models/resnet18_half_frozen_trained.pt'\n",
        "torch.save(resnet18_half_frozen, model_frozen_path)\n",
        "\n",
        "wandb.log({\"metrics_table\": table})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OYUgYZIQFhgN",
        "outputId": "f0f054de-e289-4438-dfe3-01fbe329db48"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_234909-k5qmt26y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/k5qmt26y' target=\"_blank\">resnet18-half-frozen-training</a></strong> to <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/k5qmt26y' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/k5qmt26y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module.conv1.weight: requires_grad=False\n",
            "module.bn1.weight: requires_grad=False\n",
            "module.bn1.bias: requires_grad=False\n",
            "module.layer1.0.conv1.weight: requires_grad=True\n",
            "module.layer1.0.bn1.weight: requires_grad=True\n",
            "module.layer1.0.bn1.bias: requires_grad=True\n",
            "module.layer1.0.conv2.weight: requires_grad=True\n",
            "module.layer1.0.bn2.weight: requires_grad=True\n",
            "module.layer1.0.bn2.bias: requires_grad=True\n",
            "module.layer1.1.conv1.weight: requires_grad=True\n",
            "module.layer1.1.bn1.weight: requires_grad=True\n",
            "module.layer1.1.bn1.bias: requires_grad=True\n",
            "module.layer1.1.conv2.weight: requires_grad=True\n",
            "module.layer1.1.bn2.weight: requires_grad=True\n",
            "module.layer1.1.bn2.bias: requires_grad=True\n",
            "module.layer2.0.conv1.weight: requires_grad=True\n",
            "module.layer2.0.bn1.weight: requires_grad=True\n",
            "module.layer2.0.bn1.bias: requires_grad=True\n",
            "module.layer2.0.conv2.weight: requires_grad=True\n",
            "module.layer2.0.bn2.weight: requires_grad=True\n",
            "module.layer2.0.bn2.bias: requires_grad=True\n",
            "module.layer2.0.downsample.0.weight: requires_grad=True\n",
            "module.layer2.0.downsample.1.weight: requires_grad=True\n",
            "module.layer2.0.downsample.1.bias: requires_grad=True\n",
            "module.layer2.1.conv1.weight: requires_grad=True\n",
            "module.layer2.1.bn1.weight: requires_grad=True\n",
            "module.layer2.1.bn1.bias: requires_grad=True\n",
            "module.layer2.1.conv2.weight: requires_grad=True\n",
            "module.layer2.1.bn2.weight: requires_grad=True\n",
            "module.layer2.1.bn2.bias: requires_grad=True\n",
            "module.layer3.0.conv1.weight: requires_grad=True\n",
            "module.layer3.0.bn1.weight: requires_grad=True\n",
            "module.layer3.0.bn1.bias: requires_grad=True\n",
            "module.layer3.0.conv2.weight: requires_grad=True\n",
            "module.layer3.0.bn2.weight: requires_grad=True\n",
            "module.layer3.0.bn2.bias: requires_grad=True\n",
            "module.layer3.0.downsample.0.weight: requires_grad=True\n",
            "module.layer3.0.downsample.1.weight: requires_grad=True\n",
            "module.layer3.0.downsample.1.bias: requires_grad=True\n",
            "module.layer3.1.conv1.weight: requires_grad=True\n",
            "module.layer3.1.bn1.weight: requires_grad=True\n",
            "module.layer3.1.bn1.bias: requires_grad=True\n",
            "module.layer3.1.conv2.weight: requires_grad=True\n",
            "module.layer3.1.bn2.weight: requires_grad=True\n",
            "module.layer3.1.bn2.bias: requires_grad=True\n",
            "module.layer4.0.conv1.weight: requires_grad=True\n",
            "module.layer4.0.bn1.weight: requires_grad=True\n",
            "module.layer4.0.bn1.bias: requires_grad=True\n",
            "module.layer4.0.conv2.weight: requires_grad=True\n",
            "module.layer4.0.bn2.weight: requires_grad=True\n",
            "module.layer4.0.bn2.bias: requires_grad=True\n",
            "module.layer4.0.downsample.0.weight: requires_grad=True\n",
            "module.layer4.0.downsample.1.weight: requires_grad=True\n",
            "module.layer4.0.downsample.1.bias: requires_grad=True\n",
            "module.layer4.1.conv1.weight: requires_grad=True\n",
            "module.layer4.1.bn1.weight: requires_grad=True\n",
            "module.layer4.1.bn1.bias: requires_grad=True\n",
            "module.layer4.1.conv2.weight: requires_grad=True\n",
            "module.layer4.1.bn2.weight: requires_grad=True\n",
            "module.layer4.1.bn2.bias: requires_grad=True\n",
            "module.fc.weight: requires_grad=True\n",
            "module.fc.bias: requires_grad=True\n",
            "\n",
            "[ Train epoch: 0 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-93-b0057d80ee4c>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet18_half_frozen = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: Loss = 1.6823, Accuracy = 51.56%\n",
            "Batch 10: Loss = 1.8104, Accuracy = 53.27%\n",
            "Batch 20: Loss = 1.7621, Accuracy = 54.65%\n",
            "Batch 30: Loss = 1.7359, Accuracy = 55.09%\n",
            "Batch 40: Loss = 2.2385, Accuracy = 54.55%\n",
            "Batch 50: Loss = 1.9320, Accuracy = 54.90%\n",
            "Batch 60: Loss = 1.7048, Accuracy = 55.37%\n",
            "Batch 70: Loss = 1.7780, Accuracy = 55.09%\n",
            "Batch 80: Loss = 1.3899, Accuracy = 55.22%\n",
            "Batch 90: Loss = 1.6629, Accuracy = 55.07%\n",
            "Batch 100: Loss = 2.0704, Accuracy = 54.92%\n",
            "Batch 110: Loss = 2.0217, Accuracy = 55.07%\n",
            "Batch 120: Loss = 1.6926, Accuracy = 55.26%\n",
            "Batch 130: Loss = 2.2005, Accuracy = 55.19%\n",
            "Batch 140: Loss = 1.7729, Accuracy = 55.18%\n",
            "Batch 150: Loss = 2.1875, Accuracy = 55.29%\n",
            "Batch 160: Loss = 1.7852, Accuracy = 55.34%\n",
            "Batch 170: Loss = 1.8089, Accuracy = 55.29%\n",
            "Batch 180: Loss = 1.8891, Accuracy = 55.31%\n",
            "Batch 190: Loss = 1.9751, Accuracy = 55.32%\n",
            "Batch 200: Loss = 2.5432, Accuracy = 55.25%\n",
            "Batch 210: Loss = 1.6100, Accuracy = 55.22%\n",
            "Batch 220: Loss = 1.6488, Accuracy = 55.25%\n",
            "Batch 230: Loss = 1.5059, Accuracy = 55.28%\n",
            "Batch 240: Loss = 1.6945, Accuracy = 55.23%\n",
            "Batch 250: Loss = 1.6247, Accuracy = 55.26%\n",
            "Batch 260: Loss = 1.8162, Accuracy = 55.21%\n",
            "Batch 270: Loss = 1.5968, Accuracy = 55.30%\n",
            "Batch 280: Loss = 1.8535, Accuracy = 55.33%\n",
            "Batch 290: Loss = 1.7236, Accuracy = 55.23%\n",
            "Batch 300: Loss = 1.6905, Accuracy = 55.27%\n",
            "Batch 310: Loss = 1.7514, Accuracy = 55.26%\n",
            "Batch 320: Loss = 1.5058, Accuracy = 55.34%\n",
            "Batch 330: Loss = 1.9601, Accuracy = 55.36%\n",
            "Batch 340: Loss = 2.0500, Accuracy = 55.37%\n",
            "Batch 350: Loss = 1.9564, Accuracy = 55.29%\n",
            "Batch 360: Loss = 1.6551, Accuracy = 55.26%\n",
            "Batch 370: Loss = 1.5943, Accuracy = 55.27%\n",
            "Batch 380: Loss = 1.8112, Accuracy = 55.37%\n",
            "Batch 390: Loss = 2.5417, Accuracy = 55.38%\n",
            "Epoch 0: Total Loss = 1.7527, Total Accuracy = 55.38%\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "Batch 0: Benign Loss = 2.0433, Adversarial Loss = 2.0433\n",
            "Batch 10: Benign Loss = 1.7127, Adversarial Loss = 1.7127\n",
            "Batch 20: Benign Loss = 2.1083, Adversarial Loss = 2.1083\n",
            "Batch 30: Benign Loss = 1.7468, Adversarial Loss = 1.7468\n",
            "Batch 40: Benign Loss = 1.5499, Adversarial Loss = 1.5499\n",
            "Batch 50: Benign Loss = 1.8008, Adversarial Loss = 1.8008\n",
            "Batch 60: Benign Loss = 1.9242, Adversarial Loss = 1.9242\n",
            "Batch 70: Benign Loss = 1.9000, Adversarial Loss = 1.9000\n",
            "Batch 80: Benign Loss = 1.6526, Adversarial Loss = 1.6526\n",
            "Batch 90: Benign Loss = 1.8132, Adversarial Loss = 1.8132\n",
            "Epoch 0: Benign Accuracy = 19.29%, Adversarial Accuracy = 55.76%\n",
            "Benign Loss = 4.9778, Adversarial Loss = 1.8481\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "Batch 0: Loss = 1.9202, Accuracy = 53.12%\n",
            "Batch 10: Loss = 1.6445, Accuracy = 54.26%\n",
            "Batch 20: Loss = 1.5965, Accuracy = 55.36%\n",
            "Batch 30: Loss = 1.7343, Accuracy = 55.22%\n",
            "Batch 40: Loss = 1.8713, Accuracy = 54.84%\n",
            "Batch 50: Loss = 1.7918, Accuracy = 54.79%\n",
            "Batch 60: Loss = 1.9405, Accuracy = 54.47%\n",
            "Batch 70: Loss = 1.5256, Accuracy = 54.73%\n",
            "Batch 80: Loss = 1.7182, Accuracy = 54.76%\n",
            "Batch 90: Loss = 1.7224, Accuracy = 54.73%\n",
            "Batch 100: Loss = 1.6889, Accuracy = 54.85%\n",
            "Batch 110: Loss = 1.7357, Accuracy = 54.94%\n",
            "Batch 120: Loss = 1.8241, Accuracy = 55.05%\n",
            "Batch 130: Loss = 1.7791, Accuracy = 55.00%\n",
            "Batch 140: Loss = 2.0697, Accuracy = 55.06%\n",
            "Batch 150: Loss = 1.4494, Accuracy = 55.05%\n",
            "Batch 160: Loss = 2.1630, Accuracy = 55.19%\n",
            "Batch 170: Loss = 1.6092, Accuracy = 55.20%\n",
            "Batch 180: Loss = 1.5334, Accuracy = 55.28%\n",
            "Batch 190: Loss = 2.0995, Accuracy = 55.32%\n",
            "Batch 200: Loss = 1.7502, Accuracy = 55.36%\n",
            "Batch 210: Loss = 1.8025, Accuracy = 55.29%\n",
            "Batch 220: Loss = 1.5359, Accuracy = 55.28%\n",
            "Batch 230: Loss = 1.6547, Accuracy = 55.30%\n",
            "Batch 240: Loss = 1.7110, Accuracy = 55.35%\n",
            "Batch 250: Loss = 1.9934, Accuracy = 55.33%\n",
            "Batch 260: Loss = 1.8355, Accuracy = 55.28%\n",
            "Batch 270: Loss = 1.8120, Accuracy = 55.25%\n",
            "Batch 280: Loss = 1.5036, Accuracy = 55.30%\n",
            "Batch 290: Loss = 1.8557, Accuracy = 55.33%\n",
            "Batch 300: Loss = 1.5905, Accuracy = 55.34%\n",
            "Batch 310: Loss = 1.4384, Accuracy = 55.34%\n",
            "Batch 320: Loss = 1.7153, Accuracy = 55.29%\n",
            "Batch 330: Loss = 2.1686, Accuracy = 55.27%\n",
            "Batch 340: Loss = 2.0309, Accuracy = 55.31%\n",
            "Batch 350: Loss = 1.9436, Accuracy = 55.27%\n",
            "Batch 360: Loss = 2.1095, Accuracy = 55.29%\n",
            "Batch 370: Loss = 1.5516, Accuracy = 55.28%\n",
            "Batch 380: Loss = 1.8030, Accuracy = 55.28%\n",
            "Batch 390: Loss = 1.6534, Accuracy = 55.30%\n",
            "Epoch 1: Total Loss = 1.7632, Total Accuracy = 55.30%\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "Batch 0: Benign Loss = 2.0051, Adversarial Loss = 2.0051\n",
            "Batch 10: Benign Loss = 1.6347, Adversarial Loss = 1.6347\n",
            "Batch 20: Benign Loss = 2.0640, Adversarial Loss = 2.0640\n",
            "Batch 30: Benign Loss = 1.7312, Adversarial Loss = 1.7312\n",
            "Batch 40: Benign Loss = 1.6080, Adversarial Loss = 1.6080\n",
            "Batch 50: Benign Loss = 1.7279, Adversarial Loss = 1.7279\n",
            "Batch 60: Benign Loss = 1.8953, Adversarial Loss = 1.8953\n",
            "Batch 70: Benign Loss = 1.8761, Adversarial Loss = 1.8761\n",
            "Batch 80: Benign Loss = 1.6505, Adversarial Loss = 1.6505\n",
            "Batch 90: Benign Loss = 1.7742, Adversarial Loss = 1.7742\n",
            "Epoch 1: Benign Accuracy = 21.26%, Adversarial Accuracy = 55.59%\n",
            "Benign Loss = 3.7577, Adversarial Loss = 1.8031\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "Batch 0: Loss = 2.0852, Accuracy = 53.91%\n",
            "Batch 10: Loss = 1.6077, Accuracy = 56.89%\n",
            "Batch 20: Loss = 1.9117, Accuracy = 54.91%\n",
            "Batch 30: Loss = 1.6778, Accuracy = 55.70%\n",
            "Batch 40: Loss = 1.6405, Accuracy = 55.64%\n",
            "Batch 50: Loss = 1.5468, Accuracy = 55.68%\n",
            "Batch 60: Loss = 1.7559, Accuracy = 55.75%\n",
            "Batch 70: Loss = 1.5690, Accuracy = 55.56%\n",
            "Batch 80: Loss = 1.7159, Accuracy = 55.35%\n",
            "Batch 90: Loss = 1.9518, Accuracy = 54.97%\n",
            "Batch 100: Loss = 1.9937, Accuracy = 54.94%\n",
            "Batch 110: Loss = 1.4718, Accuracy = 55.04%\n",
            "Batch 120: Loss = 1.2089, Accuracy = 55.26%\n",
            "Batch 130: Loss = 1.4392, Accuracy = 55.19%\n",
            "Batch 140: Loss = 1.5839, Accuracy = 55.12%\n",
            "Batch 150: Loss = 1.6598, Accuracy = 55.01%\n",
            "Batch 160: Loss = 1.6862, Accuracy = 55.21%\n",
            "Batch 170: Loss = 1.7635, Accuracy = 55.26%\n",
            "Batch 180: Loss = 1.4162, Accuracy = 55.37%\n",
            "Batch 190: Loss = 1.9530, Accuracy = 55.40%\n",
            "Batch 200: Loss = 1.6493, Accuracy = 55.33%\n",
            "Batch 210: Loss = 1.5620, Accuracy = 55.34%\n",
            "Batch 220: Loss = 1.6922, Accuracy = 55.33%\n",
            "Batch 230: Loss = 1.7825, Accuracy = 55.33%\n",
            "Batch 240: Loss = 2.0306, Accuracy = 55.37%\n",
            "Batch 250: Loss = 1.7961, Accuracy = 55.27%\n",
            "Batch 260: Loss = 1.7132, Accuracy = 55.32%\n",
            "Batch 270: Loss = 2.0193, Accuracy = 55.33%\n",
            "Batch 280: Loss = 2.0069, Accuracy = 55.36%\n",
            "Batch 290: Loss = 1.5151, Accuracy = 55.36%\n",
            "Batch 300: Loss = 1.4689, Accuracy = 55.40%\n",
            "Batch 310: Loss = 2.0775, Accuracy = 55.39%\n",
            "Batch 320: Loss = 1.8005, Accuracy = 55.40%\n",
            "Batch 330: Loss = 1.6279, Accuracy = 55.35%\n",
            "Batch 340: Loss = 1.8226, Accuracy = 55.35%\n",
            "Batch 350: Loss = 1.8248, Accuracy = 55.33%\n",
            "Batch 360: Loss = 1.7285, Accuracy = 55.35%\n",
            "Batch 370: Loss = 1.6027, Accuracy = 55.47%\n",
            "Batch 380: Loss = 1.9080, Accuracy = 55.46%\n",
            "Batch 390: Loss = 2.8192, Accuracy = 55.48%\n",
            "Epoch 2: Total Loss = 1.7505, Total Accuracy = 55.48%\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "Batch 0: Benign Loss = 2.0543, Adversarial Loss = 2.0543\n",
            "Batch 10: Benign Loss = 1.7194, Adversarial Loss = 1.7194\n",
            "Batch 20: Benign Loss = 2.1108, Adversarial Loss = 2.1108\n",
            "Batch 30: Benign Loss = 1.7692, Adversarial Loss = 1.7692\n",
            "Batch 40: Benign Loss = 1.6564, Adversarial Loss = 1.6564\n",
            "Batch 50: Benign Loss = 1.8460, Adversarial Loss = 1.8460\n",
            "Batch 60: Benign Loss = 1.9442, Adversarial Loss = 1.9442\n",
            "Batch 70: Benign Loss = 1.9009, Adversarial Loss = 1.9009\n",
            "Batch 80: Benign Loss = 1.7209, Adversarial Loss = 1.7209\n",
            "Batch 90: Benign Loss = 1.8142, Adversarial Loss = 1.8142\n",
            "Epoch 2: Benign Accuracy = 19.23%, Adversarial Accuracy = 55.78%\n",
            "Benign Loss = 5.0493, Adversarial Loss = 1.8599\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "Batch 0: Loss = 1.5669, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.7628, Accuracy = 56.18%\n",
            "Batch 20: Loss = 1.7563, Accuracy = 55.95%\n",
            "Batch 30: Loss = 1.5463, Accuracy = 55.90%\n",
            "Batch 40: Loss = 1.7458, Accuracy = 55.66%\n",
            "Batch 50: Loss = 2.1017, Accuracy = 55.25%\n",
            "Batch 60: Loss = 1.6715, Accuracy = 55.34%\n",
            "Batch 70: Loss = 1.7266, Accuracy = 55.40%\n",
            "Batch 80: Loss = 1.5781, Accuracy = 55.37%\n",
            "Batch 90: Loss = 1.4537, Accuracy = 55.37%\n",
            "Batch 100: Loss = 1.6782, Accuracy = 55.31%\n",
            "Batch 110: Loss = 1.5586, Accuracy = 55.37%\n",
            "Batch 120: Loss = 1.8955, Accuracy = 55.39%\n",
            "Batch 130: Loss = 1.7704, Accuracy = 55.28%\n",
            "Batch 140: Loss = 1.7392, Accuracy = 55.27%\n",
            "Batch 150: Loss = 1.7528, Accuracy = 55.27%\n",
            "Batch 160: Loss = 1.4610, Accuracy = 55.29%\n",
            "Batch 170: Loss = 1.9361, Accuracy = 55.25%\n",
            "Batch 180: Loss = 1.5490, Accuracy = 55.33%\n",
            "Batch 190: Loss = 1.7684, Accuracy = 55.34%\n",
            "Batch 200: Loss = 1.8240, Accuracy = 55.43%\n",
            "Batch 210: Loss = 1.7928, Accuracy = 55.51%\n",
            "Batch 220: Loss = 1.8439, Accuracy = 55.45%\n",
            "Batch 230: Loss = 1.9730, Accuracy = 55.49%\n",
            "Batch 240: Loss = 1.6532, Accuracy = 55.42%\n",
            "Batch 250: Loss = 1.5385, Accuracy = 55.47%\n",
            "Batch 260: Loss = 1.5331, Accuracy = 55.44%\n",
            "Batch 270: Loss = 1.4909, Accuracy = 55.49%\n",
            "Batch 280: Loss = 2.0620, Accuracy = 55.34%\n",
            "Batch 290: Loss = 1.2897, Accuracy = 55.44%\n",
            "Batch 300: Loss = 1.5845, Accuracy = 55.43%\n",
            "Batch 310: Loss = 1.9074, Accuracy = 55.36%\n",
            "Batch 320: Loss = 1.4189, Accuracy = 55.32%\n",
            "Batch 330: Loss = 1.4920, Accuracy = 55.31%\n",
            "Batch 340: Loss = 1.5514, Accuracy = 55.32%\n",
            "Batch 350: Loss = 1.7366, Accuracy = 55.34%\n",
            "Batch 360: Loss = 1.6272, Accuracy = 55.28%\n",
            "Batch 370: Loss = 1.8025, Accuracy = 55.23%\n",
            "Batch 380: Loss = 2.4869, Accuracy = 55.24%\n",
            "Batch 390: Loss = 2.1590, Accuracy = 55.29%\n",
            "Epoch 3: Total Loss = 1.7512, Total Accuracy = 55.29%\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "Batch 0: Benign Loss = 2.0298, Adversarial Loss = 2.0298\n",
            "Batch 10: Benign Loss = 1.6597, Adversarial Loss = 1.6597\n",
            "Batch 20: Benign Loss = 2.1179, Adversarial Loss = 2.1179\n",
            "Batch 30: Benign Loss = 1.7443, Adversarial Loss = 1.7443\n",
            "Batch 40: Benign Loss = 1.6443, Adversarial Loss = 1.6443\n",
            "Batch 50: Benign Loss = 1.7287, Adversarial Loss = 1.7287\n",
            "Batch 60: Benign Loss = 1.9085, Adversarial Loss = 1.9085\n",
            "Batch 70: Benign Loss = 1.8577, Adversarial Loss = 1.8577\n",
            "Batch 80: Benign Loss = 1.6757, Adversarial Loss = 1.6757\n",
            "Batch 90: Benign Loss = 1.7680, Adversarial Loss = 1.7680\n",
            "Epoch 3: Benign Accuracy = 21.93%, Adversarial Accuracy = 55.88%\n",
            "Benign Loss = 3.6213, Adversarial Loss = 1.8235\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "Batch 0: Loss = 1.8660, Accuracy = 59.38%\n",
            "Batch 10: Loss = 1.6442, Accuracy = 56.39%\n",
            "Batch 20: Loss = 1.6279, Accuracy = 54.54%\n",
            "Batch 30: Loss = 2.4697, Accuracy = 54.49%\n",
            "Batch 40: Loss = 1.6382, Accuracy = 54.73%\n",
            "Batch 50: Loss = 2.0825, Accuracy = 54.78%\n",
            "Batch 60: Loss = 1.2351, Accuracy = 55.16%\n",
            "Batch 70: Loss = 1.9067, Accuracy = 55.02%\n",
            "Batch 80: Loss = 1.7883, Accuracy = 55.10%\n",
            "Batch 90: Loss = 1.5932, Accuracy = 55.31%\n",
            "Batch 100: Loss = 1.8167, Accuracy = 55.24%\n",
            "Batch 110: Loss = 1.3881, Accuracy = 55.39%\n",
            "Batch 120: Loss = 1.5012, Accuracy = 55.58%\n",
            "Batch 130: Loss = 1.5409, Accuracy = 55.61%\n",
            "Batch 140: Loss = 2.0733, Accuracy = 55.73%\n",
            "Batch 150: Loss = 2.0164, Accuracy = 55.60%\n",
            "Batch 160: Loss = 1.6231, Accuracy = 55.51%\n",
            "Batch 170: Loss = 1.5548, Accuracy = 55.54%\n",
            "Batch 180: Loss = 1.7289, Accuracy = 55.49%\n",
            "Batch 190: Loss = 2.0979, Accuracy = 55.47%\n",
            "Batch 200: Loss = 1.7390, Accuracy = 55.39%\n",
            "Batch 210: Loss = 1.6343, Accuracy = 55.38%\n",
            "Batch 220: Loss = 1.4306, Accuracy = 55.32%\n",
            "Batch 230: Loss = 2.1426, Accuracy = 55.32%\n",
            "Batch 240: Loss = 1.2836, Accuracy = 55.34%\n",
            "Batch 250: Loss = 1.7512, Accuracy = 55.36%\n",
            "Batch 260: Loss = 2.1215, Accuracy = 55.37%\n",
            "Batch 270: Loss = 1.5105, Accuracy = 55.34%\n",
            "Batch 280: Loss = 1.8521, Accuracy = 55.43%\n",
            "Batch 290: Loss = 2.0867, Accuracy = 55.43%\n",
            "Batch 300: Loss = 2.1386, Accuracy = 55.38%\n",
            "Batch 310: Loss = 1.4561, Accuracy = 55.45%\n",
            "Batch 320: Loss = 1.7732, Accuracy = 55.30%\n",
            "Batch 330: Loss = 1.4945, Accuracy = 55.26%\n",
            "Batch 340: Loss = 1.7728, Accuracy = 55.20%\n",
            "Batch 350: Loss = 1.8728, Accuracy = 55.29%\n",
            "Batch 360: Loss = 1.6251, Accuracy = 55.28%\n",
            "Batch 370: Loss = 1.9080, Accuracy = 55.21%\n",
            "Batch 380: Loss = 1.7313, Accuracy = 55.21%\n",
            "Batch 390: Loss = 1.5384, Accuracy = 55.22%\n",
            "Epoch 4: Total Loss = 1.7703, Total Accuracy = 55.22%\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "Batch 0: Benign Loss = 2.0235, Adversarial Loss = 2.0235\n",
            "Batch 10: Benign Loss = 1.6574, Adversarial Loss = 1.6574\n",
            "Batch 20: Benign Loss = 2.0921, Adversarial Loss = 2.0921\n",
            "Batch 30: Benign Loss = 1.7595, Adversarial Loss = 1.7595\n",
            "Batch 40: Benign Loss = 1.5331, Adversarial Loss = 1.5331\n",
            "Batch 50: Benign Loss = 1.7871, Adversarial Loss = 1.7871\n",
            "Batch 60: Benign Loss = 1.8861, Adversarial Loss = 1.8861\n",
            "Batch 70: Benign Loss = 1.8694, Adversarial Loss = 1.8694\n",
            "Batch 80: Benign Loss = 1.6390, Adversarial Loss = 1.6390\n",
            "Batch 90: Benign Loss = 1.7693, Adversarial Loss = 1.7693\n",
            "Epoch 4: Benign Accuracy = 20.41%, Adversarial Accuracy = 55.71%\n",
            "Benign Loss = 4.0258, Adversarial Loss = 1.8125\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "Batch 0: Loss = 1.7832, Accuracy = 54.69%\n",
            "Batch 10: Loss = 1.3761, Accuracy = 55.89%\n",
            "Batch 20: Loss = 1.9554, Accuracy = 55.43%\n",
            "Batch 30: Loss = 1.7224, Accuracy = 55.59%\n",
            "Batch 40: Loss = 1.4796, Accuracy = 55.87%\n",
            "Batch 50: Loss = 1.6315, Accuracy = 55.61%\n",
            "Batch 60: Loss = 2.3863, Accuracy = 55.16%\n",
            "Batch 70: Loss = 1.8183, Accuracy = 55.16%\n",
            "Batch 80: Loss = 1.9283, Accuracy = 55.27%\n",
            "Batch 90: Loss = 2.3798, Accuracy = 55.31%\n",
            "Batch 100: Loss = 1.7194, Accuracy = 55.36%\n",
            "Batch 110: Loss = 1.8738, Accuracy = 55.47%\n",
            "Batch 120: Loss = 1.6557, Accuracy = 55.57%\n",
            "Batch 130: Loss = 1.5503, Accuracy = 55.60%\n",
            "Batch 140: Loss = 1.7566, Accuracy = 55.58%\n",
            "Batch 150: Loss = 1.9170, Accuracy = 55.52%\n",
            "Batch 160: Loss = 1.8522, Accuracy = 55.28%\n",
            "Batch 170: Loss = 1.7539, Accuracy = 55.32%\n",
            "Batch 180: Loss = 1.6418, Accuracy = 55.34%\n",
            "Batch 190: Loss = 1.5819, Accuracy = 55.28%\n",
            "Batch 200: Loss = 1.8683, Accuracy = 55.25%\n",
            "Batch 210: Loss = 1.6340, Accuracy = 55.23%\n",
            "Batch 220: Loss = 2.0241, Accuracy = 55.18%\n",
            "Batch 230: Loss = 1.6023, Accuracy = 55.13%\n",
            "Batch 240: Loss = 2.0867, Accuracy = 55.13%\n",
            "Batch 250: Loss = 1.5296, Accuracy = 55.18%\n",
            "Batch 260: Loss = 1.8331, Accuracy = 55.18%\n",
            "Batch 270: Loss = 1.8364, Accuracy = 55.23%\n",
            "Batch 280: Loss = 1.8889, Accuracy = 55.21%\n",
            "Batch 290: Loss = 1.8132, Accuracy = 55.21%\n",
            "Batch 300: Loss = 1.8900, Accuracy = 55.22%\n",
            "Batch 310: Loss = 2.2975, Accuracy = 55.29%\n",
            "Batch 320: Loss = 1.6891, Accuracy = 55.26%\n",
            "Batch 330: Loss = 2.1664, Accuracy = 55.23%\n",
            "Batch 340: Loss = 1.8730, Accuracy = 55.27%\n",
            "Batch 350: Loss = 1.5626, Accuracy = 55.25%\n",
            "Batch 360: Loss = 1.7503, Accuracy = 55.26%\n",
            "Batch 370: Loss = 1.6043, Accuracy = 55.23%\n",
            "Batch 380: Loss = 1.7121, Accuracy = 55.25%\n",
            "Batch 390: Loss = 1.9838, Accuracy = 55.26%\n",
            "Epoch 5: Total Loss = 1.7725, Total Accuracy = 55.26%\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "Batch 0: Benign Loss = 1.9989, Adversarial Loss = 1.9989\n",
            "Batch 10: Benign Loss = 1.6605, Adversarial Loss = 1.6605\n",
            "Batch 20: Benign Loss = 2.0925, Adversarial Loss = 2.0925\n",
            "Batch 30: Benign Loss = 1.7293, Adversarial Loss = 1.7293\n",
            "Batch 40: Benign Loss = 1.6310, Adversarial Loss = 1.6310\n",
            "Batch 50: Benign Loss = 1.7604, Adversarial Loss = 1.7604\n",
            "Batch 60: Benign Loss = 1.8840, Adversarial Loss = 1.8840\n",
            "Batch 70: Benign Loss = 1.8787, Adversarial Loss = 1.8787\n",
            "Batch 80: Benign Loss = 1.6460, Adversarial Loss = 1.6460\n",
            "Batch 90: Benign Loss = 1.7381, Adversarial Loss = 1.7381\n",
            "Epoch 5: Benign Accuracy = 20.26%, Adversarial Accuracy = 55.89%\n",
            "Benign Loss = 4.1283, Adversarial Loss = 1.8067\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "Batch 0: Loss = 1.8121, Accuracy = 54.69%\n",
            "Batch 10: Loss = 1.6495, Accuracy = 55.82%\n",
            "Batch 20: Loss = 1.8741, Accuracy = 55.92%\n",
            "Batch 30: Loss = 2.1461, Accuracy = 56.22%\n",
            "Batch 40: Loss = 1.7787, Accuracy = 55.56%\n",
            "Batch 50: Loss = 2.1127, Accuracy = 55.47%\n",
            "Batch 60: Loss = 1.9723, Accuracy = 55.66%\n",
            "Batch 70: Loss = 1.2769, Accuracy = 55.78%\n",
            "Batch 80: Loss = 2.1364, Accuracy = 55.60%\n",
            "Batch 90: Loss = 1.8947, Accuracy = 55.73%\n",
            "Batch 100: Loss = 1.9422, Accuracy = 55.60%\n",
            "Batch 110: Loss = 1.7771, Accuracy = 55.88%\n",
            "Batch 120: Loss = 1.5238, Accuracy = 56.09%\n",
            "Batch 130: Loss = 1.4660, Accuracy = 55.86%\n",
            "Batch 140: Loss = 1.6680, Accuracy = 55.75%\n",
            "Batch 150: Loss = 1.8166, Accuracy = 55.78%\n",
            "Batch 160: Loss = 2.0750, Accuracy = 55.87%\n",
            "Batch 170: Loss = 1.8531, Accuracy = 55.68%\n",
            "Batch 180: Loss = 1.6278, Accuracy = 55.65%\n",
            "Batch 190: Loss = 1.7131, Accuracy = 55.57%\n",
            "Batch 200: Loss = 1.7903, Accuracy = 55.61%\n",
            "Batch 210: Loss = 1.4605, Accuracy = 55.61%\n",
            "Batch 220: Loss = 1.9893, Accuracy = 55.61%\n",
            "Batch 230: Loss = 1.8825, Accuracy = 55.62%\n",
            "Batch 240: Loss = 2.1546, Accuracy = 55.60%\n",
            "Batch 250: Loss = 1.7673, Accuracy = 55.52%\n",
            "Batch 260: Loss = 1.7874, Accuracy = 55.56%\n",
            "Batch 270: Loss = 1.5669, Accuracy = 55.55%\n",
            "Batch 280: Loss = 1.9082, Accuracy = 55.53%\n",
            "Batch 290: Loss = 1.9800, Accuracy = 55.50%\n",
            "Batch 300: Loss = 1.5546, Accuracy = 55.49%\n",
            "Batch 310: Loss = 1.4222, Accuracy = 55.49%\n",
            "Batch 320: Loss = 1.6707, Accuracy = 55.50%\n",
            "Batch 330: Loss = 1.9629, Accuracy = 55.56%\n",
            "Batch 340: Loss = 1.4786, Accuracy = 55.49%\n",
            "Batch 350: Loss = 1.4633, Accuracy = 55.50%\n",
            "Batch 360: Loss = 2.4300, Accuracy = 55.53%\n",
            "Batch 370: Loss = 1.9489, Accuracy = 55.51%\n",
            "Batch 380: Loss = 1.9194, Accuracy = 55.52%\n",
            "Batch 390: Loss = 3.1148, Accuracy = 55.51%\n",
            "Epoch 6: Total Loss = 1.7494, Total Accuracy = 55.51%\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "Batch 0: Benign Loss = 2.0949, Adversarial Loss = 2.0949\n",
            "Batch 10: Benign Loss = 1.7097, Adversarial Loss = 1.7097\n",
            "Batch 20: Benign Loss = 2.1630, Adversarial Loss = 2.1630\n",
            "Batch 30: Benign Loss = 1.8182, Adversarial Loss = 1.8182\n",
            "Batch 40: Benign Loss = 1.6794, Adversarial Loss = 1.6794\n",
            "Batch 50: Benign Loss = 1.7984, Adversarial Loss = 1.7984\n",
            "Batch 60: Benign Loss = 1.9456, Adversarial Loss = 1.9456\n",
            "Batch 70: Benign Loss = 1.9023, Adversarial Loss = 1.9023\n",
            "Batch 80: Benign Loss = 1.6859, Adversarial Loss = 1.6859\n",
            "Batch 90: Benign Loss = 1.8070, Adversarial Loss = 1.8070\n",
            "Epoch 6: Benign Accuracy = 19.11%, Adversarial Accuracy = 55.62%\n",
            "Benign Loss = 5.2076, Adversarial Loss = 1.8736\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "Batch 0: Loss = 1.7482, Accuracy = 54.69%\n",
            "Batch 10: Loss = 1.9083, Accuracy = 55.75%\n",
            "Batch 20: Loss = 1.9163, Accuracy = 55.73%\n",
            "Batch 30: Loss = 1.7689, Accuracy = 55.49%\n",
            "Batch 40: Loss = 1.8577, Accuracy = 55.01%\n",
            "Batch 50: Loss = 1.7071, Accuracy = 54.92%\n",
            "Batch 60: Loss = 1.6128, Accuracy = 55.01%\n",
            "Batch 70: Loss = 1.8586, Accuracy = 54.98%\n",
            "Batch 80: Loss = 1.5097, Accuracy = 55.11%\n",
            "Batch 90: Loss = 2.4183, Accuracy = 54.95%\n",
            "Batch 100: Loss = 1.8442, Accuracy = 54.98%\n",
            "Batch 110: Loss = 1.5161, Accuracy = 55.24%\n",
            "Batch 120: Loss = 2.0173, Accuracy = 55.13%\n",
            "Batch 130: Loss = 1.5111, Accuracy = 55.30%\n",
            "Batch 140: Loss = 1.7936, Accuracy = 55.37%\n",
            "Batch 150: Loss = 1.9930, Accuracy = 55.48%\n",
            "Batch 160: Loss = 1.7350, Accuracy = 55.43%\n",
            "Batch 170: Loss = 1.7151, Accuracy = 55.47%\n",
            "Batch 180: Loss = 1.7437, Accuracy = 55.46%\n",
            "Batch 190: Loss = 1.6140, Accuracy = 55.51%\n",
            "Batch 200: Loss = 1.9132, Accuracy = 55.50%\n",
            "Batch 210: Loss = 1.7907, Accuracy = 55.44%\n",
            "Batch 220: Loss = 1.7428, Accuracy = 55.50%\n",
            "Batch 230: Loss = 1.6968, Accuracy = 55.45%\n",
            "Batch 240: Loss = 1.6726, Accuracy = 55.47%\n",
            "Batch 250: Loss = 1.7700, Accuracy = 55.49%\n",
            "Batch 260: Loss = 2.0193, Accuracy = 55.36%\n",
            "Batch 270: Loss = 1.7976, Accuracy = 55.37%\n",
            "Batch 280: Loss = 1.3895, Accuracy = 55.42%\n",
            "Batch 290: Loss = 2.1070, Accuracy = 55.42%\n",
            "Batch 300: Loss = 1.6673, Accuracy = 55.39%\n",
            "Batch 310: Loss = 1.4643, Accuracy = 55.37%\n",
            "Batch 320: Loss = 1.9130, Accuracy = 55.39%\n",
            "Batch 330: Loss = 1.4885, Accuracy = 55.42%\n",
            "Batch 340: Loss = 1.6451, Accuracy = 55.43%\n",
            "Batch 350: Loss = 1.6535, Accuracy = 55.43%\n",
            "Batch 360: Loss = 1.4548, Accuracy = 55.41%\n",
            "Batch 370: Loss = 1.8910, Accuracy = 55.43%\n",
            "Batch 380: Loss = 1.7628, Accuracy = 55.40%\n",
            "Batch 390: Loss = 2.0225, Accuracy = 55.35%\n",
            "Epoch 7: Total Loss = 1.7520, Total Accuracy = 55.35%\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "Batch 0: Benign Loss = 2.0133, Adversarial Loss = 2.0133\n",
            "Batch 10: Benign Loss = 1.6732, Adversarial Loss = 1.6732\n",
            "Batch 20: Benign Loss = 2.1146, Adversarial Loss = 2.1146\n",
            "Batch 30: Benign Loss = 1.7534, Adversarial Loss = 1.7534\n",
            "Batch 40: Benign Loss = 1.6691, Adversarial Loss = 1.6691\n",
            "Batch 50: Benign Loss = 1.7460, Adversarial Loss = 1.7460\n",
            "Batch 60: Benign Loss = 1.9001, Adversarial Loss = 1.9001\n",
            "Batch 70: Benign Loss = 1.9352, Adversarial Loss = 1.9352\n",
            "Batch 80: Benign Loss = 1.6794, Adversarial Loss = 1.6794\n",
            "Batch 90: Benign Loss = 1.8030, Adversarial Loss = 1.8030\n",
            "Epoch 7: Benign Accuracy = 19.83%, Adversarial Accuracy = 55.52%\n",
            "Benign Loss = 4.4174, Adversarial Loss = 1.8305\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "Batch 0: Loss = 1.3560, Accuracy = 64.06%\n",
            "Batch 10: Loss = 1.6317, Accuracy = 57.39%\n",
            "Batch 20: Loss = 1.9346, Accuracy = 55.54%\n",
            "Batch 30: Loss = 1.6303, Accuracy = 56.17%\n",
            "Batch 40: Loss = 2.0837, Accuracy = 56.12%\n",
            "Batch 50: Loss = 1.8683, Accuracy = 55.87%\n",
            "Batch 60: Loss = 1.5288, Accuracy = 55.97%\n",
            "Batch 70: Loss = 1.9459, Accuracy = 55.80%\n",
            "Batch 80: Loss = 1.8540, Accuracy = 55.59%\n",
            "Batch 90: Loss = 1.9730, Accuracy = 55.43%\n",
            "Batch 100: Loss = 2.1844, Accuracy = 55.34%\n",
            "Batch 110: Loss = 1.5805, Accuracy = 55.36%\n",
            "Batch 120: Loss = 1.7252, Accuracy = 55.32%\n",
            "Batch 130: Loss = 1.7030, Accuracy = 55.39%\n",
            "Batch 140: Loss = 2.0423, Accuracy = 55.23%\n",
            "Batch 150: Loss = 1.5744, Accuracy = 55.04%\n",
            "Batch 160: Loss = 1.7025, Accuracy = 55.13%\n",
            "Batch 170: Loss = 1.7713, Accuracy = 55.14%\n",
            "Batch 180: Loss = 1.9173, Accuracy = 55.15%\n",
            "Batch 190: Loss = 2.0869, Accuracy = 55.15%\n",
            "Batch 200: Loss = 1.6413, Accuracy = 55.29%\n",
            "Batch 210: Loss = 1.8680, Accuracy = 55.26%\n",
            "Batch 220: Loss = 1.9386, Accuracy = 55.39%\n",
            "Batch 230: Loss = 1.8219, Accuracy = 55.40%\n",
            "Batch 240: Loss = 2.0445, Accuracy = 55.37%\n",
            "Batch 250: Loss = 1.7032, Accuracy = 55.43%\n",
            "Batch 260: Loss = 1.8408, Accuracy = 55.38%\n",
            "Batch 270: Loss = 1.5139, Accuracy = 55.42%\n",
            "Batch 280: Loss = 1.6433, Accuracy = 55.45%\n",
            "Batch 290: Loss = 1.9760, Accuracy = 55.44%\n",
            "Batch 300: Loss = 2.2153, Accuracy = 55.35%\n",
            "Batch 310: Loss = 1.6485, Accuracy = 55.35%\n",
            "Batch 320: Loss = 1.6439, Accuracy = 55.33%\n",
            "Batch 330: Loss = 2.1817, Accuracy = 55.31%\n",
            "Batch 340: Loss = 1.7000, Accuracy = 55.28%\n",
            "Batch 350: Loss = 1.9534, Accuracy = 55.23%\n",
            "Batch 360: Loss = 1.8584, Accuracy = 55.23%\n",
            "Batch 370: Loss = 1.8765, Accuracy = 55.19%\n",
            "Batch 380: Loss = 1.6701, Accuracy = 55.08%\n",
            "Batch 390: Loss = 1.5428, Accuracy = 55.02%\n",
            "Epoch 8: Total Loss = 1.7619, Total Accuracy = 55.02%\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "Batch 0: Benign Loss = 2.0485, Adversarial Loss = 2.0485\n",
            "Batch 10: Benign Loss = 1.6990, Adversarial Loss = 1.6990\n",
            "Batch 20: Benign Loss = 2.1084, Adversarial Loss = 2.1084\n",
            "Batch 30: Benign Loss = 1.7639, Adversarial Loss = 1.7639\n",
            "Batch 40: Benign Loss = 1.6429, Adversarial Loss = 1.6429\n",
            "Batch 50: Benign Loss = 1.8079, Adversarial Loss = 1.8079\n",
            "Batch 60: Benign Loss = 1.9161, Adversarial Loss = 1.9161\n",
            "Batch 70: Benign Loss = 1.8744, Adversarial Loss = 1.8744\n",
            "Batch 80: Benign Loss = 1.6680, Adversarial Loss = 1.6680\n",
            "Batch 90: Benign Loss = 1.7778, Adversarial Loss = 1.7778\n",
            "Epoch 8: Benign Accuracy = 18.90%, Adversarial Accuracy = 55.84%\n",
            "Benign Loss = 4.7569, Adversarial Loss = 1.8405\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "Batch 0: Loss = 1.8178, Accuracy = 51.56%\n",
            "Batch 10: Loss = 1.6741, Accuracy = 53.27%\n",
            "Batch 20: Loss = 2.1245, Accuracy = 54.76%\n",
            "Batch 30: Loss = 1.7849, Accuracy = 55.47%\n",
            "Batch 40: Loss = 1.8469, Accuracy = 55.60%\n",
            "Batch 50: Loss = 1.2962, Accuracy = 55.85%\n",
            "Batch 60: Loss = 1.6166, Accuracy = 56.06%\n",
            "Batch 70: Loss = 1.5982, Accuracy = 55.73%\n",
            "Batch 80: Loss = 1.6786, Accuracy = 55.77%\n",
            "Batch 90: Loss = 1.8564, Accuracy = 55.75%\n",
            "Batch 100: Loss = 1.7793, Accuracy = 55.84%\n",
            "Batch 110: Loss = 1.5619, Accuracy = 56.00%\n",
            "Batch 120: Loss = 1.4442, Accuracy = 55.88%\n",
            "Batch 130: Loss = 2.2063, Accuracy = 55.64%\n",
            "Batch 140: Loss = 1.8129, Accuracy = 55.47%\n",
            "Batch 150: Loss = 2.0895, Accuracy = 55.49%\n",
            "Batch 160: Loss = 1.6726, Accuracy = 55.33%\n",
            "Batch 170: Loss = 1.7885, Accuracy = 55.34%\n",
            "Batch 180: Loss = 1.7888, Accuracy = 55.43%\n",
            "Batch 190: Loss = 1.7911, Accuracy = 55.44%\n",
            "Batch 200: Loss = 1.5865, Accuracy = 55.37%\n",
            "Batch 210: Loss = 1.4815, Accuracy = 55.34%\n",
            "Batch 220: Loss = 1.8787, Accuracy = 55.39%\n",
            "Batch 230: Loss = 1.5763, Accuracy = 55.47%\n",
            "Batch 240: Loss = 1.8103, Accuracy = 55.41%\n",
            "Batch 250: Loss = 1.8102, Accuracy = 55.42%\n",
            "Batch 260: Loss = 2.1876, Accuracy = 55.38%\n",
            "Batch 270: Loss = 2.0703, Accuracy = 55.39%\n",
            "Batch 280: Loss = 1.8431, Accuracy = 55.42%\n",
            "Batch 290: Loss = 1.8891, Accuracy = 55.45%\n",
            "Batch 300: Loss = 1.6184, Accuracy = 55.47%\n",
            "Batch 310: Loss = 1.8814, Accuracy = 55.38%\n",
            "Batch 320: Loss = 1.8497, Accuracy = 55.33%\n",
            "Batch 330: Loss = 1.7442, Accuracy = 55.27%\n",
            "Batch 340: Loss = 1.9731, Accuracy = 55.30%\n",
            "Batch 350: Loss = 1.3438, Accuracy = 55.28%\n",
            "Batch 360: Loss = 1.8151, Accuracy = 55.25%\n",
            "Batch 370: Loss = 1.5587, Accuracy = 55.23%\n",
            "Batch 380: Loss = 1.5397, Accuracy = 55.27%\n",
            "Batch 390: Loss = 1.9424, Accuracy = 55.18%\n",
            "Epoch 9: Total Loss = 1.7681, Total Accuracy = 55.18%\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "Batch 0: Benign Loss = 2.0308, Adversarial Loss = 2.0308\n",
            "Batch 10: Benign Loss = 1.6348, Adversarial Loss = 1.6348\n",
            "Batch 20: Benign Loss = 2.1580, Adversarial Loss = 2.1580\n",
            "Batch 30: Benign Loss = 1.7651, Adversarial Loss = 1.7651\n",
            "Batch 40: Benign Loss = 1.5855, Adversarial Loss = 1.5855\n",
            "Batch 50: Benign Loss = 1.7876, Adversarial Loss = 1.7876\n",
            "Batch 60: Benign Loss = 1.8868, Adversarial Loss = 1.8868\n",
            "Batch 70: Benign Loss = 1.9075, Adversarial Loss = 1.9075\n",
            "Batch 80: Benign Loss = 1.6171, Adversarial Loss = 1.6171\n",
            "Batch 90: Benign Loss = 1.7464, Adversarial Loss = 1.7464\n",
            "Epoch 9: Benign Accuracy = 21.00%, Adversarial Accuracy = 56.05%\n",
            "Benign Loss = 3.8041, Adversarial Loss = 1.8315\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "Batch 0: Loss = 1.4222, Accuracy = 51.56%\n",
            "Batch 10: Loss = 1.6603, Accuracy = 55.75%\n",
            "Batch 20: Loss = 1.8004, Accuracy = 54.20%\n",
            "Batch 30: Loss = 2.0621, Accuracy = 53.86%\n",
            "Batch 40: Loss = 1.9837, Accuracy = 53.45%\n",
            "Batch 50: Loss = 1.8493, Accuracy = 53.91%\n",
            "Batch 60: Loss = 1.9524, Accuracy = 54.41%\n",
            "Batch 70: Loss = 1.7054, Accuracy = 54.73%\n",
            "Batch 80: Loss = 1.7334, Accuracy = 54.85%\n",
            "Batch 90: Loss = 1.1936, Accuracy = 54.99%\n",
            "Batch 100: Loss = 1.8875, Accuracy = 54.86%\n",
            "Batch 110: Loss = 1.3135, Accuracy = 54.97%\n",
            "Batch 120: Loss = 1.7100, Accuracy = 55.04%\n",
            "Batch 130: Loss = 1.6219, Accuracy = 55.01%\n",
            "Batch 140: Loss = 1.8885, Accuracy = 54.89%\n",
            "Batch 150: Loss = 1.9321, Accuracy = 54.98%\n",
            "Batch 160: Loss = 1.4727, Accuracy = 54.90%\n",
            "Batch 170: Loss = 1.5453, Accuracy = 54.95%\n",
            "Batch 180: Loss = 2.0316, Accuracy = 55.15%\n",
            "Batch 190: Loss = 1.6528, Accuracy = 55.08%\n",
            "Batch 200: Loss = 2.1741, Accuracy = 55.13%\n",
            "Batch 210: Loss = 1.6332, Accuracy = 55.17%\n",
            "Batch 220: Loss = 1.4344, Accuracy = 55.15%\n",
            "Batch 230: Loss = 1.5793, Accuracy = 55.12%\n",
            "Batch 240: Loss = 1.5574, Accuracy = 55.27%\n",
            "Batch 250: Loss = 2.0113, Accuracy = 55.25%\n",
            "Batch 260: Loss = 1.7780, Accuracy = 55.28%\n",
            "Batch 270: Loss = 1.5581, Accuracy = 55.28%\n",
            "Batch 280: Loss = 1.7044, Accuracy = 55.24%\n",
            "Batch 290: Loss = 2.1472, Accuracy = 55.28%\n",
            "Batch 300: Loss = 1.6900, Accuracy = 55.28%\n",
            "Batch 310: Loss = 1.9527, Accuracy = 55.23%\n",
            "Batch 320: Loss = 1.6396, Accuracy = 55.21%\n",
            "Batch 330: Loss = 1.2823, Accuracy = 55.38%\n",
            "Batch 340: Loss = 1.8422, Accuracy = 55.46%\n",
            "Batch 350: Loss = 1.8627, Accuracy = 55.50%\n",
            "Batch 360: Loss = 1.7003, Accuracy = 55.47%\n",
            "Batch 370: Loss = 2.1969, Accuracy = 55.46%\n",
            "Batch 380: Loss = 1.5724, Accuracy = 55.41%\n",
            "Batch 390: Loss = 2.2713, Accuracy = 55.46%\n",
            "Epoch 10: Total Loss = 1.7546, Total Accuracy = 55.46%\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "Batch 0: Benign Loss = 2.0482, Adversarial Loss = 2.0482\n",
            "Batch 10: Benign Loss = 1.6949, Adversarial Loss = 1.6949\n",
            "Batch 20: Benign Loss = 2.1586, Adversarial Loss = 2.1586\n",
            "Batch 30: Benign Loss = 1.7960, Adversarial Loss = 1.7960\n",
            "Batch 40: Benign Loss = 1.6405, Adversarial Loss = 1.6405\n",
            "Batch 50: Benign Loss = 1.8039, Adversarial Loss = 1.8039\n",
            "Batch 60: Benign Loss = 1.9314, Adversarial Loss = 1.9314\n",
            "Batch 70: Benign Loss = 1.8876, Adversarial Loss = 1.8876\n",
            "Batch 80: Benign Loss = 1.6804, Adversarial Loss = 1.6804\n",
            "Batch 90: Benign Loss = 1.7929, Adversarial Loss = 1.7929\n",
            "Epoch 10: Benign Accuracy = 20.34%, Adversarial Accuracy = 55.57%\n",
            "Benign Loss = 4.0288, Adversarial Loss = 1.8491\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "Batch 0: Loss = 1.5558, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.7185, Accuracy = 52.98%\n",
            "Batch 20: Loss = 1.9755, Accuracy = 52.79%\n",
            "Batch 30: Loss = 1.6705, Accuracy = 53.88%\n",
            "Batch 40: Loss = 2.3201, Accuracy = 53.83%\n",
            "Batch 50: Loss = 1.2915, Accuracy = 54.44%\n",
            "Batch 60: Loss = 1.9084, Accuracy = 54.78%\n",
            "Batch 70: Loss = 1.4497, Accuracy = 54.84%\n",
            "Batch 80: Loss = 1.7927, Accuracy = 54.91%\n",
            "Batch 90: Loss = 1.7890, Accuracy = 55.07%\n",
            "Batch 100: Loss = 1.8245, Accuracy = 55.00%\n",
            "Batch 110: Loss = 1.8891, Accuracy = 55.22%\n",
            "Batch 120: Loss = 1.7235, Accuracy = 55.27%\n",
            "Batch 130: Loss = 1.5951, Accuracy = 55.13%\n",
            "Batch 140: Loss = 1.7702, Accuracy = 55.21%\n",
            "Batch 150: Loss = 1.7025, Accuracy = 55.29%\n",
            "Batch 160: Loss = 1.7708, Accuracy = 55.15%\n",
            "Batch 170: Loss = 2.0210, Accuracy = 54.93%\n",
            "Batch 180: Loss = 1.7883, Accuracy = 54.91%\n",
            "Batch 190: Loss = 1.6970, Accuracy = 55.02%\n",
            "Batch 200: Loss = 1.6917, Accuracy = 55.04%\n",
            "Batch 210: Loss = 1.7385, Accuracy = 54.92%\n",
            "Batch 220: Loss = 1.5367, Accuracy = 54.98%\n",
            "Batch 230: Loss = 2.2698, Accuracy = 55.04%\n",
            "Batch 240: Loss = 2.1176, Accuracy = 54.98%\n",
            "Batch 250: Loss = 2.0439, Accuracy = 55.08%\n",
            "Batch 260: Loss = 2.0168, Accuracy = 55.14%\n",
            "Batch 270: Loss = 1.8677, Accuracy = 55.13%\n",
            "Batch 280: Loss = 1.7012, Accuracy = 55.13%\n",
            "Batch 290: Loss = 2.0105, Accuracy = 55.05%\n",
            "Batch 300: Loss = 1.9011, Accuracy = 55.10%\n",
            "Batch 310: Loss = 1.6463, Accuracy = 55.13%\n",
            "Batch 320: Loss = 1.8804, Accuracy = 55.06%\n",
            "Batch 330: Loss = 1.4943, Accuracy = 55.11%\n",
            "Batch 340: Loss = 1.4744, Accuracy = 55.10%\n",
            "Batch 350: Loss = 1.7712, Accuracy = 55.08%\n",
            "Batch 360: Loss = 1.1370, Accuracy = 55.17%\n",
            "Batch 370: Loss = 1.4409, Accuracy = 55.17%\n",
            "Batch 380: Loss = 1.6223, Accuracy = 55.22%\n",
            "Batch 390: Loss = 1.9284, Accuracy = 55.17%\n",
            "Epoch 11: Total Loss = 1.7643, Total Accuracy = 55.17%\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "Batch 0: Benign Loss = 2.0023, Adversarial Loss = 2.0023\n",
            "Batch 10: Benign Loss = 1.6753, Adversarial Loss = 1.6753\n",
            "Batch 20: Benign Loss = 2.0859, Adversarial Loss = 2.0859\n",
            "Batch 30: Benign Loss = 1.7399, Adversarial Loss = 1.7399\n",
            "Batch 40: Benign Loss = 1.6081, Adversarial Loss = 1.6081\n",
            "Batch 50: Benign Loss = 1.8182, Adversarial Loss = 1.8182\n",
            "Batch 60: Benign Loss = 1.8754, Adversarial Loss = 1.8754\n",
            "Batch 70: Benign Loss = 1.8935, Adversarial Loss = 1.8935\n",
            "Batch 80: Benign Loss = 1.6290, Adversarial Loss = 1.6290\n",
            "Batch 90: Benign Loss = 1.7539, Adversarial Loss = 1.7539\n",
            "Epoch 11: Benign Accuracy = 20.34%, Adversarial Accuracy = 55.69%\n",
            "Benign Loss = 4.1611, Adversarial Loss = 1.8202\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "Batch 0: Loss = 1.8224, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.3803, Accuracy = 55.82%\n",
            "Batch 20: Loss = 1.8441, Accuracy = 55.69%\n",
            "Batch 30: Loss = 1.9176, Accuracy = 55.82%\n",
            "Batch 40: Loss = 1.9684, Accuracy = 55.43%\n",
            "Batch 50: Loss = 1.7204, Accuracy = 55.58%\n",
            "Batch 60: Loss = 1.6860, Accuracy = 55.49%\n",
            "Batch 70: Loss = 1.7362, Accuracy = 55.17%\n",
            "Batch 80: Loss = 1.6337, Accuracy = 55.28%\n",
            "Batch 90: Loss = 2.4668, Accuracy = 55.20%\n",
            "Batch 100: Loss = 1.2228, Accuracy = 55.21%\n",
            "Batch 110: Loss = 1.4622, Accuracy = 55.35%\n",
            "Batch 120: Loss = 1.6831, Accuracy = 55.17%\n",
            "Batch 130: Loss = 1.3891, Accuracy = 55.08%\n",
            "Batch 140: Loss = 1.4763, Accuracy = 55.11%\n",
            "Batch 150: Loss = 1.6181, Accuracy = 55.18%\n",
            "Batch 160: Loss = 2.1136, Accuracy = 55.04%\n",
            "Batch 170: Loss = 1.9797, Accuracy = 54.90%\n",
            "Batch 180: Loss = 1.4328, Accuracy = 55.01%\n",
            "Batch 190: Loss = 2.1647, Accuracy = 55.12%\n",
            "Batch 200: Loss = 2.0023, Accuracy = 55.14%\n",
            "Batch 210: Loss = 1.6789, Accuracy = 55.15%\n",
            "Batch 220: Loss = 1.8239, Accuracy = 55.16%\n",
            "Batch 230: Loss = 1.5927, Accuracy = 55.16%\n",
            "Batch 240: Loss = 1.1234, Accuracy = 55.21%\n",
            "Batch 250: Loss = 1.7609, Accuracy = 55.22%\n",
            "Batch 260: Loss = 1.6931, Accuracy = 55.21%\n",
            "Batch 270: Loss = 2.1740, Accuracy = 55.16%\n",
            "Batch 280: Loss = 1.7126, Accuracy = 55.15%\n",
            "Batch 290: Loss = 1.3632, Accuracy = 55.20%\n",
            "Batch 300: Loss = 1.3885, Accuracy = 55.30%\n",
            "Batch 310: Loss = 1.4860, Accuracy = 55.30%\n",
            "Batch 320: Loss = 1.5015, Accuracy = 55.25%\n",
            "Batch 330: Loss = 2.2086, Accuracy = 55.26%\n",
            "Batch 340: Loss = 1.7557, Accuracy = 55.28%\n",
            "Batch 350: Loss = 1.6783, Accuracy = 55.36%\n",
            "Batch 360: Loss = 1.7131, Accuracy = 55.33%\n",
            "Batch 370: Loss = 1.8424, Accuracy = 55.30%\n",
            "Batch 380: Loss = 1.8935, Accuracy = 55.28%\n",
            "Batch 390: Loss = 1.7638, Accuracy = 55.30%\n",
            "Epoch 12: Total Loss = 1.7627, Total Accuracy = 55.30%\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "Batch 0: Benign Loss = 2.0806, Adversarial Loss = 2.0806\n",
            "Batch 10: Benign Loss = 1.7124, Adversarial Loss = 1.7124\n",
            "Batch 20: Benign Loss = 2.1449, Adversarial Loss = 2.1449\n",
            "Batch 30: Benign Loss = 1.7812, Adversarial Loss = 1.7812\n",
            "Batch 40: Benign Loss = 1.6631, Adversarial Loss = 1.6631\n",
            "Batch 50: Benign Loss = 1.8234, Adversarial Loss = 1.8234\n",
            "Batch 60: Benign Loss = 1.9377, Adversarial Loss = 1.9377\n",
            "Batch 70: Benign Loss = 1.9275, Adversarial Loss = 1.9275\n",
            "Batch 80: Benign Loss = 1.6950, Adversarial Loss = 1.6950\n",
            "Batch 90: Benign Loss = 1.8051, Adversarial Loss = 1.8051\n",
            "Epoch 12: Benign Accuracy = 19.37%, Adversarial Accuracy = 55.52%\n",
            "Benign Loss = 4.7742, Adversarial Loss = 1.8579\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "Batch 0: Loss = 1.8465, Accuracy = 53.12%\n",
            "Batch 10: Loss = 2.1225, Accuracy = 55.47%\n",
            "Batch 20: Loss = 1.5637, Accuracy = 55.17%\n",
            "Batch 30: Loss = 1.6866, Accuracy = 55.39%\n",
            "Batch 40: Loss = 2.2827, Accuracy = 54.76%\n",
            "Batch 50: Loss = 2.0449, Accuracy = 54.63%\n",
            "Batch 60: Loss = 1.5000, Accuracy = 54.85%\n",
            "Batch 70: Loss = 1.6031, Accuracy = 55.27%\n",
            "Batch 80: Loss = 2.0386, Accuracy = 55.25%\n",
            "Batch 90: Loss = 2.1100, Accuracy = 55.13%\n",
            "Batch 100: Loss = 1.5672, Accuracy = 55.20%\n",
            "Batch 110: Loss = 1.9092, Accuracy = 55.27%\n",
            "Batch 120: Loss = 1.6812, Accuracy = 55.24%\n",
            "Batch 130: Loss = 2.0172, Accuracy = 55.21%\n",
            "Batch 140: Loss = 1.8998, Accuracy = 55.36%\n",
            "Batch 150: Loss = 1.8197, Accuracy = 55.31%\n",
            "Batch 160: Loss = 1.6382, Accuracy = 55.43%\n",
            "Batch 170: Loss = 1.8878, Accuracy = 55.48%\n",
            "Batch 180: Loss = 1.5616, Accuracy = 55.41%\n",
            "Batch 190: Loss = 1.6306, Accuracy = 55.47%\n",
            "Batch 200: Loss = 2.1565, Accuracy = 55.39%\n",
            "Batch 210: Loss = 1.3741, Accuracy = 55.39%\n",
            "Batch 220: Loss = 1.7690, Accuracy = 55.40%\n",
            "Batch 230: Loss = 1.8596, Accuracy = 55.43%\n",
            "Batch 240: Loss = 1.9572, Accuracy = 55.48%\n",
            "Batch 250: Loss = 1.5798, Accuracy = 55.50%\n",
            "Batch 260: Loss = 2.1404, Accuracy = 55.42%\n",
            "Batch 270: Loss = 1.5428, Accuracy = 55.46%\n",
            "Batch 280: Loss = 1.6726, Accuracy = 55.45%\n",
            "Batch 290: Loss = 1.9016, Accuracy = 55.50%\n",
            "Batch 300: Loss = 1.7854, Accuracy = 55.50%\n",
            "Batch 310: Loss = 1.8841, Accuracy = 55.58%\n",
            "Batch 320: Loss = 1.6784, Accuracy = 55.59%\n",
            "Batch 330: Loss = 2.1277, Accuracy = 55.59%\n",
            "Batch 340: Loss = 1.7482, Accuracy = 55.60%\n",
            "Batch 350: Loss = 1.8297, Accuracy = 55.62%\n",
            "Batch 360: Loss = 1.7053, Accuracy = 55.65%\n",
            "Batch 370: Loss = 1.9532, Accuracy = 55.60%\n",
            "Batch 380: Loss = 1.8221, Accuracy = 55.59%\n",
            "Batch 390: Loss = 2.7533, Accuracy = 55.56%\n",
            "Epoch 13: Total Loss = 1.7582, Total Accuracy = 55.56%\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "Batch 0: Benign Loss = 2.0191, Adversarial Loss = 2.0191\n",
            "Batch 10: Benign Loss = 1.6716, Adversarial Loss = 1.6716\n",
            "Batch 20: Benign Loss = 2.0826, Adversarial Loss = 2.0826\n",
            "Batch 30: Benign Loss = 1.7447, Adversarial Loss = 1.7447\n",
            "Batch 40: Benign Loss = 1.6089, Adversarial Loss = 1.6089\n",
            "Batch 50: Benign Loss = 1.7769, Adversarial Loss = 1.7769\n",
            "Batch 60: Benign Loss = 1.8871, Adversarial Loss = 1.8871\n",
            "Batch 70: Benign Loss = 1.8904, Adversarial Loss = 1.8904\n",
            "Batch 80: Benign Loss = 1.6792, Adversarial Loss = 1.6792\n",
            "Batch 90: Benign Loss = 1.7699, Adversarial Loss = 1.7699\n",
            "Epoch 13: Benign Accuracy = 18.66%, Adversarial Accuracy = 55.67%\n",
            "Benign Loss = 5.4572, Adversarial Loss = 1.8158\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "Batch 0: Loss = 1.6999, Accuracy = 56.25%\n",
            "Batch 10: Loss = 1.7170, Accuracy = 53.12%\n",
            "Batch 20: Loss = 2.1779, Accuracy = 54.09%\n",
            "Batch 30: Loss = 2.1601, Accuracy = 54.44%\n",
            "Batch 40: Loss = 1.6581, Accuracy = 54.74%\n",
            "Batch 50: Loss = 2.0946, Accuracy = 54.50%\n",
            "Batch 60: Loss = 2.0107, Accuracy = 54.43%\n",
            "Batch 70: Loss = 1.9716, Accuracy = 54.83%\n",
            "Batch 80: Loss = 1.8456, Accuracy = 54.92%\n",
            "Batch 90: Loss = 1.5048, Accuracy = 55.18%\n",
            "Batch 100: Loss = 1.6696, Accuracy = 55.12%\n",
            "Batch 110: Loss = 1.3760, Accuracy = 55.21%\n",
            "Batch 120: Loss = 1.9871, Accuracy = 55.07%\n",
            "Batch 130: Loss = 1.6382, Accuracy = 55.21%\n",
            "Batch 140: Loss = 1.5002, Accuracy = 55.31%\n",
            "Batch 150: Loss = 1.7090, Accuracy = 55.35%\n",
            "Batch 160: Loss = 1.6820, Accuracy = 55.44%\n",
            "Batch 170: Loss = 1.6900, Accuracy = 55.44%\n",
            "Batch 180: Loss = 2.3517, Accuracy = 55.43%\n",
            "Batch 190: Loss = 1.3972, Accuracy = 55.38%\n",
            "Batch 200: Loss = 1.5913, Accuracy = 55.41%\n",
            "Batch 210: Loss = 1.8019, Accuracy = 55.41%\n",
            "Batch 220: Loss = 1.7700, Accuracy = 55.47%\n",
            "Batch 230: Loss = 2.1120, Accuracy = 55.49%\n",
            "Batch 240: Loss = 1.5490, Accuracy = 55.49%\n",
            "Batch 250: Loss = 1.7197, Accuracy = 55.41%\n",
            "Batch 260: Loss = 1.8529, Accuracy = 55.42%\n",
            "Batch 270: Loss = 1.7217, Accuracy = 55.44%\n",
            "Batch 280: Loss = 1.5754, Accuracy = 55.45%\n",
            "Batch 290: Loss = 2.0810, Accuracy = 55.47%\n",
            "Batch 300: Loss = 1.8023, Accuracy = 55.49%\n",
            "Batch 310: Loss = 1.6398, Accuracy = 55.47%\n",
            "Batch 320: Loss = 1.6020, Accuracy = 55.43%\n",
            "Batch 330: Loss = 1.8944, Accuracy = 55.47%\n",
            "Batch 340: Loss = 1.6329, Accuracy = 55.44%\n",
            "Batch 350: Loss = 2.1199, Accuracy = 55.37%\n",
            "Batch 360: Loss = 2.3602, Accuracy = 55.33%\n",
            "Batch 370: Loss = 1.2767, Accuracy = 55.35%\n",
            "Batch 380: Loss = 1.7691, Accuracy = 55.29%\n",
            "Batch 390: Loss = 2.6149, Accuracy = 55.28%\n",
            "Epoch 14: Total Loss = 1.7644, Total Accuracy = 55.28%\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "Batch 0: Benign Loss = 2.0922, Adversarial Loss = 2.0922\n",
            "Batch 10: Benign Loss = 1.7190, Adversarial Loss = 1.7190\n",
            "Batch 20: Benign Loss = 2.1428, Adversarial Loss = 2.1428\n",
            "Batch 30: Benign Loss = 1.7930, Adversarial Loss = 1.7930\n",
            "Batch 40: Benign Loss = 1.6883, Adversarial Loss = 1.6883\n",
            "Batch 50: Benign Loss = 1.8233, Adversarial Loss = 1.8233\n",
            "Batch 60: Benign Loss = 1.9012, Adversarial Loss = 1.9012\n",
            "Batch 70: Benign Loss = 1.9281, Adversarial Loss = 1.9281\n",
            "Batch 80: Benign Loss = 1.6763, Adversarial Loss = 1.6763\n",
            "Batch 90: Benign Loss = 1.7997, Adversarial Loss = 1.7997\n",
            "Epoch 14: Benign Accuracy = 19.74%, Adversarial Accuracy = 55.84%\n",
            "Benign Loss = 4.4315, Adversarial Loss = 1.8626\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "Batch 0: Loss = 1.4486, Accuracy = 57.81%\n",
            "Batch 10: Loss = 2.0722, Accuracy = 54.55%\n",
            "Batch 20: Loss = 1.8456, Accuracy = 54.09%\n",
            "Batch 30: Loss = 1.7868, Accuracy = 54.81%\n",
            "Batch 40: Loss = 1.7072, Accuracy = 55.01%\n",
            "Batch 50: Loss = 1.6590, Accuracy = 55.13%\n",
            "Batch 60: Loss = 1.4294, Accuracy = 55.15%\n",
            "Batch 70: Loss = 1.6051, Accuracy = 55.15%\n",
            "Batch 80: Loss = 1.5210, Accuracy = 55.14%\n",
            "Batch 90: Loss = 1.6065, Accuracy = 54.88%\n",
            "Batch 100: Loss = 1.7054, Accuracy = 54.77%\n",
            "Batch 110: Loss = 1.7041, Accuracy = 55.12%\n",
            "Batch 120: Loss = 2.2466, Accuracy = 55.15%\n",
            "Batch 130: Loss = 1.6633, Accuracy = 55.20%\n",
            "Batch 140: Loss = 2.0421, Accuracy = 55.15%\n",
            "Batch 150: Loss = 1.7053, Accuracy = 55.24%\n",
            "Batch 160: Loss = 1.4306, Accuracy = 55.32%\n",
            "Batch 170: Loss = 1.7093, Accuracy = 55.30%\n",
            "Batch 180: Loss = 1.8411, Accuracy = 55.35%\n",
            "Batch 190: Loss = 1.6270, Accuracy = 55.38%\n",
            "Batch 200: Loss = 1.6872, Accuracy = 55.40%\n",
            "Batch 210: Loss = 2.0899, Accuracy = 55.51%\n",
            "Batch 220: Loss = 1.5953, Accuracy = 55.61%\n",
            "Batch 230: Loss = 2.1405, Accuracy = 55.59%\n",
            "Batch 240: Loss = 2.0030, Accuracy = 55.62%\n",
            "Batch 250: Loss = 2.8101, Accuracy = 55.63%\n",
            "Batch 260: Loss = 1.7830, Accuracy = 55.58%\n",
            "Batch 270: Loss = 1.7897, Accuracy = 55.50%\n",
            "Batch 280: Loss = 1.4897, Accuracy = 55.57%\n",
            "Batch 290: Loss = 2.0221, Accuracy = 55.58%\n",
            "Batch 300: Loss = 1.8420, Accuracy = 55.58%\n",
            "Batch 310: Loss = 1.5116, Accuracy = 55.60%\n",
            "Batch 320: Loss = 1.8140, Accuracy = 55.63%\n",
            "Batch 330: Loss = 1.9844, Accuracy = 55.64%\n",
            "Batch 340: Loss = 2.0044, Accuracy = 55.66%\n",
            "Batch 350: Loss = 1.5871, Accuracy = 55.56%\n",
            "Batch 360: Loss = 1.7526, Accuracy = 55.51%\n",
            "Batch 370: Loss = 1.7043, Accuracy = 55.56%\n",
            "Batch 380: Loss = 1.9276, Accuracy = 55.55%\n",
            "Batch 390: Loss = 2.6807, Accuracy = 55.51%\n",
            "Epoch 15: Total Loss = 1.7602, Total Accuracy = 55.51%\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "Batch 0: Benign Loss = 2.0592, Adversarial Loss = 2.0592\n",
            "Batch 10: Benign Loss = 1.6865, Adversarial Loss = 1.6865\n",
            "Batch 20: Benign Loss = 2.1053, Adversarial Loss = 2.1053\n",
            "Batch 30: Benign Loss = 1.7639, Adversarial Loss = 1.7639\n",
            "Batch 40: Benign Loss = 1.5971, Adversarial Loss = 1.5971\n",
            "Batch 50: Benign Loss = 1.7248, Adversarial Loss = 1.7248\n",
            "Batch 60: Benign Loss = 1.9350, Adversarial Loss = 1.9350\n",
            "Batch 70: Benign Loss = 1.9260, Adversarial Loss = 1.9260\n",
            "Batch 80: Benign Loss = 1.6748, Adversarial Loss = 1.6748\n",
            "Batch 90: Benign Loss = 1.7985, Adversarial Loss = 1.7985\n",
            "Epoch 15: Benign Accuracy = 20.31%, Adversarial Accuracy = 55.43%\n",
            "Benign Loss = 4.1382, Adversarial Loss = 1.8436\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "Batch 0: Loss = 1.5527, Accuracy = 56.25%\n",
            "Batch 10: Loss = 1.5724, Accuracy = 55.97%\n",
            "Batch 20: Loss = 1.6140, Accuracy = 56.51%\n",
            "Batch 30: Loss = 1.7397, Accuracy = 55.87%\n",
            "Batch 40: Loss = 1.9445, Accuracy = 55.72%\n",
            "Batch 50: Loss = 2.2120, Accuracy = 55.45%\n",
            "Batch 60: Loss = 2.0548, Accuracy = 55.35%\n",
            "Batch 70: Loss = 1.2841, Accuracy = 55.47%\n",
            "Batch 80: Loss = 2.0514, Accuracy = 55.54%\n",
            "Batch 90: Loss = 1.6411, Accuracy = 55.19%\n",
            "Batch 100: Loss = 1.9654, Accuracy = 55.11%\n",
            "Batch 110: Loss = 1.6650, Accuracy = 55.05%\n",
            "Batch 120: Loss = 1.6689, Accuracy = 55.00%\n",
            "Batch 130: Loss = 1.7256, Accuracy = 54.94%\n",
            "Batch 140: Loss = 1.7006, Accuracy = 55.02%\n",
            "Batch 150: Loss = 1.7917, Accuracy = 55.10%\n",
            "Batch 160: Loss = 1.5501, Accuracy = 55.08%\n",
            "Batch 170: Loss = 2.0221, Accuracy = 54.99%\n",
            "Batch 180: Loss = 1.8447, Accuracy = 54.99%\n",
            "Batch 190: Loss = 1.9066, Accuracy = 55.02%\n",
            "Batch 200: Loss = 1.5675, Accuracy = 55.12%\n",
            "Batch 210: Loss = 1.6098, Accuracy = 55.13%\n",
            "Batch 220: Loss = 1.9185, Accuracy = 54.94%\n",
            "Batch 230: Loss = 1.8510, Accuracy = 55.00%\n",
            "Batch 240: Loss = 1.7227, Accuracy = 55.12%\n",
            "Batch 250: Loss = 1.6983, Accuracy = 55.10%\n",
            "Batch 260: Loss = 1.4571, Accuracy = 55.14%\n",
            "Batch 270: Loss = 1.5442, Accuracy = 55.18%\n",
            "Batch 280: Loss = 1.8989, Accuracy = 55.30%\n",
            "Batch 290: Loss = 1.7341, Accuracy = 55.26%\n",
            "Batch 300: Loss = 2.0375, Accuracy = 55.22%\n",
            "Batch 310: Loss = 1.3849, Accuracy = 55.20%\n",
            "Batch 320: Loss = 1.5001, Accuracy = 55.26%\n",
            "Batch 330: Loss = 1.8183, Accuracy = 55.29%\n",
            "Batch 340: Loss = 2.0600, Accuracy = 55.24%\n",
            "Batch 350: Loss = 1.4639, Accuracy = 55.26%\n",
            "Batch 360: Loss = 1.3548, Accuracy = 55.23%\n",
            "Batch 370: Loss = 1.8925, Accuracy = 55.19%\n",
            "Batch 380: Loss = 1.8266, Accuracy = 55.19%\n",
            "Batch 390: Loss = 1.6890, Accuracy = 55.21%\n",
            "Epoch 16: Total Loss = 1.7580, Total Accuracy = 55.21%\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "Batch 0: Benign Loss = 2.0065, Adversarial Loss = 2.0065\n",
            "Batch 10: Benign Loss = 1.6438, Adversarial Loss = 1.6438\n",
            "Batch 20: Benign Loss = 2.0883, Adversarial Loss = 2.0883\n",
            "Batch 30: Benign Loss = 1.7441, Adversarial Loss = 1.7441\n",
            "Batch 40: Benign Loss = 1.6420, Adversarial Loss = 1.6420\n",
            "Batch 50: Benign Loss = 1.7779, Adversarial Loss = 1.7779\n",
            "Batch 60: Benign Loss = 1.8905, Adversarial Loss = 1.8905\n",
            "Batch 70: Benign Loss = 1.8567, Adversarial Loss = 1.8567\n",
            "Batch 80: Benign Loss = 1.6564, Adversarial Loss = 1.6564\n",
            "Batch 90: Benign Loss = 1.7680, Adversarial Loss = 1.7680\n",
            "Epoch 16: Benign Accuracy = 20.89%, Adversarial Accuracy = 55.77%\n",
            "Benign Loss = 3.8864, Adversarial Loss = 1.8099\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "Batch 0: Loss = 1.7271, Accuracy = 51.56%\n",
            "Batch 10: Loss = 1.6579, Accuracy = 53.69%\n",
            "Batch 20: Loss = 1.9926, Accuracy = 54.17%\n",
            "Batch 30: Loss = 2.2215, Accuracy = 54.23%\n",
            "Batch 40: Loss = 2.0177, Accuracy = 54.59%\n",
            "Batch 50: Loss = 1.7354, Accuracy = 54.67%\n",
            "Batch 60: Loss = 2.0111, Accuracy = 54.73%\n",
            "Batch 70: Loss = 1.2849, Accuracy = 54.86%\n",
            "Batch 80: Loss = 2.0252, Accuracy = 54.82%\n",
            "Batch 90: Loss = 1.8812, Accuracy = 54.76%\n",
            "Batch 100: Loss = 1.5695, Accuracy = 54.73%\n",
            "Batch 110: Loss = 1.6238, Accuracy = 54.85%\n",
            "Batch 120: Loss = 1.4810, Accuracy = 54.93%\n",
            "Batch 130: Loss = 1.7642, Accuracy = 55.09%\n",
            "Batch 140: Loss = 2.3124, Accuracy = 54.95%\n",
            "Batch 150: Loss = 1.7123, Accuracy = 54.97%\n",
            "Batch 160: Loss = 1.7412, Accuracy = 54.99%\n",
            "Batch 170: Loss = 1.4433, Accuracy = 55.06%\n",
            "Batch 180: Loss = 1.7272, Accuracy = 54.98%\n",
            "Batch 190: Loss = 1.5479, Accuracy = 55.01%\n",
            "Batch 200: Loss = 1.8081, Accuracy = 55.03%\n",
            "Batch 210: Loss = 1.4204, Accuracy = 55.04%\n",
            "Batch 220: Loss = 1.4649, Accuracy = 55.13%\n",
            "Batch 230: Loss = 2.0458, Accuracy = 55.11%\n",
            "Batch 240: Loss = 1.5191, Accuracy = 55.06%\n",
            "Batch 250: Loss = 1.8376, Accuracy = 54.99%\n",
            "Batch 260: Loss = 1.5733, Accuracy = 55.02%\n",
            "Batch 270: Loss = 1.9284, Accuracy = 55.17%\n",
            "Batch 280: Loss = 1.2574, Accuracy = 55.14%\n",
            "Batch 290: Loss = 1.8297, Accuracy = 55.09%\n",
            "Batch 300: Loss = 1.6295, Accuracy = 55.15%\n",
            "Batch 310: Loss = 1.3166, Accuracy = 55.15%\n",
            "Batch 320: Loss = 1.5988, Accuracy = 55.19%\n",
            "Batch 330: Loss = 1.6260, Accuracy = 55.17%\n",
            "Batch 340: Loss = 1.5978, Accuracy = 55.19%\n",
            "Batch 350: Loss = 1.5310, Accuracy = 55.20%\n",
            "Batch 360: Loss = 1.9571, Accuracy = 55.22%\n",
            "Batch 370: Loss = 1.5983, Accuracy = 55.27%\n",
            "Batch 380: Loss = 1.3866, Accuracy = 55.34%\n",
            "Batch 390: Loss = 2.0453, Accuracy = 55.28%\n",
            "Epoch 17: Total Loss = 1.7668, Total Accuracy = 55.28%\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "Batch 0: Benign Loss = 2.0472, Adversarial Loss = 2.0472\n",
            "Batch 10: Benign Loss = 1.6552, Adversarial Loss = 1.6552\n",
            "Batch 20: Benign Loss = 2.1218, Adversarial Loss = 2.1218\n",
            "Batch 30: Benign Loss = 1.7729, Adversarial Loss = 1.7729\n",
            "Batch 40: Benign Loss = 1.6563, Adversarial Loss = 1.6563\n",
            "Batch 50: Benign Loss = 1.7523, Adversarial Loss = 1.7523\n",
            "Batch 60: Benign Loss = 1.8897, Adversarial Loss = 1.8897\n",
            "Batch 70: Benign Loss = 1.8773, Adversarial Loss = 1.8773\n",
            "Batch 80: Benign Loss = 1.6704, Adversarial Loss = 1.6704\n",
            "Batch 90: Benign Loss = 1.7865, Adversarial Loss = 1.7865\n",
            "Epoch 17: Benign Accuracy = 19.63%, Adversarial Accuracy = 56.01%\n",
            "Benign Loss = 4.9126, Adversarial Loss = 1.8332\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "Batch 0: Loss = 1.6884, Accuracy = 58.59%\n",
            "Batch 10: Loss = 1.3740, Accuracy = 55.89%\n",
            "Batch 20: Loss = 1.6906, Accuracy = 55.06%\n",
            "Batch 30: Loss = 1.8811, Accuracy = 55.54%\n",
            "Batch 40: Loss = 2.0619, Accuracy = 56.00%\n",
            "Batch 50: Loss = 1.6997, Accuracy = 56.59%\n",
            "Batch 60: Loss = 1.9663, Accuracy = 56.76%\n",
            "Batch 70: Loss = 1.8579, Accuracy = 56.57%\n",
            "Batch 80: Loss = 1.7739, Accuracy = 56.63%\n",
            "Batch 90: Loss = 1.5071, Accuracy = 56.40%\n",
            "Batch 100: Loss = 1.8373, Accuracy = 56.01%\n",
            "Batch 110: Loss = 1.4464, Accuracy = 56.05%\n",
            "Batch 120: Loss = 1.5633, Accuracy = 56.01%\n",
            "Batch 130: Loss = 1.4565, Accuracy = 55.96%\n",
            "Batch 140: Loss = 1.5476, Accuracy = 55.77%\n",
            "Batch 150: Loss = 1.7313, Accuracy = 55.74%\n",
            "Batch 160: Loss = 1.8036, Accuracy = 55.86%\n",
            "Batch 170: Loss = 1.6436, Accuracy = 55.92%\n",
            "Batch 180: Loss = 1.9185, Accuracy = 55.90%\n",
            "Batch 190: Loss = 1.4166, Accuracy = 55.79%\n",
            "Batch 200: Loss = 2.1478, Accuracy = 55.78%\n",
            "Batch 210: Loss = 2.2044, Accuracy = 55.69%\n",
            "Batch 220: Loss = 2.0275, Accuracy = 55.66%\n",
            "Batch 230: Loss = 2.1694, Accuracy = 55.56%\n",
            "Batch 240: Loss = 1.8144, Accuracy = 55.59%\n",
            "Batch 250: Loss = 1.6690, Accuracy = 55.55%\n",
            "Batch 260: Loss = 1.7846, Accuracy = 55.63%\n",
            "Batch 270: Loss = 1.5972, Accuracy = 55.66%\n",
            "Batch 280: Loss = 1.8610, Accuracy = 55.72%\n",
            "Batch 290: Loss = 1.8525, Accuracy = 55.65%\n",
            "Batch 300: Loss = 1.8651, Accuracy = 55.55%\n",
            "Batch 310: Loss = 1.7251, Accuracy = 55.50%\n",
            "Batch 320: Loss = 1.9710, Accuracy = 55.44%\n",
            "Batch 330: Loss = 1.9178, Accuracy = 55.45%\n",
            "Batch 340: Loss = 1.7602, Accuracy = 55.49%\n",
            "Batch 350: Loss = 1.6112, Accuracy = 55.52%\n",
            "Batch 360: Loss = 1.9948, Accuracy = 55.49%\n",
            "Batch 370: Loss = 1.7760, Accuracy = 55.49%\n",
            "Batch 380: Loss = 2.0068, Accuracy = 55.37%\n",
            "Batch 390: Loss = 2.1647, Accuracy = 55.42%\n",
            "Epoch 18: Total Loss = 1.7662, Total Accuracy = 55.42%\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "Batch 0: Benign Loss = 2.0066, Adversarial Loss = 2.0066\n",
            "Batch 10: Benign Loss = 1.6824, Adversarial Loss = 1.6824\n",
            "Batch 20: Benign Loss = 2.0719, Adversarial Loss = 2.0719\n",
            "Batch 30: Benign Loss = 1.7402, Adversarial Loss = 1.7402\n",
            "Batch 40: Benign Loss = 1.6088, Adversarial Loss = 1.6088\n",
            "Batch 50: Benign Loss = 1.7949, Adversarial Loss = 1.7949\n",
            "Batch 60: Benign Loss = 1.8625, Adversarial Loss = 1.8625\n",
            "Batch 70: Benign Loss = 1.8564, Adversarial Loss = 1.8564\n",
            "Batch 80: Benign Loss = 1.6477, Adversarial Loss = 1.6477\n",
            "Batch 90: Benign Loss = 1.7735, Adversarial Loss = 1.7735\n",
            "Epoch 18: Benign Accuracy = 20.33%, Adversarial Accuracy = 55.82%\n",
            "Benign Loss = 4.0577, Adversarial Loss = 1.8088\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "Batch 0: Loss = 1.6785, Accuracy = 55.47%\n",
            "Batch 10: Loss = 1.7371, Accuracy = 51.99%\n",
            "Batch 20: Loss = 1.7153, Accuracy = 53.50%\n",
            "Batch 30: Loss = 1.6410, Accuracy = 53.73%\n",
            "Batch 40: Loss = 1.7830, Accuracy = 53.87%\n",
            "Batch 50: Loss = 1.6580, Accuracy = 54.30%\n",
            "Batch 60: Loss = 1.8096, Accuracy = 54.83%\n",
            "Batch 70: Loss = 2.0959, Accuracy = 55.00%\n",
            "Batch 80: Loss = 1.7650, Accuracy = 54.92%\n",
            "Batch 90: Loss = 1.7630, Accuracy = 54.73%\n",
            "Batch 100: Loss = 1.7348, Accuracy = 54.82%\n",
            "Batch 110: Loss = 2.1096, Accuracy = 54.79%\n",
            "Batch 120: Loss = 1.5975, Accuracy = 54.71%\n",
            "Batch 130: Loss = 1.6762, Accuracy = 54.62%\n",
            "Batch 140: Loss = 2.0727, Accuracy = 54.56%\n",
            "Batch 150: Loss = 1.9552, Accuracy = 54.62%\n",
            "Batch 160: Loss = 2.1414, Accuracy = 54.54%\n",
            "Batch 170: Loss = 1.7670, Accuracy = 54.53%\n",
            "Batch 180: Loss = 1.8036, Accuracy = 54.60%\n",
            "Batch 190: Loss = 1.9582, Accuracy = 54.78%\n",
            "Batch 200: Loss = 2.2170, Accuracy = 54.75%\n",
            "Batch 210: Loss = 1.5564, Accuracy = 54.78%\n",
            "Batch 220: Loss = 1.5298, Accuracy = 54.77%\n",
            "Batch 230: Loss = 1.2554, Accuracy = 54.81%\n",
            "Batch 240: Loss = 1.6991, Accuracy = 54.83%\n",
            "Batch 250: Loss = 1.6954, Accuracy = 54.71%\n",
            "Batch 260: Loss = 1.3347, Accuracy = 54.78%\n",
            "Batch 270: Loss = 1.4979, Accuracy = 54.89%\n",
            "Batch 280: Loss = 1.7206, Accuracy = 54.88%\n",
            "Batch 290: Loss = 1.6235, Accuracy = 54.93%\n",
            "Batch 300: Loss = 1.5756, Accuracy = 54.96%\n",
            "Batch 310: Loss = 1.6928, Accuracy = 54.95%\n",
            "Batch 320: Loss = 1.6272, Accuracy = 54.97%\n",
            "Batch 330: Loss = 1.8846, Accuracy = 55.03%\n",
            "Batch 340: Loss = 1.6164, Accuracy = 55.03%\n",
            "Batch 350: Loss = 1.4804, Accuracy = 55.08%\n",
            "Batch 360: Loss = 1.7415, Accuracy = 55.12%\n",
            "Batch 370: Loss = 2.1975, Accuracy = 55.07%\n",
            "Batch 380: Loss = 1.7024, Accuracy = 55.06%\n",
            "Batch 390: Loss = 1.6736, Accuracy = 55.09%\n",
            "Epoch 19: Total Loss = 1.7635, Total Accuracy = 55.09%\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "Batch 0: Benign Loss = 1.9938, Adversarial Loss = 1.9938\n",
            "Batch 10: Benign Loss = 1.5860, Adversarial Loss = 1.5860\n",
            "Batch 20: Benign Loss = 2.0900, Adversarial Loss = 2.0900\n",
            "Batch 30: Benign Loss = 1.7226, Adversarial Loss = 1.7226\n",
            "Batch 40: Benign Loss = 1.5735, Adversarial Loss = 1.5735\n",
            "Batch 50: Benign Loss = 1.7210, Adversarial Loss = 1.7210\n",
            "Batch 60: Benign Loss = 1.8516, Adversarial Loss = 1.8516\n",
            "Batch 70: Benign Loss = 1.8610, Adversarial Loss = 1.8610\n",
            "Batch 80: Benign Loss = 1.6277, Adversarial Loss = 1.6277\n",
            "Batch 90: Benign Loss = 1.7329, Adversarial Loss = 1.7329\n",
            "Epoch 19: Benign Accuracy = 21.50%, Adversarial Accuracy = 55.93%\n",
            "Benign Loss = 3.6671, Adversarial Loss = 1.7861\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "Batch 0: Loss = 1.6277, Accuracy = 54.69%\n",
            "Batch 10: Loss = 1.7334, Accuracy = 56.18%\n",
            "Batch 20: Loss = 1.7089, Accuracy = 55.73%\n",
            "Batch 30: Loss = 2.0165, Accuracy = 55.24%\n",
            "Batch 40: Loss = 1.5376, Accuracy = 55.45%\n",
            "Batch 50: Loss = 1.9998, Accuracy = 55.56%\n",
            "Batch 60: Loss = 1.4002, Accuracy = 55.62%\n",
            "Batch 70: Loss = 1.8802, Accuracy = 55.39%\n",
            "Batch 80: Loss = 1.6840, Accuracy = 55.36%\n",
            "Batch 90: Loss = 1.7871, Accuracy = 55.39%\n",
            "Batch 100: Loss = 1.9694, Accuracy = 55.40%\n",
            "Batch 110: Loss = 1.7204, Accuracy = 55.37%\n",
            "Batch 120: Loss = 1.7244, Accuracy = 55.43%\n",
            "Batch 130: Loss = 1.8189, Accuracy = 55.45%\n",
            "Batch 140: Loss = 2.0059, Accuracy = 55.32%\n",
            "Batch 150: Loss = 1.4507, Accuracy = 55.25%\n",
            "Batch 160: Loss = 2.1177, Accuracy = 55.20%\n",
            "Batch 170: Loss = 1.9292, Accuracy = 55.12%\n",
            "Batch 180: Loss = 1.7485, Accuracy = 55.19%\n",
            "Batch 190: Loss = 1.9622, Accuracy = 55.16%\n",
            "Batch 200: Loss = 1.7341, Accuracy = 55.12%\n",
            "Batch 210: Loss = 1.5914, Accuracy = 55.10%\n",
            "Batch 220: Loss = 1.2267, Accuracy = 55.15%\n",
            "Batch 230: Loss = 1.6282, Accuracy = 55.16%\n",
            "Batch 240: Loss = 2.0588, Accuracy = 55.16%\n",
            "Batch 250: Loss = 1.8609, Accuracy = 55.14%\n",
            "Batch 260: Loss = 2.2846, Accuracy = 55.12%\n",
            "Batch 270: Loss = 1.7888, Accuracy = 55.14%\n",
            "Batch 280: Loss = 2.1942, Accuracy = 55.17%\n",
            "Batch 290: Loss = 1.8484, Accuracy = 55.22%\n",
            "Batch 300: Loss = 2.0327, Accuracy = 55.15%\n",
            "Batch 310: Loss = 1.5055, Accuracy = 55.17%\n",
            "Batch 320: Loss = 1.6704, Accuracy = 55.19%\n",
            "Batch 330: Loss = 1.7445, Accuracy = 55.17%\n",
            "Batch 340: Loss = 1.8236, Accuracy = 55.19%\n",
            "Batch 350: Loss = 1.4712, Accuracy = 55.20%\n",
            "Batch 360: Loss = 2.0745, Accuracy = 55.17%\n",
            "Batch 370: Loss = 1.9798, Accuracy = 55.14%\n",
            "Batch 380: Loss = 1.4637, Accuracy = 55.17%\n",
            "Batch 390: Loss = 2.0797, Accuracy = 55.15%\n",
            "Epoch 20: Total Loss = 1.7778, Total Accuracy = 55.15%\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "Batch 0: Benign Loss = 2.0463, Adversarial Loss = 2.0463\n",
            "Batch 10: Benign Loss = 1.6993, Adversarial Loss = 1.6993\n",
            "Batch 20: Benign Loss = 2.1199, Adversarial Loss = 2.1199\n",
            "Batch 30: Benign Loss = 1.7593, Adversarial Loss = 1.7593\n",
            "Batch 40: Benign Loss = 1.5945, Adversarial Loss = 1.5945\n",
            "Batch 50: Benign Loss = 1.7358, Adversarial Loss = 1.7358\n",
            "Batch 60: Benign Loss = 1.9024, Adversarial Loss = 1.9024\n",
            "Batch 70: Benign Loss = 1.9285, Adversarial Loss = 1.9285\n",
            "Batch 80: Benign Loss = 1.6706, Adversarial Loss = 1.6706\n",
            "Batch 90: Benign Loss = 1.8067, Adversarial Loss = 1.8067\n",
            "Epoch 20: Benign Accuracy = 20.29%, Adversarial Accuracy = 55.76%\n",
            "Benign Loss = 4.0935, Adversarial Loss = 1.8383\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "Batch 0: Loss = 1.8983, Accuracy = 49.22%\n",
            "Batch 10: Loss = 1.8106, Accuracy = 55.26%\n",
            "Batch 20: Loss = 1.8389, Accuracy = 55.06%\n",
            "Batch 30: Loss = 2.1633, Accuracy = 55.59%\n",
            "Batch 40: Loss = 1.7808, Accuracy = 56.04%\n",
            "Batch 50: Loss = 1.4537, Accuracy = 55.58%\n",
            "Batch 60: Loss = 1.5255, Accuracy = 55.70%\n",
            "Batch 70: Loss = 1.6100, Accuracy = 55.70%\n",
            "Batch 80: Loss = 1.5726, Accuracy = 55.81%\n",
            "Batch 90: Loss = 1.8406, Accuracy = 55.61%\n",
            "Batch 100: Loss = 2.0179, Accuracy = 55.49%\n",
            "Batch 110: Loss = 1.6994, Accuracy = 55.49%\n",
            "Batch 120: Loss = 1.6152, Accuracy = 55.49%\n",
            "Batch 130: Loss = 1.4937, Accuracy = 55.47%\n",
            "Batch 140: Loss = 1.3510, Accuracy = 55.50%\n",
            "Batch 150: Loss = 1.7454, Accuracy = 55.55%\n",
            "Batch 160: Loss = 2.2024, Accuracy = 55.62%\n",
            "Batch 170: Loss = 1.5374, Accuracy = 55.61%\n",
            "Batch 180: Loss = 2.0317, Accuracy = 55.60%\n",
            "Batch 190: Loss = 1.6887, Accuracy = 55.55%\n",
            "Batch 200: Loss = 1.4118, Accuracy = 55.52%\n",
            "Batch 210: Loss = 1.8149, Accuracy = 55.34%\n",
            "Batch 220: Loss = 1.9429, Accuracy = 55.36%\n",
            "Batch 230: Loss = 1.8941, Accuracy = 55.24%\n",
            "Batch 240: Loss = 1.6117, Accuracy = 55.27%\n",
            "Batch 250: Loss = 1.7876, Accuracy = 55.28%\n",
            "Batch 260: Loss = 1.8382, Accuracy = 55.25%\n",
            "Batch 270: Loss = 1.6370, Accuracy = 55.31%\n",
            "Batch 280: Loss = 1.3381, Accuracy = 55.35%\n",
            "Batch 290: Loss = 2.4008, Accuracy = 55.35%\n",
            "Batch 300: Loss = 1.4107, Accuracy = 55.33%\n",
            "Batch 310: Loss = 1.6358, Accuracy = 55.32%\n",
            "Batch 320: Loss = 1.9196, Accuracy = 55.41%\n",
            "Batch 330: Loss = 1.6562, Accuracy = 55.39%\n",
            "Batch 340: Loss = 1.7718, Accuracy = 55.33%\n",
            "Batch 350: Loss = 1.7141, Accuracy = 55.35%\n",
            "Batch 360: Loss = 2.3125, Accuracy = 55.36%\n",
            "Batch 370: Loss = 1.8957, Accuracy = 55.37%\n",
            "Batch 380: Loss = 1.9167, Accuracy = 55.39%\n",
            "Batch 390: Loss = 2.1795, Accuracy = 55.42%\n",
            "Epoch 21: Total Loss = 1.7668, Total Accuracy = 55.42%\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "Batch 0: Benign Loss = 2.0556, Adversarial Loss = 2.0556\n",
            "Batch 10: Benign Loss = 1.6794, Adversarial Loss = 1.6794\n",
            "Batch 20: Benign Loss = 2.1477, Adversarial Loss = 2.1477\n",
            "Batch 30: Benign Loss = 1.7667, Adversarial Loss = 1.7667\n",
            "Batch 40: Benign Loss = 1.6381, Adversarial Loss = 1.6381\n",
            "Batch 50: Benign Loss = 1.7994, Adversarial Loss = 1.7994\n",
            "Batch 60: Benign Loss = 1.9162, Adversarial Loss = 1.9162\n",
            "Batch 70: Benign Loss = 1.8648, Adversarial Loss = 1.8648\n",
            "Batch 80: Benign Loss = 1.6748, Adversarial Loss = 1.6748\n",
            "Batch 90: Benign Loss = 1.7985, Adversarial Loss = 1.7985\n",
            "Epoch 21: Benign Accuracy = 20.55%, Adversarial Accuracy = 56.25%\n",
            "Benign Loss = 4.2335, Adversarial Loss = 1.8392\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "Batch 0: Loss = 1.5374, Accuracy = 60.94%\n",
            "Batch 10: Loss = 1.6459, Accuracy = 55.61%\n",
            "Batch 20: Loss = 1.6371, Accuracy = 54.28%\n",
            "Batch 30: Loss = 2.0401, Accuracy = 54.44%\n",
            "Batch 40: Loss = 1.5683, Accuracy = 54.86%\n",
            "Batch 50: Loss = 1.6620, Accuracy = 55.50%\n",
            "Batch 60: Loss = 1.7808, Accuracy = 55.78%\n",
            "Batch 70: Loss = 1.7803, Accuracy = 55.30%\n",
            "Batch 80: Loss = 1.5246, Accuracy = 55.52%\n",
            "Batch 90: Loss = 2.0061, Accuracy = 55.43%\n",
            "Batch 100: Loss = 1.8230, Accuracy = 55.56%\n",
            "Batch 110: Loss = 2.0569, Accuracy = 55.50%\n",
            "Batch 120: Loss = 1.7531, Accuracy = 55.69%\n",
            "Batch 130: Loss = 1.7506, Accuracy = 55.61%\n",
            "Batch 140: Loss = 1.7437, Accuracy = 55.57%\n",
            "Batch 150: Loss = 1.8425, Accuracy = 55.64%\n",
            "Batch 160: Loss = 1.6275, Accuracy = 55.47%\n",
            "Batch 170: Loss = 1.7452, Accuracy = 55.46%\n",
            "Batch 180: Loss = 1.5758, Accuracy = 55.45%\n",
            "Batch 190: Loss = 1.8743, Accuracy = 55.42%\n",
            "Batch 200: Loss = 1.6002, Accuracy = 55.50%\n",
            "Batch 210: Loss = 2.2953, Accuracy = 55.35%\n",
            "Batch 220: Loss = 1.5376, Accuracy = 55.42%\n",
            "Batch 230: Loss = 1.8859, Accuracy = 55.39%\n",
            "Batch 240: Loss = 1.6545, Accuracy = 55.37%\n",
            "Batch 250: Loss = 2.1580, Accuracy = 55.33%\n",
            "Batch 260: Loss = 1.6962, Accuracy = 55.40%\n",
            "Batch 270: Loss = 1.4914, Accuracy = 55.49%\n",
            "Batch 280: Loss = 1.7316, Accuracy = 55.49%\n",
            "Batch 290: Loss = 1.6331, Accuracy = 55.48%\n",
            "Batch 300: Loss = 1.5942, Accuracy = 55.48%\n",
            "Batch 310: Loss = 1.7648, Accuracy = 55.46%\n",
            "Batch 320: Loss = 1.8313, Accuracy = 55.45%\n",
            "Batch 330: Loss = 1.5598, Accuracy = 55.43%\n",
            "Batch 340: Loss = 2.1067, Accuracy = 55.42%\n",
            "Batch 350: Loss = 1.7691, Accuracy = 55.39%\n",
            "Batch 360: Loss = 2.0618, Accuracy = 55.36%\n",
            "Batch 370: Loss = 1.5257, Accuracy = 55.39%\n",
            "Batch 380: Loss = 1.9914, Accuracy = 55.32%\n",
            "Batch 390: Loss = 1.7226, Accuracy = 55.27%\n",
            "Epoch 22: Total Loss = 1.7625, Total Accuracy = 55.27%\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "Batch 0: Benign Loss = 2.0261, Adversarial Loss = 2.0261\n",
            "Batch 10: Benign Loss = 1.6802, Adversarial Loss = 1.6802\n",
            "Batch 20: Benign Loss = 2.1086, Adversarial Loss = 2.1086\n",
            "Batch 30: Benign Loss = 1.7618, Adversarial Loss = 1.7618\n",
            "Batch 40: Benign Loss = 1.6067, Adversarial Loss = 1.6067\n",
            "Batch 50: Benign Loss = 1.7286, Adversarial Loss = 1.7286\n",
            "Batch 60: Benign Loss = 1.9409, Adversarial Loss = 1.9409\n",
            "Batch 70: Benign Loss = 1.9418, Adversarial Loss = 1.9418\n",
            "Batch 80: Benign Loss = 1.6499, Adversarial Loss = 1.6499\n",
            "Batch 90: Benign Loss = 1.8174, Adversarial Loss = 1.8174\n",
            "Epoch 22: Benign Accuracy = 21.18%, Adversarial Accuracy = 55.62%\n",
            "Benign Loss = 3.7807, Adversarial Loss = 1.8346\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "Batch 0: Loss = 1.5597, Accuracy = 56.25%\n",
            "Batch 10: Loss = 1.9757, Accuracy = 55.40%\n",
            "Batch 20: Loss = 1.8020, Accuracy = 55.77%\n",
            "Batch 30: Loss = 1.7472, Accuracy = 55.59%\n",
            "Batch 40: Loss = 2.1074, Accuracy = 55.54%\n",
            "Batch 50: Loss = 1.7415, Accuracy = 55.84%\n",
            "Batch 60: Loss = 1.5411, Accuracy = 55.74%\n",
            "Batch 70: Loss = 2.0155, Accuracy = 55.90%\n",
            "Batch 80: Loss = 1.6325, Accuracy = 56.23%\n",
            "Batch 90: Loss = 1.7060, Accuracy = 56.01%\n",
            "Batch 100: Loss = 2.1806, Accuracy = 56.06%\n",
            "Batch 110: Loss = 1.7396, Accuracy = 55.99%\n",
            "Batch 120: Loss = 1.6235, Accuracy = 55.91%\n",
            "Batch 130: Loss = 1.9274, Accuracy = 55.78%\n",
            "Batch 140: Loss = 1.4148, Accuracy = 55.66%\n",
            "Batch 150: Loss = 1.5296, Accuracy = 55.60%\n",
            "Batch 160: Loss = 2.1919, Accuracy = 55.58%\n",
            "Batch 170: Loss = 1.5599, Accuracy = 55.53%\n",
            "Batch 180: Loss = 1.7309, Accuracy = 55.44%\n",
            "Batch 190: Loss = 1.5230, Accuracy = 55.47%\n",
            "Batch 200: Loss = 1.6632, Accuracy = 55.32%\n",
            "Batch 210: Loss = 1.7613, Accuracy = 55.24%\n",
            "Batch 220: Loss = 1.8935, Accuracy = 55.24%\n",
            "Batch 230: Loss = 1.6969, Accuracy = 55.28%\n",
            "Batch 240: Loss = 1.9060, Accuracy = 55.25%\n",
            "Batch 250: Loss = 1.8647, Accuracy = 55.19%\n",
            "Batch 260: Loss = 1.9974, Accuracy = 55.19%\n",
            "Batch 270: Loss = 1.8828, Accuracy = 55.21%\n",
            "Batch 280: Loss = 1.8657, Accuracy = 55.20%\n",
            "Batch 290: Loss = 1.9066, Accuracy = 55.18%\n",
            "Batch 300: Loss = 1.7703, Accuracy = 55.13%\n",
            "Batch 310: Loss = 1.7217, Accuracy = 55.20%\n",
            "Batch 320: Loss = 1.9597, Accuracy = 55.16%\n",
            "Batch 330: Loss = 2.1882, Accuracy = 55.14%\n",
            "Batch 340: Loss = 1.5292, Accuracy = 55.17%\n",
            "Batch 350: Loss = 1.7900, Accuracy = 55.17%\n",
            "Batch 360: Loss = 1.8306, Accuracy = 55.15%\n",
            "Batch 370: Loss = 1.8290, Accuracy = 55.20%\n",
            "Batch 380: Loss = 1.7953, Accuracy = 55.23%\n",
            "Batch 390: Loss = 1.6263, Accuracy = 55.26%\n",
            "Epoch 23: Total Loss = 1.7551, Total Accuracy = 55.26%\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "Batch 0: Benign Loss = 2.0161, Adversarial Loss = 2.0161\n",
            "Batch 10: Benign Loss = 1.6566, Adversarial Loss = 1.6566\n",
            "Batch 20: Benign Loss = 2.1013, Adversarial Loss = 2.1013\n",
            "Batch 30: Benign Loss = 1.7468, Adversarial Loss = 1.7468\n",
            "Batch 40: Benign Loss = 1.6151, Adversarial Loss = 1.6151\n",
            "Batch 50: Benign Loss = 1.7986, Adversarial Loss = 1.7986\n",
            "Batch 60: Benign Loss = 1.8874, Adversarial Loss = 1.8874\n",
            "Batch 70: Benign Loss = 1.8568, Adversarial Loss = 1.8568\n",
            "Batch 80: Benign Loss = 1.6611, Adversarial Loss = 1.6611\n",
            "Batch 90: Benign Loss = 1.7579, Adversarial Loss = 1.7579\n",
            "Epoch 23: Benign Accuracy = 20.32%, Adversarial Accuracy = 56.00%\n",
            "Benign Loss = 4.1869, Adversarial Loss = 1.8118\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "Batch 0: Loss = 1.6693, Accuracy = 50.78%\n",
            "Batch 10: Loss = 1.5709, Accuracy = 55.04%\n",
            "Batch 20: Loss = 1.8736, Accuracy = 54.65%\n",
            "Batch 30: Loss = 1.5485, Accuracy = 54.56%\n",
            "Batch 40: Loss = 1.8224, Accuracy = 55.01%\n",
            "Batch 50: Loss = 1.9840, Accuracy = 55.04%\n",
            "Batch 60: Loss = 1.4625, Accuracy = 55.44%\n",
            "Batch 70: Loss = 1.5342, Accuracy = 55.73%\n",
            "Batch 80: Loss = 1.7711, Accuracy = 55.47%\n",
            "Batch 90: Loss = 1.5177, Accuracy = 55.25%\n",
            "Batch 100: Loss = 1.5271, Accuracy = 55.14%\n",
            "Batch 110: Loss = 1.9388, Accuracy = 55.20%\n",
            "Batch 120: Loss = 2.0521, Accuracy = 55.40%\n",
            "Batch 130: Loss = 1.9380, Accuracy = 55.27%\n",
            "Batch 140: Loss = 1.8914, Accuracy = 55.34%\n",
            "Batch 150: Loss = 1.5680, Accuracy = 55.38%\n",
            "Batch 160: Loss = 1.9853, Accuracy = 55.40%\n",
            "Batch 170: Loss = 1.4957, Accuracy = 55.42%\n",
            "Batch 180: Loss = 2.3642, Accuracy = 55.34%\n",
            "Batch 190: Loss = 1.9283, Accuracy = 55.39%\n",
            "Batch 200: Loss = 2.0365, Accuracy = 55.40%\n",
            "Batch 210: Loss = 1.7886, Accuracy = 55.39%\n",
            "Batch 220: Loss = 1.8143, Accuracy = 55.33%\n",
            "Batch 230: Loss = 1.5731, Accuracy = 55.38%\n",
            "Batch 240: Loss = 1.4702, Accuracy = 55.47%\n",
            "Batch 250: Loss = 1.2723, Accuracy = 55.44%\n",
            "Batch 260: Loss = 1.6926, Accuracy = 55.54%\n",
            "Batch 270: Loss = 1.7575, Accuracy = 55.53%\n",
            "Batch 280: Loss = 1.6528, Accuracy = 55.49%\n",
            "Batch 290: Loss = 2.6249, Accuracy = 55.48%\n",
            "Batch 300: Loss = 1.6842, Accuracy = 55.49%\n",
            "Batch 310: Loss = 1.4512, Accuracy = 55.46%\n",
            "Batch 320: Loss = 2.0972, Accuracy = 55.42%\n",
            "Batch 330: Loss = 1.4630, Accuracy = 55.43%\n",
            "Batch 340: Loss = 1.8792, Accuracy = 55.35%\n",
            "Batch 350: Loss = 1.7480, Accuracy = 55.36%\n",
            "Batch 360: Loss = 1.5197, Accuracy = 55.39%\n",
            "Batch 370: Loss = 1.4105, Accuracy = 55.35%\n",
            "Batch 380: Loss = 1.8433, Accuracy = 55.30%\n",
            "Batch 390: Loss = 1.7491, Accuracy = 55.28%\n",
            "Epoch 24: Total Loss = 1.7545, Total Accuracy = 55.28%\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "Batch 0: Benign Loss = 2.0056, Adversarial Loss = 2.0056\n",
            "Batch 10: Benign Loss = 1.6368, Adversarial Loss = 1.6368\n",
            "Batch 20: Benign Loss = 2.1304, Adversarial Loss = 2.1304\n",
            "Batch 30: Benign Loss = 1.7530, Adversarial Loss = 1.7530\n",
            "Batch 40: Benign Loss = 1.5713, Adversarial Loss = 1.5713\n",
            "Batch 50: Benign Loss = 1.7465, Adversarial Loss = 1.7465\n",
            "Batch 60: Benign Loss = 1.8683, Adversarial Loss = 1.8683\n",
            "Batch 70: Benign Loss = 1.8883, Adversarial Loss = 1.8883\n",
            "Batch 80: Benign Loss = 1.6756, Adversarial Loss = 1.6756\n",
            "Batch 90: Benign Loss = 1.7722, Adversarial Loss = 1.7722\n",
            "Epoch 24: Benign Accuracy = 20.03%, Adversarial Accuracy = 55.73%\n",
            "Benign Loss = 4.1478, Adversarial Loss = 1.8094\n",
            "Training complete in 6779.24 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_adv_accuracy</td><td>▄▂▄▅▃▅▃▂▅▆▂▃▂▃▅▁▄▆▄▅▄█▃▆▄</td></tr><tr><td>test_adv_loss</td><td>▆▂▇▄▃▃█▅▅▅▆▄▇▃▇▆▃▅▃▁▅▅▅▃▃</td></tr><tr><td>test_benign_accuracy</td><td>▂▇▂█▅▄▂▄▂▆▅▅▃▁▃▅▆▃▅▇▄▅▆▅▄</td></tr><tr><td>test_benign_loss</td><td>▆▂▆▁▃▃▇▄▅▂▃▃▅█▄▃▂▆▃▁▃▃▂▃▃</td></tr><tr><td>train_adv_accuracy</td><td>▂▄▁▁▆▇▁▂▄▆▂▅▄▃▅▄▃▅▅▄█▅▄▂▂</td></tr><tr><td>train_adv_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>test_adv_accuracy</td><td>55.73</td></tr><tr><td>test_adv_loss</td><td>1.80938</td></tr><tr><td>test_benign_accuracy</td><td>20.03</td></tr><tr><td>test_benign_loss</td><td>4.14776</td></tr><tr><td>train_adv_accuracy</td><td>1.75454</td></tr><tr><td>train_adv_loss</td><td>0.32405</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-half-frozen-training</strong> at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/k5qmt26y' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/k5qmt26y</a><br/> View project at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241209_234909-k5qmt26y/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(resnet18_half_frozen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6mMDbob7hPm",
        "outputId": "1681da35-b3a7-4174-86b7-9187d6cfcf98"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benign Accuracy: 20.00%\n",
            "Adversarial Accuracy: 23.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19.999998807907104, 22.999998927116394)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT 3: FINETUNING\n",
        "\n",
        "wandb.init(project=\"layer-freezing-adversarial-training\", name=\"resnet18-finetuned-training\")\n",
        "table = wandb.Table(columns=[\"epoch\", \"train_adv_accuracy\", \"train_adv_loss\", \"test_benign_accuracy\", \"test_adv_accuracy\", \"test_benign_loss\", \"test_adv_loss\"])\n",
        "\n",
        "# Model and device setup\n",
        "resnet18_finetuned = torch.load(model_path)\n",
        "resnet18_finetuned = torch.nn.DataParallel(resnet18_finetuned)\n",
        "\n",
        "# Freeze all layers except the fully connected (fc) layer\n",
        "for name, param in resnet18_finetuned.module.named_parameters():\n",
        "    if \"fc\" not in name:  # Freeze all layers except the 'fc' layer\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Check that only the fc layer is trainable\n",
        "for name, param in resnet18_finetuned.named_parameters():\n",
        "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# Define adversary (PGD Attack)\n",
        "adversary = PGD(resnet18, eps=0.03, alpha=0.01, steps=40)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, resnet18_finetuned.parameters()),\n",
        "                      lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Adjust learning rate\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.01\n",
        "    if epoch >= 30:\n",
        "        lr /= 10\n",
        "    if epoch >= 40:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Training and testing loop\n",
        "start_time = time.time()\n",
        "for epoch in range(0, 25):  # Train for 25 epochs\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_adv_accuracy, train_adv_loss = adversarial_train(epoch, resnet18_finetuned)\n",
        "    test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss = adversarial_test(epoch, resnet18_finetuned)\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_adv_accuracy\": train_adv_accuracy,\n",
        "        \"train_adv_loss\": train_adv_loss,\n",
        "        \"test_benign_accuracy\": test_benign_accuracy,\n",
        "        \"test_adv_accuracy\": test_adv_accuracy,\n",
        "        \"test_benign_loss\": test_benign_loss,\n",
        "        \"test_adv_loss\": test_adv_loss\n",
        "    })\n",
        "    table.add_data(epoch, train_adv_accuracy, train_adv_loss, test_benign_accuracy, test_adv_accuracy, test_benign_loss, test_adv_loss)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Training complete in {end_time - start_time:.2f} seconds')\n",
        "\n",
        "model_finetuned_path = '/content/drive/MyDrive/MIT/6.7960 Deep Learning/models/resnet18_finetuned_trained.pt'\n",
        "torch.save(resnet18_finetuned, model_finetuned_path)\n",
        "\n",
        "wandb.log({\"metrics_table\": table})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vmk9iDhAFdHg",
        "outputId": "59528379-af86-4b5f-b006-70794c5e469b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241210_014427-rtdh0yd1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/rtdh0yd1' target=\"_blank\">resnet18-finetuned-training</a></strong> to <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/rtdh0yd1' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/rtdh0yd1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module.conv1.weight: requires_grad=False\n",
            "module.bn1.weight: requires_grad=False\n",
            "module.bn1.bias: requires_grad=False\n",
            "module.layer1.0.conv1.weight: requires_grad=False\n",
            "module.layer1.0.bn1.weight: requires_grad=False\n",
            "module.layer1.0.bn1.bias: requires_grad=False\n",
            "module.layer1.0.conv2.weight: requires_grad=False\n",
            "module.layer1.0.bn2.weight: requires_grad=False\n",
            "module.layer1.0.bn2.bias: requires_grad=False\n",
            "module.layer1.1.conv1.weight: requires_grad=False\n",
            "module.layer1.1.bn1.weight: requires_grad=False\n",
            "module.layer1.1.bn1.bias: requires_grad=False\n",
            "module.layer1.1.conv2.weight: requires_grad=False\n",
            "module.layer1.1.bn2.weight: requires_grad=False\n",
            "module.layer1.1.bn2.bias: requires_grad=False\n",
            "module.layer2.0.conv1.weight: requires_grad=False\n",
            "module.layer2.0.bn1.weight: requires_grad=False\n",
            "module.layer2.0.bn1.bias: requires_grad=False\n",
            "module.layer2.0.conv2.weight: requires_grad=False\n",
            "module.layer2.0.bn2.weight: requires_grad=False\n",
            "module.layer2.0.bn2.bias: requires_grad=False\n",
            "module.layer2.0.downsample.0.weight: requires_grad=False\n",
            "module.layer2.0.downsample.1.weight: requires_grad=False\n",
            "module.layer2.0.downsample.1.bias: requires_grad=False\n",
            "module.layer2.1.conv1.weight: requires_grad=False\n",
            "module.layer2.1.bn1.weight: requires_grad=False\n",
            "module.layer2.1.bn1.bias: requires_grad=False\n",
            "module.layer2.1.conv2.weight: requires_grad=False\n",
            "module.layer2.1.bn2.weight: requires_grad=False\n",
            "module.layer2.1.bn2.bias: requires_grad=False\n",
            "module.layer3.0.conv1.weight: requires_grad=False\n",
            "module.layer3.0.bn1.weight: requires_grad=False\n",
            "module.layer3.0.bn1.bias: requires_grad=False\n",
            "module.layer3.0.conv2.weight: requires_grad=False\n",
            "module.layer3.0.bn2.weight: requires_grad=False\n",
            "module.layer3.0.bn2.bias: requires_grad=False\n",
            "module.layer3.0.downsample.0.weight: requires_grad=False\n",
            "module.layer3.0.downsample.1.weight: requires_grad=False\n",
            "module.layer3.0.downsample.1.bias: requires_grad=False\n",
            "module.layer3.1.conv1.weight: requires_grad=False\n",
            "module.layer3.1.bn1.weight: requires_grad=False\n",
            "module.layer3.1.bn1.bias: requires_grad=False\n",
            "module.layer3.1.conv2.weight: requires_grad=False\n",
            "module.layer3.1.bn2.weight: requires_grad=False\n",
            "module.layer3.1.bn2.bias: requires_grad=False\n",
            "module.layer4.0.conv1.weight: requires_grad=False\n",
            "module.layer4.0.bn1.weight: requires_grad=False\n",
            "module.layer4.0.bn1.bias: requires_grad=False\n",
            "module.layer4.0.conv2.weight: requires_grad=False\n",
            "module.layer4.0.bn2.weight: requires_grad=False\n",
            "module.layer4.0.bn2.bias: requires_grad=False\n",
            "module.layer4.0.downsample.0.weight: requires_grad=False\n",
            "module.layer4.0.downsample.1.weight: requires_grad=False\n",
            "module.layer4.0.downsample.1.bias: requires_grad=False\n",
            "module.layer4.1.conv1.weight: requires_grad=False\n",
            "module.layer4.1.bn1.weight: requires_grad=False\n",
            "module.layer4.1.bn1.bias: requires_grad=False\n",
            "module.layer4.1.conv2.weight: requires_grad=False\n",
            "module.layer4.1.bn2.weight: requires_grad=False\n",
            "module.layer4.1.bn2.bias: requires_grad=False\n",
            "module.fc.weight: requires_grad=True\n",
            "module.fc.bias: requires_grad=True\n",
            "\n",
            "[ Train epoch: 0 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-245a16f0c0fb>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet18_finetuned = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: Loss = 1.8483, Accuracy = 54.69%\n",
            "Batch 10: Loss = 1.5559, Accuracy = 55.26%\n",
            "Batch 20: Loss = 1.6713, Accuracy = 55.28%\n",
            "Batch 30: Loss = 1.1652, Accuracy = 55.27%\n",
            "Batch 40: Loss = 1.3751, Accuracy = 55.47%\n",
            "Batch 50: Loss = 1.0389, Accuracy = 55.42%\n",
            "Batch 60: Loss = 1.1531, Accuracy = 55.65%\n",
            "Batch 70: Loss = 1.0491, Accuracy = 55.39%\n",
            "Batch 80: Loss = 1.1143, Accuracy = 55.73%\n",
            "Batch 90: Loss = 1.3645, Accuracy = 55.65%\n",
            "Batch 100: Loss = 1.1071, Accuracy = 55.74%\n",
            "Batch 110: Loss = 1.0735, Accuracy = 55.83%\n",
            "Batch 120: Loss = 1.2509, Accuracy = 55.75%\n",
            "Batch 130: Loss = 1.3187, Accuracy = 55.92%\n",
            "Batch 140: Loss = 1.2264, Accuracy = 56.08%\n",
            "Batch 150: Loss = 1.0944, Accuracy = 56.09%\n",
            "Batch 160: Loss = 1.2988, Accuracy = 56.13%\n",
            "Batch 170: Loss = 1.3965, Accuracy = 56.11%\n",
            "Batch 180: Loss = 1.2006, Accuracy = 56.22%\n",
            "Batch 190: Loss = 1.1142, Accuracy = 56.27%\n",
            "Batch 200: Loss = 1.1510, Accuracy = 56.33%\n",
            "Batch 210: Loss = 1.1109, Accuracy = 56.34%\n",
            "Batch 220: Loss = 1.2594, Accuracy = 56.39%\n",
            "Batch 230: Loss = 1.2268, Accuracy = 56.38%\n",
            "Batch 240: Loss = 1.2364, Accuracy = 56.33%\n",
            "Batch 250: Loss = 1.1539, Accuracy = 56.36%\n",
            "Batch 260: Loss = 1.2613, Accuracy = 56.36%\n",
            "Batch 270: Loss = 1.0374, Accuracy = 56.45%\n",
            "Batch 280: Loss = 1.1556, Accuracy = 56.56%\n",
            "Batch 290: Loss = 1.3455, Accuracy = 56.60%\n",
            "Batch 300: Loss = 1.0995, Accuracy = 56.65%\n",
            "Batch 310: Loss = 1.1878, Accuracy = 56.68%\n",
            "Batch 320: Loss = 1.2610, Accuracy = 56.72%\n",
            "Batch 330: Loss = 1.2633, Accuracy = 56.78%\n",
            "Batch 340: Loss = 1.0374, Accuracy = 56.78%\n",
            "Batch 350: Loss = 1.2536, Accuracy = 56.79%\n",
            "Batch 360: Loss = 1.2278, Accuracy = 56.83%\n",
            "Batch 370: Loss = 1.0314, Accuracy = 56.86%\n",
            "Batch 380: Loss = 1.2893, Accuracy = 56.88%\n",
            "Batch 390: Loss = 1.1540, Accuracy = 56.87%\n",
            "Epoch 0: Total Loss = 1.2553, Total Accuracy = 56.87%\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "Batch 0: Benign Loss = 1.2642, Adversarial Loss = 1.2642\n",
            "Batch 10: Benign Loss = 1.0832, Adversarial Loss = 1.0832\n",
            "Batch 20: Benign Loss = 1.2329, Adversarial Loss = 1.2329\n",
            "Batch 30: Benign Loss = 1.1500, Adversarial Loss = 1.1500\n",
            "Batch 40: Benign Loss = 1.0554, Adversarial Loss = 1.0554\n",
            "Batch 50: Benign Loss = 1.1686, Adversarial Loss = 1.1686\n",
            "Batch 60: Benign Loss = 1.1947, Adversarial Loss = 1.1947\n",
            "Batch 70: Benign Loss = 1.1365, Adversarial Loss = 1.1365\n",
            "Batch 80: Benign Loss = 1.0883, Adversarial Loss = 1.0883\n",
            "Batch 90: Benign Loss = 1.0870, Adversarial Loss = 1.0870\n",
            "Epoch 0: Benign Accuracy = 21.45%, Adversarial Accuracy = 59.08%\n",
            "Benign Loss = 2.4991, Adversarial Loss = 1.1748\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "Batch 0: Loss = 1.1422, Accuracy = 61.72%\n",
            "Batch 10: Loss = 1.1883, Accuracy = 58.17%\n",
            "Batch 20: Loss = 1.3215, Accuracy = 58.44%\n",
            "Batch 30: Loss = 1.2742, Accuracy = 58.54%\n",
            "Batch 40: Loss = 1.1334, Accuracy = 58.94%\n",
            "Batch 50: Loss = 1.2704, Accuracy = 58.93%\n",
            "Batch 60: Loss = 1.3229, Accuracy = 58.98%\n",
            "Batch 70: Loss = 1.1258, Accuracy = 58.77%\n",
            "Batch 80: Loss = 1.2091, Accuracy = 58.76%\n",
            "Batch 90: Loss = 1.0466, Accuracy = 58.72%\n",
            "Batch 100: Loss = 1.1838, Accuracy = 58.79%\n",
            "Batch 110: Loss = 1.0904, Accuracy = 58.71%\n",
            "Batch 120: Loss = 1.1943, Accuracy = 58.92%\n",
            "Batch 130: Loss = 1.0011, Accuracy = 58.74%\n",
            "Batch 140: Loss = 1.1856, Accuracy = 58.54%\n",
            "Batch 150: Loss = 1.1762, Accuracy = 58.51%\n",
            "Batch 160: Loss = 1.2856, Accuracy = 58.68%\n",
            "Batch 170: Loss = 1.3430, Accuracy = 58.57%\n",
            "Batch 180: Loss = 1.1294, Accuracy = 58.53%\n",
            "Batch 190: Loss = 1.2551, Accuracy = 58.47%\n",
            "Batch 200: Loss = 1.1761, Accuracy = 58.43%\n",
            "Batch 210: Loss = 1.1717, Accuracy = 58.46%\n",
            "Batch 220: Loss = 1.0252, Accuracy = 58.42%\n",
            "Batch 230: Loss = 1.2401, Accuracy = 58.32%\n",
            "Batch 240: Loss = 1.1399, Accuracy = 58.31%\n",
            "Batch 250: Loss = 1.1241, Accuracy = 58.34%\n",
            "Batch 260: Loss = 1.1248, Accuracy = 58.33%\n",
            "Batch 270: Loss = 1.2608, Accuracy = 58.35%\n",
            "Batch 280: Loss = 1.1528, Accuracy = 58.41%\n",
            "Batch 290: Loss = 1.1303, Accuracy = 58.34%\n",
            "Batch 300: Loss = 1.1013, Accuracy = 58.39%\n",
            "Batch 310: Loss = 1.1752, Accuracy = 58.47%\n",
            "Batch 320: Loss = 1.2338, Accuracy = 58.48%\n",
            "Batch 330: Loss = 1.3134, Accuracy = 58.56%\n",
            "Batch 340: Loss = 1.0825, Accuracy = 58.47%\n",
            "Batch 350: Loss = 1.1774, Accuracy = 58.47%\n",
            "Batch 360: Loss = 1.3626, Accuracy = 58.45%\n",
            "Batch 370: Loss = 1.0592, Accuracy = 58.43%\n",
            "Batch 380: Loss = 1.2295, Accuracy = 58.42%\n",
            "Batch 390: Loss = 1.1024, Accuracy = 58.39%\n",
            "Epoch 1: Total Loss = 1.1819, Total Accuracy = 58.39%\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "Batch 0: Benign Loss = 1.2912, Adversarial Loss = 1.2912\n",
            "Batch 10: Benign Loss = 1.1221, Adversarial Loss = 1.1221\n",
            "Batch 20: Benign Loss = 1.2023, Adversarial Loss = 1.2023\n",
            "Batch 30: Benign Loss = 1.1447, Adversarial Loss = 1.1447\n",
            "Batch 40: Benign Loss = 1.0486, Adversarial Loss = 1.0486\n",
            "Batch 50: Benign Loss = 1.1388, Adversarial Loss = 1.1388\n",
            "Batch 60: Benign Loss = 1.1788, Adversarial Loss = 1.1788\n",
            "Batch 70: Benign Loss = 1.1074, Adversarial Loss = 1.1074\n",
            "Batch 80: Benign Loss = 1.0495, Adversarial Loss = 1.0495\n",
            "Batch 90: Benign Loss = 1.1184, Adversarial Loss = 1.1184\n",
            "Epoch 1: Benign Accuracy = 22.95%, Adversarial Accuracy = 59.19%\n",
            "Benign Loss = 2.5880, Adversarial Loss = 1.1669\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "Batch 0: Loss = 1.0738, Accuracy = 60.16%\n",
            "Batch 10: Loss = 1.2220, Accuracy = 58.88%\n",
            "Batch 20: Loss = 1.1342, Accuracy = 59.30%\n",
            "Batch 30: Loss = 1.0460, Accuracy = 59.40%\n",
            "Batch 40: Loss = 1.0140, Accuracy = 59.43%\n",
            "Batch 50: Loss = 1.2005, Accuracy = 60.05%\n",
            "Batch 60: Loss = 1.1427, Accuracy = 60.02%\n",
            "Batch 70: Loss = 1.1950, Accuracy = 60.09%\n",
            "Batch 80: Loss = 1.1657, Accuracy = 60.04%\n",
            "Batch 90: Loss = 1.1318, Accuracy = 60.05%\n",
            "Batch 100: Loss = 1.1343, Accuracy = 59.97%\n",
            "Batch 110: Loss = 0.8369, Accuracy = 59.92%\n",
            "Batch 120: Loss = 1.1632, Accuracy = 59.83%\n",
            "Batch 130: Loss = 1.2087, Accuracy = 59.82%\n",
            "Batch 140: Loss = 1.2626, Accuracy = 59.92%\n",
            "Batch 150: Loss = 1.2875, Accuracy = 59.81%\n",
            "Batch 160: Loss = 1.2321, Accuracy = 59.75%\n",
            "Batch 170: Loss = 0.9652, Accuracy = 59.82%\n",
            "Batch 180: Loss = 1.2716, Accuracy = 59.82%\n",
            "Batch 190: Loss = 1.0960, Accuracy = 59.85%\n",
            "Batch 200: Loss = 1.0719, Accuracy = 59.78%\n",
            "Batch 210: Loss = 1.4502, Accuracy = 59.63%\n",
            "Batch 220: Loss = 1.2147, Accuracy = 59.63%\n",
            "Batch 230: Loss = 1.1885, Accuracy = 59.54%\n",
            "Batch 240: Loss = 1.2089, Accuracy = 59.52%\n",
            "Batch 250: Loss = 1.0233, Accuracy = 59.55%\n",
            "Batch 260: Loss = 1.2580, Accuracy = 59.52%\n",
            "Batch 270: Loss = 1.3984, Accuracy = 59.41%\n",
            "Batch 280: Loss = 0.9523, Accuracy = 59.42%\n",
            "Batch 290: Loss = 1.2479, Accuracy = 59.31%\n",
            "Batch 300: Loss = 1.1816, Accuracy = 59.37%\n",
            "Batch 310: Loss = 1.1238, Accuracy = 59.33%\n",
            "Batch 320: Loss = 1.1073, Accuracy = 59.33%\n",
            "Batch 330: Loss = 1.2933, Accuracy = 59.31%\n",
            "Batch 340: Loss = 1.2042, Accuracy = 59.32%\n",
            "Batch 350: Loss = 1.1327, Accuracy = 59.29%\n",
            "Batch 360: Loss = 1.1296, Accuracy = 59.31%\n",
            "Batch 370: Loss = 1.1303, Accuracy = 59.32%\n",
            "Batch 380: Loss = 1.1432, Accuracy = 59.32%\n",
            "Batch 390: Loss = 1.2464, Accuracy = 59.31%\n",
            "Epoch 2: Total Loss = 1.1600, Total Accuracy = 59.31%\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "Batch 0: Benign Loss = 1.2293, Adversarial Loss = 1.2293\n",
            "Batch 10: Benign Loss = 1.0670, Adversarial Loss = 1.0670\n",
            "Batch 20: Benign Loss = 1.1601, Adversarial Loss = 1.1601\n",
            "Batch 30: Benign Loss = 1.1435, Adversarial Loss = 1.1435\n",
            "Batch 40: Benign Loss = 1.0152, Adversarial Loss = 1.0152\n",
            "Batch 50: Benign Loss = 1.1204, Adversarial Loss = 1.1204\n",
            "Batch 60: Benign Loss = 1.1787, Adversarial Loss = 1.1787\n",
            "Batch 70: Benign Loss = 1.1428, Adversarial Loss = 1.1428\n",
            "Batch 80: Benign Loss = 1.0846, Adversarial Loss = 1.0846\n",
            "Batch 90: Benign Loss = 1.1199, Adversarial Loss = 1.1199\n",
            "Epoch 2: Benign Accuracy = 23.86%, Adversarial Accuracy = 59.53%\n",
            "Benign Loss = 2.6675, Adversarial Loss = 1.1533\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "Batch 0: Loss = 1.1218, Accuracy = 60.16%\n",
            "Batch 10: Loss = 1.2386, Accuracy = 57.67%\n",
            "Batch 20: Loss = 0.9931, Accuracy = 58.63%\n",
            "Batch 30: Loss = 1.2199, Accuracy = 59.10%\n",
            "Batch 40: Loss = 1.1518, Accuracy = 59.81%\n",
            "Batch 50: Loss = 1.0810, Accuracy = 59.76%\n",
            "Batch 60: Loss = 1.3022, Accuracy = 59.89%\n",
            "Batch 70: Loss = 1.0992, Accuracy = 59.94%\n",
            "Batch 80: Loss = 1.1642, Accuracy = 59.81%\n",
            "Batch 90: Loss = 1.1226, Accuracy = 59.86%\n",
            "Batch 100: Loss = 0.9834, Accuracy = 59.68%\n",
            "Batch 110: Loss = 1.2895, Accuracy = 59.78%\n",
            "Batch 120: Loss = 1.0096, Accuracy = 59.59%\n",
            "Batch 130: Loss = 1.1017, Accuracy = 59.56%\n",
            "Batch 140: Loss = 1.2788, Accuracy = 59.61%\n",
            "Batch 150: Loss = 1.2962, Accuracy = 59.59%\n",
            "Batch 160: Loss = 1.0732, Accuracy = 59.51%\n",
            "Batch 170: Loss = 1.0541, Accuracy = 59.41%\n",
            "Batch 180: Loss = 1.0947, Accuracy = 59.37%\n",
            "Batch 190: Loss = 1.3451, Accuracy = 59.38%\n",
            "Batch 200: Loss = 1.3118, Accuracy = 59.31%\n",
            "Batch 210: Loss = 1.1596, Accuracy = 59.28%\n",
            "Batch 220: Loss = 1.1492, Accuracy = 59.28%\n",
            "Batch 230: Loss = 1.3844, Accuracy = 59.24%\n",
            "Batch 240: Loss = 1.0589, Accuracy = 59.31%\n",
            "Batch 250: Loss = 1.0028, Accuracy = 59.24%\n",
            "Batch 260: Loss = 1.0584, Accuracy = 59.31%\n",
            "Batch 270: Loss = 1.1078, Accuracy = 59.29%\n",
            "Batch 280: Loss = 1.1442, Accuracy = 59.31%\n",
            "Batch 290: Loss = 1.0902, Accuracy = 59.26%\n",
            "Batch 300: Loss = 1.0914, Accuracy = 59.30%\n",
            "Batch 310: Loss = 1.1568, Accuracy = 59.25%\n",
            "Batch 320: Loss = 1.1291, Accuracy = 59.25%\n",
            "Batch 330: Loss = 1.0665, Accuracy = 59.21%\n",
            "Batch 340: Loss = 1.0915, Accuracy = 59.27%\n",
            "Batch 350: Loss = 1.3536, Accuracy = 59.25%\n",
            "Batch 360: Loss = 1.1507, Accuracy = 59.25%\n",
            "Batch 370: Loss = 1.2569, Accuracy = 59.22%\n",
            "Batch 380: Loss = 1.0194, Accuracy = 59.28%\n",
            "Batch 390: Loss = 1.0738, Accuracy = 59.26%\n",
            "Epoch 3: Total Loss = 1.1539, Total Accuracy = 59.26%\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "Batch 0: Benign Loss = 1.2333, Adversarial Loss = 1.2333\n",
            "Batch 10: Benign Loss = 1.0718, Adversarial Loss = 1.0718\n",
            "Batch 20: Benign Loss = 1.1435, Adversarial Loss = 1.1435\n",
            "Batch 30: Benign Loss = 1.1175, Adversarial Loss = 1.1175\n",
            "Batch 40: Benign Loss = 1.0306, Adversarial Loss = 1.0306\n",
            "Batch 50: Benign Loss = 1.1354, Adversarial Loss = 1.1354\n",
            "Batch 60: Benign Loss = 1.1373, Adversarial Loss = 1.1373\n",
            "Batch 70: Benign Loss = 1.1198, Adversarial Loss = 1.1198\n",
            "Batch 80: Benign Loss = 1.0648, Adversarial Loss = 1.0648\n",
            "Batch 90: Benign Loss = 1.0796, Adversarial Loss = 1.0796\n",
            "Epoch 3: Benign Accuracy = 26.40%, Adversarial Accuracy = 60.37%\n",
            "Benign Loss = 2.1971, Adversarial Loss = 1.1395\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "Batch 0: Loss = 1.2021, Accuracy = 59.38%\n",
            "Batch 10: Loss = 1.2118, Accuracy = 57.95%\n",
            "Batch 20: Loss = 1.0397, Accuracy = 58.74%\n",
            "Batch 30: Loss = 1.1022, Accuracy = 59.12%\n",
            "Batch 40: Loss = 1.0984, Accuracy = 58.73%\n",
            "Batch 50: Loss = 1.2882, Accuracy = 58.61%\n",
            "Batch 60: Loss = 1.3375, Accuracy = 58.50%\n",
            "Batch 70: Loss = 1.2467, Accuracy = 58.88%\n",
            "Batch 80: Loss = 1.2888, Accuracy = 59.21%\n",
            "Batch 90: Loss = 1.1444, Accuracy = 59.39%\n",
            "Batch 100: Loss = 1.1418, Accuracy = 59.58%\n",
            "Batch 110: Loss = 1.1763, Accuracy = 59.63%\n",
            "Batch 120: Loss = 1.0278, Accuracy = 59.64%\n",
            "Batch 130: Loss = 1.0409, Accuracy = 59.43%\n",
            "Batch 140: Loss = 1.0580, Accuracy = 59.36%\n",
            "Batch 150: Loss = 1.0985, Accuracy = 59.40%\n",
            "Batch 160: Loss = 1.0911, Accuracy = 59.43%\n",
            "Batch 170: Loss = 1.2036, Accuracy = 59.40%\n",
            "Batch 180: Loss = 1.0813, Accuracy = 59.36%\n",
            "Batch 190: Loss = 1.1083, Accuracy = 59.33%\n",
            "Batch 200: Loss = 1.0470, Accuracy = 59.27%\n",
            "Batch 210: Loss = 1.1820, Accuracy = 59.38%\n",
            "Batch 220: Loss = 1.2933, Accuracy = 59.38%\n",
            "Batch 230: Loss = 1.3185, Accuracy = 59.38%\n",
            "Batch 240: Loss = 1.2450, Accuracy = 59.29%\n",
            "Batch 250: Loss = 1.2063, Accuracy = 59.26%\n",
            "Batch 260: Loss = 1.0861, Accuracy = 59.22%\n",
            "Batch 270: Loss = 1.2498, Accuracy = 59.10%\n",
            "Batch 280: Loss = 1.2112, Accuracy = 59.10%\n",
            "Batch 290: Loss = 0.9994, Accuracy = 59.09%\n",
            "Batch 300: Loss = 1.1276, Accuracy = 59.10%\n",
            "Batch 310: Loss = 1.0985, Accuracy = 59.09%\n",
            "Batch 320: Loss = 1.1662, Accuracy = 59.04%\n",
            "Batch 330: Loss = 1.1182, Accuracy = 59.11%\n",
            "Batch 340: Loss = 1.1219, Accuracy = 59.16%\n",
            "Batch 350: Loss = 1.2598, Accuracy = 59.14%\n",
            "Batch 360: Loss = 0.9372, Accuracy = 59.20%\n",
            "Batch 370: Loss = 1.2368, Accuracy = 59.19%\n",
            "Batch 380: Loss = 0.9600, Accuracy = 59.21%\n",
            "Batch 390: Loss = 1.2447, Accuracy = 59.22%\n",
            "Epoch 4: Total Loss = 1.1549, Total Accuracy = 59.22%\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "Batch 0: Benign Loss = 1.2121, Adversarial Loss = 1.2121\n",
            "Batch 10: Benign Loss = 1.0578, Adversarial Loss = 1.0578\n",
            "Batch 20: Benign Loss = 1.1704, Adversarial Loss = 1.1704\n",
            "Batch 30: Benign Loss = 1.1477, Adversarial Loss = 1.1477\n",
            "Batch 40: Benign Loss = 1.0277, Adversarial Loss = 1.0277\n",
            "Batch 50: Benign Loss = 1.1269, Adversarial Loss = 1.1269\n",
            "Batch 60: Benign Loss = 1.1349, Adversarial Loss = 1.1349\n",
            "Batch 70: Benign Loss = 1.1243, Adversarial Loss = 1.1243\n",
            "Batch 80: Benign Loss = 1.0494, Adversarial Loss = 1.0494\n",
            "Batch 90: Benign Loss = 1.0921, Adversarial Loss = 1.0921\n",
            "Epoch 4: Benign Accuracy = 24.93%, Adversarial Accuracy = 60.42%\n",
            "Benign Loss = 2.3983, Adversarial Loss = 1.1399\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "Batch 0: Loss = 1.2453, Accuracy = 58.59%\n",
            "Batch 10: Loss = 1.1316, Accuracy = 61.22%\n",
            "Batch 20: Loss = 1.1787, Accuracy = 59.08%\n",
            "Batch 30: Loss = 1.0340, Accuracy = 58.72%\n",
            "Batch 40: Loss = 1.1616, Accuracy = 59.11%\n",
            "Batch 50: Loss = 1.1310, Accuracy = 58.78%\n",
            "Batch 60: Loss = 1.3212, Accuracy = 58.63%\n",
            "Batch 70: Loss = 1.2661, Accuracy = 58.76%\n",
            "Batch 80: Loss = 1.2231, Accuracy = 58.74%\n",
            "Batch 90: Loss = 1.2028, Accuracy = 58.83%\n",
            "Batch 100: Loss = 1.0518, Accuracy = 59.14%\n",
            "Batch 110: Loss = 1.2035, Accuracy = 58.82%\n",
            "Batch 120: Loss = 1.1017, Accuracy = 58.73%\n",
            "Batch 130: Loss = 1.1143, Accuracy = 58.78%\n",
            "Batch 140: Loss = 1.1910, Accuracy = 58.92%\n",
            "Batch 150: Loss = 1.0148, Accuracy = 59.05%\n",
            "Batch 160: Loss = 1.1484, Accuracy = 59.01%\n",
            "Batch 170: Loss = 1.1415, Accuracy = 59.01%\n",
            "Batch 180: Loss = 1.0697, Accuracy = 59.12%\n",
            "Batch 190: Loss = 1.2635, Accuracy = 59.27%\n",
            "Batch 200: Loss = 1.1094, Accuracy = 59.36%\n",
            "Batch 210: Loss = 1.1098, Accuracy = 59.41%\n",
            "Batch 220: Loss = 1.0757, Accuracy = 59.38%\n",
            "Batch 230: Loss = 1.1357, Accuracy = 59.33%\n",
            "Batch 240: Loss = 1.1505, Accuracy = 59.40%\n",
            "Batch 250: Loss = 1.0088, Accuracy = 59.53%\n",
            "Batch 260: Loss = 0.9849, Accuracy = 59.54%\n",
            "Batch 270: Loss = 1.1454, Accuracy = 59.54%\n",
            "Batch 280: Loss = 1.0043, Accuracy = 59.63%\n",
            "Batch 290: Loss = 1.2763, Accuracy = 59.57%\n",
            "Batch 300: Loss = 1.3030, Accuracy = 59.63%\n",
            "Batch 310: Loss = 1.0937, Accuracy = 59.67%\n",
            "Batch 320: Loss = 1.3487, Accuracy = 59.63%\n",
            "Batch 330: Loss = 1.2911, Accuracy = 59.61%\n",
            "Batch 340: Loss = 0.8838, Accuracy = 59.65%\n",
            "Batch 350: Loss = 1.0252, Accuracy = 59.69%\n",
            "Batch 360: Loss = 0.9955, Accuracy = 59.70%\n",
            "Batch 370: Loss = 1.1595, Accuracy = 59.69%\n",
            "Batch 380: Loss = 1.2956, Accuracy = 59.60%\n",
            "Batch 390: Loss = 1.0341, Accuracy = 59.54%\n",
            "Epoch 5: Total Loss = 1.1439, Total Accuracy = 59.54%\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "Batch 0: Benign Loss = 1.1844, Adversarial Loss = 1.1844\n",
            "Batch 10: Benign Loss = 1.0645, Adversarial Loss = 1.0645\n",
            "Batch 20: Benign Loss = 1.2050, Adversarial Loss = 1.2050\n",
            "Batch 30: Benign Loss = 1.1174, Adversarial Loss = 1.1174\n",
            "Batch 40: Benign Loss = 0.9991, Adversarial Loss = 0.9991\n",
            "Batch 50: Benign Loss = 1.1378, Adversarial Loss = 1.1378\n",
            "Batch 60: Benign Loss = 1.1314, Adversarial Loss = 1.1314\n",
            "Batch 70: Benign Loss = 1.1125, Adversarial Loss = 1.1125\n",
            "Batch 80: Benign Loss = 1.0914, Adversarial Loss = 1.0914\n",
            "Batch 90: Benign Loss = 1.1052, Adversarial Loss = 1.1052\n",
            "Epoch 5: Benign Accuracy = 25.78%, Adversarial Accuracy = 59.84%\n",
            "Benign Loss = 2.2855, Adversarial Loss = 1.1407\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "Batch 0: Loss = 1.1561, Accuracy = 57.81%\n",
            "Batch 10: Loss = 1.0917, Accuracy = 59.87%\n",
            "Batch 20: Loss = 1.0855, Accuracy = 60.27%\n",
            "Batch 30: Loss = 1.2683, Accuracy = 59.83%\n",
            "Batch 40: Loss = 1.0915, Accuracy = 60.42%\n",
            "Batch 50: Loss = 1.1620, Accuracy = 60.42%\n",
            "Batch 60: Loss = 1.1104, Accuracy = 60.37%\n",
            "Batch 70: Loss = 1.0594, Accuracy = 60.41%\n",
            "Batch 80: Loss = 1.1636, Accuracy = 60.17%\n",
            "Batch 90: Loss = 1.3589, Accuracy = 60.12%\n",
            "Batch 100: Loss = 1.0448, Accuracy = 60.06%\n",
            "Batch 110: Loss = 1.1571, Accuracy = 59.98%\n",
            "Batch 120: Loss = 1.0677, Accuracy = 59.63%\n",
            "Batch 130: Loss = 1.1051, Accuracy = 59.48%\n",
            "Batch 140: Loss = 0.9857, Accuracy = 59.59%\n",
            "Batch 150: Loss = 1.2918, Accuracy = 59.52%\n",
            "Batch 160: Loss = 1.0397, Accuracy = 59.70%\n",
            "Batch 170: Loss = 0.9393, Accuracy = 59.77%\n",
            "Batch 180: Loss = 1.1338, Accuracy = 59.68%\n",
            "Batch 190: Loss = 1.2477, Accuracy = 59.72%\n",
            "Batch 200: Loss = 1.2086, Accuracy = 59.75%\n",
            "Batch 210: Loss = 1.3601, Accuracy = 59.69%\n",
            "Batch 220: Loss = 0.9925, Accuracy = 59.75%\n",
            "Batch 230: Loss = 1.1194, Accuracy = 59.70%\n",
            "Batch 240: Loss = 0.9738, Accuracy = 59.80%\n",
            "Batch 250: Loss = 1.2243, Accuracy = 59.77%\n",
            "Batch 260: Loss = 1.1213, Accuracy = 59.80%\n",
            "Batch 270: Loss = 1.0672, Accuracy = 59.76%\n",
            "Batch 280: Loss = 1.1548, Accuracy = 59.73%\n",
            "Batch 290: Loss = 1.0917, Accuracy = 59.75%\n",
            "Batch 300: Loss = 1.0971, Accuracy = 59.73%\n",
            "Batch 310: Loss = 1.0898, Accuracy = 59.73%\n",
            "Batch 320: Loss = 1.0830, Accuracy = 59.75%\n",
            "Batch 330: Loss = 1.1263, Accuracy = 59.73%\n",
            "Batch 340: Loss = 1.1601, Accuracy = 59.79%\n",
            "Batch 350: Loss = 1.1979, Accuracy = 59.71%\n",
            "Batch 360: Loss = 1.1339, Accuracy = 59.72%\n",
            "Batch 370: Loss = 1.0856, Accuracy = 59.71%\n",
            "Batch 380: Loss = 1.0458, Accuracy = 59.70%\n",
            "Batch 390: Loss = 1.1559, Accuracy = 59.63%\n",
            "Epoch 6: Total Loss = 1.1396, Total Accuracy = 59.63%\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "Batch 0: Benign Loss = 1.2364, Adversarial Loss = 1.2364\n",
            "Batch 10: Benign Loss = 1.1456, Adversarial Loss = 1.1456\n",
            "Batch 20: Benign Loss = 1.1512, Adversarial Loss = 1.1512\n",
            "Batch 30: Benign Loss = 1.0984, Adversarial Loss = 1.0984\n",
            "Batch 40: Benign Loss = 0.9975, Adversarial Loss = 0.9975\n",
            "Batch 50: Benign Loss = 1.1234, Adversarial Loss = 1.1234\n",
            "Batch 60: Benign Loss = 1.1584, Adversarial Loss = 1.1584\n",
            "Batch 70: Benign Loss = 1.0941, Adversarial Loss = 1.0941\n",
            "Batch 80: Benign Loss = 1.0538, Adversarial Loss = 1.0538\n",
            "Batch 90: Benign Loss = 1.1118, Adversarial Loss = 1.1118\n",
            "Epoch 6: Benign Accuracy = 24.52%, Adversarial Accuracy = 60.38%\n",
            "Benign Loss = 2.5577, Adversarial Loss = 1.1387\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "Batch 0: Loss = 1.1130, Accuracy = 60.16%\n",
            "Batch 10: Loss = 1.0977, Accuracy = 60.94%\n",
            "Batch 20: Loss = 1.1766, Accuracy = 60.23%\n",
            "Batch 30: Loss = 1.0847, Accuracy = 60.51%\n",
            "Batch 40: Loss = 1.1559, Accuracy = 60.46%\n",
            "Batch 50: Loss = 0.9404, Accuracy = 60.68%\n",
            "Batch 60: Loss = 1.4720, Accuracy = 60.51%\n",
            "Batch 70: Loss = 1.1420, Accuracy = 60.66%\n",
            "Batch 80: Loss = 1.0906, Accuracy = 60.59%\n",
            "Batch 90: Loss = 1.0477, Accuracy = 60.41%\n",
            "Batch 100: Loss = 1.3374, Accuracy = 60.15%\n",
            "Batch 110: Loss = 1.0068, Accuracy = 60.27%\n",
            "Batch 120: Loss = 1.0026, Accuracy = 60.30%\n",
            "Batch 130: Loss = 1.1987, Accuracy = 60.39%\n",
            "Batch 140: Loss = 1.0862, Accuracy = 60.26%\n",
            "Batch 150: Loss = 1.0559, Accuracy = 60.29%\n",
            "Batch 160: Loss = 1.2570, Accuracy = 60.29%\n",
            "Batch 170: Loss = 1.0792, Accuracy = 60.13%\n",
            "Batch 180: Loss = 1.0978, Accuracy = 60.06%\n",
            "Batch 190: Loss = 1.0009, Accuracy = 60.15%\n",
            "Batch 200: Loss = 1.1689, Accuracy = 60.23%\n",
            "Batch 210: Loss = 1.1289, Accuracy = 60.20%\n",
            "Batch 220: Loss = 1.1688, Accuracy = 60.16%\n",
            "Batch 230: Loss = 1.1358, Accuracy = 60.24%\n",
            "Batch 240: Loss = 1.1360, Accuracy = 60.19%\n",
            "Batch 250: Loss = 1.0925, Accuracy = 60.15%\n",
            "Batch 260: Loss = 1.0308, Accuracy = 60.14%\n",
            "Batch 270: Loss = 1.0532, Accuracy = 60.12%\n",
            "Batch 280: Loss = 1.0460, Accuracy = 60.21%\n",
            "Batch 290: Loss = 1.1231, Accuracy = 60.13%\n",
            "Batch 300: Loss = 1.1362, Accuracy = 60.08%\n",
            "Batch 310: Loss = 1.1741, Accuracy = 60.07%\n",
            "Batch 320: Loss = 1.0896, Accuracy = 60.11%\n",
            "Batch 330: Loss = 1.1138, Accuracy = 60.16%\n",
            "Batch 340: Loss = 1.1003, Accuracy = 60.31%\n",
            "Batch 350: Loss = 1.1441, Accuracy = 60.31%\n",
            "Batch 360: Loss = 1.2131, Accuracy = 60.32%\n",
            "Batch 370: Loss = 1.1829, Accuracy = 60.31%\n",
            "Batch 380: Loss = 1.2258, Accuracy = 60.28%\n",
            "Batch 390: Loss = 1.0302, Accuracy = 60.34%\n",
            "Epoch 7: Total Loss = 1.1323, Total Accuracy = 60.34%\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "Batch 0: Benign Loss = 1.1926, Adversarial Loss = 1.1926\n",
            "Batch 10: Benign Loss = 1.0577, Adversarial Loss = 1.0577\n",
            "Batch 20: Benign Loss = 1.1320, Adversarial Loss = 1.1320\n",
            "Batch 30: Benign Loss = 1.0954, Adversarial Loss = 1.0954\n",
            "Batch 40: Benign Loss = 1.0192, Adversarial Loss = 1.0192\n",
            "Batch 50: Benign Loss = 1.1120, Adversarial Loss = 1.1120\n",
            "Batch 60: Benign Loss = 1.1492, Adversarial Loss = 1.1492\n",
            "Batch 70: Benign Loss = 1.1293, Adversarial Loss = 1.1293\n",
            "Batch 80: Benign Loss = 1.1045, Adversarial Loss = 1.1045\n",
            "Batch 90: Benign Loss = 1.1190, Adversarial Loss = 1.1190\n",
            "Epoch 7: Benign Accuracy = 22.33%, Adversarial Accuracy = 60.61%\n",
            "Benign Loss = 2.7211, Adversarial Loss = 1.1239\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "Batch 0: Loss = 1.0911, Accuracy = 60.16%\n",
            "Batch 10: Loss = 1.1241, Accuracy = 60.09%\n",
            "Batch 20: Loss = 1.0310, Accuracy = 61.05%\n",
            "Batch 30: Loss = 1.3776, Accuracy = 60.69%\n",
            "Batch 40: Loss = 1.3112, Accuracy = 60.65%\n",
            "Batch 50: Loss = 1.1720, Accuracy = 61.14%\n",
            "Batch 60: Loss = 1.0408, Accuracy = 61.26%\n",
            "Batch 70: Loss = 1.2041, Accuracy = 61.12%\n",
            "Batch 80: Loss = 1.1348, Accuracy = 61.43%\n",
            "Batch 90: Loss = 1.1919, Accuracy = 61.33%\n",
            "Batch 100: Loss = 1.1352, Accuracy = 61.22%\n",
            "Batch 110: Loss = 1.0093, Accuracy = 61.06%\n",
            "Batch 120: Loss = 1.3033, Accuracy = 60.85%\n",
            "Batch 130: Loss = 1.0597, Accuracy = 61.00%\n",
            "Batch 140: Loss = 1.1765, Accuracy = 60.78%\n",
            "Batch 150: Loss = 1.1815, Accuracy = 60.65%\n",
            "Batch 160: Loss = 1.2504, Accuracy = 60.56%\n",
            "Batch 170: Loss = 1.0204, Accuracy = 60.54%\n",
            "Batch 180: Loss = 0.9363, Accuracy = 60.63%\n",
            "Batch 190: Loss = 1.0455, Accuracy = 60.54%\n",
            "Batch 200: Loss = 1.0189, Accuracy = 60.54%\n",
            "Batch 210: Loss = 1.2416, Accuracy = 60.52%\n",
            "Batch 220: Loss = 1.0222, Accuracy = 60.44%\n",
            "Batch 230: Loss = 1.3136, Accuracy = 60.36%\n",
            "Batch 240: Loss = 1.0985, Accuracy = 60.22%\n",
            "Batch 250: Loss = 1.3774, Accuracy = 60.16%\n",
            "Batch 260: Loss = 1.0852, Accuracy = 60.04%\n",
            "Batch 270: Loss = 1.1488, Accuracy = 60.04%\n",
            "Batch 280: Loss = 1.2629, Accuracy = 59.99%\n",
            "Batch 290: Loss = 1.2043, Accuracy = 59.90%\n",
            "Batch 300: Loss = 1.2600, Accuracy = 59.93%\n",
            "Batch 310: Loss = 1.0825, Accuracy = 59.99%\n",
            "Batch 320: Loss = 1.3247, Accuracy = 59.98%\n",
            "Batch 330: Loss = 1.0912, Accuracy = 59.94%\n",
            "Batch 340: Loss = 1.0538, Accuracy = 59.95%\n",
            "Batch 350: Loss = 1.2718, Accuracy = 59.98%\n",
            "Batch 360: Loss = 1.2013, Accuracy = 59.95%\n",
            "Batch 370: Loss = 1.1148, Accuracy = 59.92%\n",
            "Batch 380: Loss = 1.1274, Accuracy = 59.95%\n",
            "Batch 390: Loss = 1.2378, Accuracy = 60.00%\n",
            "Epoch 8: Total Loss = 1.1326, Total Accuracy = 60.00%\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "Batch 0: Benign Loss = 1.2174, Adversarial Loss = 1.2174\n",
            "Batch 10: Benign Loss = 1.0867, Adversarial Loss = 1.0867\n",
            "Batch 20: Benign Loss = 1.1125, Adversarial Loss = 1.1125\n",
            "Batch 30: Benign Loss = 1.0912, Adversarial Loss = 1.0912\n",
            "Batch 40: Benign Loss = 0.9700, Adversarial Loss = 0.9700\n",
            "Batch 50: Benign Loss = 1.0929, Adversarial Loss = 1.0929\n",
            "Batch 60: Benign Loss = 1.1449, Adversarial Loss = 1.1449\n",
            "Batch 70: Benign Loss = 1.0837, Adversarial Loss = 1.0837\n",
            "Batch 80: Benign Loss = 1.0318, Adversarial Loss = 1.0318\n",
            "Batch 90: Benign Loss = 1.0973, Adversarial Loss = 1.0973\n",
            "Epoch 8: Benign Accuracy = 23.68%, Adversarial Accuracy = 61.24%\n",
            "Benign Loss = 2.4046, Adversarial Loss = 1.1143\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "Batch 0: Loss = 1.0872, Accuracy = 61.72%\n",
            "Batch 10: Loss = 1.1879, Accuracy = 58.95%\n",
            "Batch 20: Loss = 1.1328, Accuracy = 59.45%\n",
            "Batch 30: Loss = 1.0295, Accuracy = 61.04%\n",
            "Batch 40: Loss = 1.1235, Accuracy = 60.63%\n",
            "Batch 50: Loss = 1.1309, Accuracy = 60.25%\n",
            "Batch 60: Loss = 0.9933, Accuracy = 60.46%\n",
            "Batch 70: Loss = 1.2640, Accuracy = 60.31%\n",
            "Batch 80: Loss = 1.1989, Accuracy = 60.17%\n",
            "Batch 90: Loss = 1.0250, Accuracy = 60.06%\n",
            "Batch 100: Loss = 1.1747, Accuracy = 60.00%\n",
            "Batch 110: Loss = 1.2960, Accuracy = 59.91%\n",
            "Batch 120: Loss = 1.0057, Accuracy = 59.90%\n",
            "Batch 130: Loss = 1.1353, Accuracy = 59.89%\n",
            "Batch 140: Loss = 1.2019, Accuracy = 59.89%\n",
            "Batch 150: Loss = 1.2445, Accuracy = 59.78%\n",
            "Batch 160: Loss = 1.0615, Accuracy = 59.78%\n",
            "Batch 170: Loss = 1.0873, Accuracy = 59.87%\n",
            "Batch 180: Loss = 1.0772, Accuracy = 59.86%\n",
            "Batch 190: Loss = 1.1292, Accuracy = 59.91%\n",
            "Batch 200: Loss = 1.0834, Accuracy = 59.93%\n",
            "Batch 210: Loss = 1.1787, Accuracy = 59.89%\n",
            "Batch 220: Loss = 1.1308, Accuracy = 59.93%\n",
            "Batch 230: Loss = 1.1571, Accuracy = 59.95%\n",
            "Batch 240: Loss = 1.1862, Accuracy = 60.00%\n",
            "Batch 250: Loss = 1.0661, Accuracy = 60.03%\n",
            "Batch 260: Loss = 1.1410, Accuracy = 60.10%\n",
            "Batch 270: Loss = 1.1643, Accuracy = 60.01%\n",
            "Batch 280: Loss = 1.0807, Accuracy = 60.02%\n",
            "Batch 290: Loss = 1.1861, Accuracy = 59.94%\n",
            "Batch 300: Loss = 1.0759, Accuracy = 59.91%\n",
            "Batch 310: Loss = 1.0321, Accuracy = 59.93%\n",
            "Batch 320: Loss = 1.1661, Accuracy = 59.90%\n",
            "Batch 330: Loss = 1.2884, Accuracy = 59.82%\n",
            "Batch 340: Loss = 0.9801, Accuracy = 59.76%\n",
            "Batch 350: Loss = 1.1961, Accuracy = 59.84%\n",
            "Batch 360: Loss = 1.3411, Accuracy = 59.83%\n",
            "Batch 370: Loss = 1.0884, Accuracy = 59.86%\n",
            "Batch 380: Loss = 1.2362, Accuracy = 59.89%\n",
            "Batch 390: Loss = 1.3815, Accuracy = 59.95%\n",
            "Epoch 9: Total Loss = 1.1338, Total Accuracy = 59.95%\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "Batch 0: Benign Loss = 1.2124, Adversarial Loss = 1.2124\n",
            "Batch 10: Benign Loss = 1.0550, Adversarial Loss = 1.0550\n",
            "Batch 20: Benign Loss = 1.1376, Adversarial Loss = 1.1376\n",
            "Batch 30: Benign Loss = 1.1190, Adversarial Loss = 1.1190\n",
            "Batch 40: Benign Loss = 1.0310, Adversarial Loss = 1.0310\n",
            "Batch 50: Benign Loss = 1.1254, Adversarial Loss = 1.1254\n",
            "Batch 60: Benign Loss = 1.1312, Adversarial Loss = 1.1312\n",
            "Batch 70: Benign Loss = 1.0825, Adversarial Loss = 1.0825\n",
            "Batch 80: Benign Loss = 1.0375, Adversarial Loss = 1.0375\n",
            "Batch 90: Benign Loss = 1.0959, Adversarial Loss = 1.0959\n",
            "Epoch 9: Benign Accuracy = 23.52%, Adversarial Accuracy = 60.90%\n",
            "Benign Loss = 2.4527, Adversarial Loss = 1.1154\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "Batch 0: Loss = 1.1455, Accuracy = 62.50%\n",
            "Batch 10: Loss = 1.0782, Accuracy = 60.16%\n",
            "Batch 20: Loss = 1.2834, Accuracy = 59.71%\n",
            "Batch 30: Loss = 1.2137, Accuracy = 60.06%\n",
            "Batch 40: Loss = 0.9516, Accuracy = 59.89%\n",
            "Batch 50: Loss = 1.2827, Accuracy = 59.47%\n",
            "Batch 60: Loss = 1.0447, Accuracy = 59.36%\n",
            "Batch 70: Loss = 1.0310, Accuracy = 59.62%\n",
            "Batch 80: Loss = 1.0427, Accuracy = 59.59%\n",
            "Batch 90: Loss = 1.1608, Accuracy = 59.56%\n",
            "Batch 100: Loss = 1.1133, Accuracy = 59.53%\n",
            "Batch 110: Loss = 1.0744, Accuracy = 59.52%\n",
            "Batch 120: Loss = 1.2870, Accuracy = 59.34%\n",
            "Batch 130: Loss = 0.9931, Accuracy = 59.43%\n",
            "Batch 140: Loss = 1.0535, Accuracy = 59.47%\n",
            "Batch 150: Loss = 0.9694, Accuracy = 59.65%\n",
            "Batch 160: Loss = 0.9864, Accuracy = 59.72%\n",
            "Batch 170: Loss = 1.0867, Accuracy = 59.82%\n",
            "Batch 180: Loss = 1.1031, Accuracy = 59.85%\n",
            "Batch 190: Loss = 1.0010, Accuracy = 59.85%\n",
            "Batch 200: Loss = 1.1710, Accuracy = 59.88%\n",
            "Batch 210: Loss = 1.1356, Accuracy = 59.90%\n",
            "Batch 220: Loss = 1.2715, Accuracy = 59.96%\n",
            "Batch 230: Loss = 1.0187, Accuracy = 59.95%\n",
            "Batch 240: Loss = 0.9770, Accuracy = 60.03%\n",
            "Batch 250: Loss = 1.1896, Accuracy = 59.99%\n",
            "Batch 260: Loss = 1.3194, Accuracy = 60.07%\n",
            "Batch 270: Loss = 1.1976, Accuracy = 60.14%\n",
            "Batch 280: Loss = 0.9963, Accuracy = 60.08%\n",
            "Batch 290: Loss = 1.1178, Accuracy = 60.09%\n",
            "Batch 300: Loss = 1.0819, Accuracy = 60.00%\n",
            "Batch 310: Loss = 0.9944, Accuracy = 59.96%\n",
            "Batch 320: Loss = 1.1305, Accuracy = 59.93%\n",
            "Batch 330: Loss = 0.9836, Accuracy = 60.01%\n",
            "Batch 340: Loss = 1.1299, Accuracy = 60.03%\n",
            "Batch 350: Loss = 1.1241, Accuracy = 60.01%\n",
            "Batch 360: Loss = 1.0269, Accuracy = 60.04%\n",
            "Batch 370: Loss = 1.0921, Accuracy = 60.04%\n",
            "Batch 380: Loss = 1.0628, Accuracy = 60.06%\n",
            "Batch 390: Loss = 1.2488, Accuracy = 60.03%\n",
            "Epoch 10: Total Loss = 1.1280, Total Accuracy = 60.03%\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "Batch 0: Benign Loss = 1.2170, Adversarial Loss = 1.2170\n",
            "Batch 10: Benign Loss = 1.0724, Adversarial Loss = 1.0724\n",
            "Batch 20: Benign Loss = 1.1609, Adversarial Loss = 1.1609\n",
            "Batch 30: Benign Loss = 1.1172, Adversarial Loss = 1.1172\n",
            "Batch 40: Benign Loss = 0.9981, Adversarial Loss = 0.9981\n",
            "Batch 50: Benign Loss = 1.0905, Adversarial Loss = 1.0905\n",
            "Batch 60: Benign Loss = 1.1652, Adversarial Loss = 1.1652\n",
            "Batch 70: Benign Loss = 1.1011, Adversarial Loss = 1.1011\n",
            "Batch 80: Benign Loss = 1.0063, Adversarial Loss = 1.0063\n",
            "Batch 90: Benign Loss = 1.0842, Adversarial Loss = 1.0842\n",
            "Epoch 10: Benign Accuracy = 23.19%, Adversarial Accuracy = 60.67%\n",
            "Benign Loss = 3.1199, Adversarial Loss = 1.1249\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "Batch 0: Loss = 1.2679, Accuracy = 52.34%\n",
            "Batch 10: Loss = 1.1470, Accuracy = 57.81%\n",
            "Batch 20: Loss = 1.1100, Accuracy = 57.96%\n",
            "Batch 30: Loss = 1.1274, Accuracy = 58.22%\n",
            "Batch 40: Loss = 1.2386, Accuracy = 58.40%\n",
            "Batch 50: Loss = 1.1585, Accuracy = 58.70%\n",
            "Batch 60: Loss = 1.1718, Accuracy = 58.93%\n",
            "Batch 70: Loss = 1.1652, Accuracy = 59.08%\n",
            "Batch 80: Loss = 1.0470, Accuracy = 59.33%\n",
            "Batch 90: Loss = 1.1378, Accuracy = 59.43%\n",
            "Batch 100: Loss = 1.0828, Accuracy = 59.40%\n",
            "Batch 110: Loss = 0.9843, Accuracy = 59.63%\n",
            "Batch 120: Loss = 1.1656, Accuracy = 59.79%\n",
            "Batch 130: Loss = 1.2462, Accuracy = 59.74%\n",
            "Batch 140: Loss = 0.9394, Accuracy = 59.83%\n",
            "Batch 150: Loss = 1.1888, Accuracy = 59.84%\n",
            "Batch 160: Loss = 1.1329, Accuracy = 59.82%\n",
            "Batch 170: Loss = 1.0409, Accuracy = 59.89%\n",
            "Batch 180: Loss = 1.1405, Accuracy = 59.99%\n",
            "Batch 190: Loss = 1.0138, Accuracy = 60.02%\n",
            "Batch 200: Loss = 1.2601, Accuracy = 60.00%\n",
            "Batch 210: Loss = 1.1229, Accuracy = 60.07%\n",
            "Batch 220: Loss = 1.0013, Accuracy = 60.13%\n",
            "Batch 230: Loss = 1.4420, Accuracy = 60.16%\n",
            "Batch 240: Loss = 1.0678, Accuracy = 60.21%\n",
            "Batch 250: Loss = 1.2389, Accuracy = 60.23%\n",
            "Batch 260: Loss = 1.0594, Accuracy = 60.21%\n",
            "Batch 270: Loss = 0.9981, Accuracy = 60.23%\n",
            "Batch 280: Loss = 1.0975, Accuracy = 60.12%\n",
            "Batch 290: Loss = 1.4054, Accuracy = 60.06%\n",
            "Batch 300: Loss = 1.0104, Accuracy = 60.10%\n",
            "Batch 310: Loss = 1.1581, Accuracy = 60.10%\n",
            "Batch 320: Loss = 0.9964, Accuracy = 60.11%\n",
            "Batch 330: Loss = 1.1279, Accuracy = 60.13%\n",
            "Batch 340: Loss = 0.9253, Accuracy = 60.17%\n",
            "Batch 350: Loss = 0.9893, Accuracy = 60.13%\n",
            "Batch 360: Loss = 1.1123, Accuracy = 60.09%\n",
            "Batch 370: Loss = 1.1663, Accuracy = 60.08%\n",
            "Batch 380: Loss = 1.0870, Accuracy = 60.07%\n",
            "Batch 390: Loss = 1.1379, Accuracy = 60.04%\n",
            "Epoch 11: Total Loss = 1.1288, Total Accuracy = 60.04%\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "Batch 0: Benign Loss = 1.2117, Adversarial Loss = 1.2117\n",
            "Batch 10: Benign Loss = 1.0881, Adversarial Loss = 1.0881\n",
            "Batch 20: Benign Loss = 1.1373, Adversarial Loss = 1.1373\n",
            "Batch 30: Benign Loss = 1.1114, Adversarial Loss = 1.1114\n",
            "Batch 40: Benign Loss = 0.9946, Adversarial Loss = 0.9946\n",
            "Batch 50: Benign Loss = 1.1208, Adversarial Loss = 1.1208\n",
            "Batch 60: Benign Loss = 1.1338, Adversarial Loss = 1.1338\n",
            "Batch 70: Benign Loss = 1.1408, Adversarial Loss = 1.1408\n",
            "Batch 80: Benign Loss = 1.0169, Adversarial Loss = 1.0169\n",
            "Batch 90: Benign Loss = 1.0417, Adversarial Loss = 1.0417\n",
            "Epoch 11: Benign Accuracy = 22.81%, Adversarial Accuracy = 60.91%\n",
            "Benign Loss = 2.7437, Adversarial Loss = 1.1182\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "Batch 0: Loss = 1.0997, Accuracy = 64.06%\n",
            "Batch 10: Loss = 1.2321, Accuracy = 62.29%\n",
            "Batch 20: Loss = 1.0912, Accuracy = 59.56%\n",
            "Batch 30: Loss = 1.0586, Accuracy = 59.32%\n",
            "Batch 40: Loss = 1.1562, Accuracy = 59.38%\n",
            "Batch 50: Loss = 1.1569, Accuracy = 59.15%\n",
            "Batch 60: Loss = 1.1767, Accuracy = 59.22%\n",
            "Batch 70: Loss = 1.0989, Accuracy = 59.08%\n",
            "Batch 80: Loss = 1.1760, Accuracy = 59.64%\n",
            "Batch 90: Loss = 1.1831, Accuracy = 59.71%\n",
            "Batch 100: Loss = 1.0677, Accuracy = 59.61%\n",
            "Batch 110: Loss = 1.0532, Accuracy = 59.63%\n",
            "Batch 120: Loss = 1.1367, Accuracy = 59.87%\n",
            "Batch 130: Loss = 1.1466, Accuracy = 59.90%\n",
            "Batch 140: Loss = 1.1487, Accuracy = 59.87%\n",
            "Batch 150: Loss = 1.0043, Accuracy = 59.70%\n",
            "Batch 160: Loss = 1.0743, Accuracy = 59.67%\n",
            "Batch 170: Loss = 1.1770, Accuracy = 59.65%\n",
            "Batch 180: Loss = 1.0489, Accuracy = 59.76%\n",
            "Batch 190: Loss = 1.1803, Accuracy = 59.76%\n",
            "Batch 200: Loss = 1.0382, Accuracy = 59.89%\n",
            "Batch 210: Loss = 1.1376, Accuracy = 59.87%\n",
            "Batch 220: Loss = 1.1565, Accuracy = 59.84%\n",
            "Batch 230: Loss = 1.1686, Accuracy = 59.76%\n",
            "Batch 240: Loss = 1.2426, Accuracy = 59.74%\n",
            "Batch 250: Loss = 1.0324, Accuracy = 59.73%\n",
            "Batch 260: Loss = 1.0079, Accuracy = 59.73%\n",
            "Batch 270: Loss = 1.0577, Accuracy = 59.76%\n",
            "Batch 280: Loss = 1.0981, Accuracy = 59.76%\n",
            "Batch 290: Loss = 1.1997, Accuracy = 59.81%\n",
            "Batch 300: Loss = 1.0969, Accuracy = 59.79%\n",
            "Batch 310: Loss = 1.0793, Accuracy = 59.80%\n",
            "Batch 320: Loss = 1.0200, Accuracy = 59.80%\n",
            "Batch 330: Loss = 1.0170, Accuracy = 59.79%\n",
            "Batch 340: Loss = 1.1007, Accuracy = 59.86%\n",
            "Batch 350: Loss = 1.0224, Accuracy = 59.84%\n",
            "Batch 360: Loss = 1.1719, Accuracy = 59.89%\n",
            "Batch 370: Loss = 1.0325, Accuracy = 59.85%\n",
            "Batch 380: Loss = 1.1970, Accuracy = 59.88%\n",
            "Batch 390: Loss = 1.2477, Accuracy = 59.89%\n",
            "Epoch 12: Total Loss = 1.1305, Total Accuracy = 59.89%\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "Batch 0: Benign Loss = 1.1750, Adversarial Loss = 1.1750\n",
            "Batch 10: Benign Loss = 1.0318, Adversarial Loss = 1.0318\n",
            "Batch 20: Benign Loss = 1.1553, Adversarial Loss = 1.1553\n",
            "Batch 30: Benign Loss = 1.0851, Adversarial Loss = 1.0851\n",
            "Batch 40: Benign Loss = 0.9835, Adversarial Loss = 0.9835\n",
            "Batch 50: Benign Loss = 1.0903, Adversarial Loss = 1.0903\n",
            "Batch 60: Benign Loss = 1.1184, Adversarial Loss = 1.1184\n",
            "Batch 70: Benign Loss = 1.1166, Adversarial Loss = 1.1166\n",
            "Batch 80: Benign Loss = 1.0399, Adversarial Loss = 1.0399\n",
            "Batch 90: Benign Loss = 1.0883, Adversarial Loss = 1.0883\n",
            "Epoch 12: Benign Accuracy = 22.25%, Adversarial Accuracy = 60.98%\n",
            "Benign Loss = 2.6116, Adversarial Loss = 1.1123\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "Batch 0: Loss = 0.9991, Accuracy = 64.84%\n",
            "Batch 10: Loss = 1.1393, Accuracy = 61.15%\n",
            "Batch 20: Loss = 1.2613, Accuracy = 60.71%\n",
            "Batch 30: Loss = 1.1754, Accuracy = 60.38%\n",
            "Batch 40: Loss = 1.2159, Accuracy = 59.98%\n",
            "Batch 50: Loss = 1.2291, Accuracy = 60.39%\n",
            "Batch 60: Loss = 1.1394, Accuracy = 59.94%\n",
            "Batch 70: Loss = 1.0766, Accuracy = 59.98%\n",
            "Batch 80: Loss = 0.8615, Accuracy = 60.12%\n",
            "Batch 90: Loss = 1.2890, Accuracy = 59.97%\n",
            "Batch 100: Loss = 1.1344, Accuracy = 59.88%\n",
            "Batch 110: Loss = 1.1373, Accuracy = 59.96%\n",
            "Batch 120: Loss = 1.2602, Accuracy = 59.90%\n",
            "Batch 130: Loss = 1.1156, Accuracy = 59.75%\n",
            "Batch 140: Loss = 1.1758, Accuracy = 59.85%\n",
            "Batch 150: Loss = 1.1370, Accuracy = 59.77%\n",
            "Batch 160: Loss = 1.2329, Accuracy = 59.85%\n",
            "Batch 170: Loss = 1.0830, Accuracy = 59.90%\n",
            "Batch 180: Loss = 1.0191, Accuracy = 59.91%\n",
            "Batch 190: Loss = 1.1387, Accuracy = 59.96%\n",
            "Batch 200: Loss = 1.0411, Accuracy = 59.96%\n",
            "Batch 210: Loss = 1.1569, Accuracy = 59.89%\n",
            "Batch 220: Loss = 1.3753, Accuracy = 59.88%\n",
            "Batch 230: Loss = 1.1627, Accuracy = 59.89%\n",
            "Batch 240: Loss = 1.0164, Accuracy = 59.98%\n",
            "Batch 250: Loss = 1.2002, Accuracy = 59.99%\n",
            "Batch 260: Loss = 1.0986, Accuracy = 60.01%\n",
            "Batch 270: Loss = 1.0688, Accuracy = 59.99%\n",
            "Batch 280: Loss = 0.9856, Accuracy = 60.02%\n",
            "Batch 290: Loss = 1.3874, Accuracy = 59.97%\n",
            "Batch 300: Loss = 1.1729, Accuracy = 60.05%\n",
            "Batch 310: Loss = 1.0797, Accuracy = 60.03%\n",
            "Batch 320: Loss = 1.1188, Accuracy = 59.98%\n",
            "Batch 330: Loss = 1.1524, Accuracy = 60.02%\n",
            "Batch 340: Loss = 0.9249, Accuracy = 60.04%\n",
            "Batch 350: Loss = 1.3818, Accuracy = 60.02%\n",
            "Batch 360: Loss = 1.0550, Accuracy = 60.00%\n",
            "Batch 370: Loss = 1.1604, Accuracy = 60.02%\n",
            "Batch 380: Loss = 1.1481, Accuracy = 60.02%\n",
            "Batch 390: Loss = 0.9642, Accuracy = 60.03%\n",
            "Epoch 13: Total Loss = 1.1265, Total Accuracy = 60.03%\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "Batch 0: Benign Loss = 1.1824, Adversarial Loss = 1.1824\n",
            "Batch 10: Benign Loss = 1.0618, Adversarial Loss = 1.0618\n",
            "Batch 20: Benign Loss = 1.1870, Adversarial Loss = 1.1870\n",
            "Batch 30: Benign Loss = 1.1095, Adversarial Loss = 1.1095\n",
            "Batch 40: Benign Loss = 1.0033, Adversarial Loss = 1.0033\n",
            "Batch 50: Benign Loss = 1.1141, Adversarial Loss = 1.1141\n",
            "Batch 60: Benign Loss = 1.1704, Adversarial Loss = 1.1704\n",
            "Batch 70: Benign Loss = 1.1375, Adversarial Loss = 1.1375\n",
            "Batch 80: Benign Loss = 1.0482, Adversarial Loss = 1.0482\n",
            "Batch 90: Benign Loss = 1.0882, Adversarial Loss = 1.0882\n",
            "Epoch 13: Benign Accuracy = 24.62%, Adversarial Accuracy = 59.97%\n",
            "Benign Loss = 2.4289, Adversarial Loss = 1.1419\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "Batch 0: Loss = 0.8826, Accuracy = 65.62%\n",
            "Batch 10: Loss = 1.3197, Accuracy = 59.16%\n",
            "Batch 20: Loss = 1.2832, Accuracy = 59.82%\n",
            "Batch 30: Loss = 1.1447, Accuracy = 59.58%\n",
            "Batch 40: Loss = 1.1586, Accuracy = 59.85%\n",
            "Batch 50: Loss = 1.1284, Accuracy = 59.91%\n",
            "Batch 60: Loss = 1.1565, Accuracy = 60.09%\n",
            "Batch 70: Loss = 1.1524, Accuracy = 59.90%\n",
            "Batch 80: Loss = 1.1638, Accuracy = 59.95%\n",
            "Batch 90: Loss = 1.0711, Accuracy = 59.98%\n",
            "Batch 100: Loss = 1.0758, Accuracy = 60.02%\n",
            "Batch 110: Loss = 1.1750, Accuracy = 59.92%\n",
            "Batch 120: Loss = 1.0557, Accuracy = 59.82%\n",
            "Batch 130: Loss = 1.1474, Accuracy = 59.91%\n",
            "Batch 140: Loss = 1.1384, Accuracy = 59.82%\n",
            "Batch 150: Loss = 1.1016, Accuracy = 59.79%\n",
            "Batch 160: Loss = 1.0899, Accuracy = 59.85%\n",
            "Batch 170: Loss = 1.0312, Accuracy = 59.94%\n",
            "Batch 180: Loss = 1.2127, Accuracy = 60.00%\n",
            "Batch 190: Loss = 1.0536, Accuracy = 60.08%\n",
            "Batch 200: Loss = 1.2450, Accuracy = 60.02%\n",
            "Batch 210: Loss = 0.9948, Accuracy = 59.99%\n",
            "Batch 220: Loss = 1.0970, Accuracy = 60.07%\n",
            "Batch 230: Loss = 1.1319, Accuracy = 60.15%\n",
            "Batch 240: Loss = 1.2632, Accuracy = 60.11%\n",
            "Batch 250: Loss = 1.1910, Accuracy = 60.16%\n",
            "Batch 260: Loss = 0.9834, Accuracy = 60.28%\n",
            "Batch 270: Loss = 0.9970, Accuracy = 60.40%\n",
            "Batch 280: Loss = 1.1302, Accuracy = 60.42%\n",
            "Batch 290: Loss = 1.2673, Accuracy = 60.38%\n",
            "Batch 300: Loss = 1.2448, Accuracy = 60.30%\n",
            "Batch 310: Loss = 0.9300, Accuracy = 60.32%\n",
            "Batch 320: Loss = 1.0693, Accuracy = 60.30%\n",
            "Batch 330: Loss = 1.2503, Accuracy = 60.32%\n",
            "Batch 340: Loss = 1.0702, Accuracy = 60.30%\n",
            "Batch 350: Loss = 1.1945, Accuracy = 60.25%\n",
            "Batch 360: Loss = 1.2302, Accuracy = 60.27%\n",
            "Batch 370: Loss = 0.9819, Accuracy = 60.29%\n",
            "Batch 380: Loss = 1.0697, Accuracy = 60.27%\n",
            "Batch 390: Loss = 1.0613, Accuracy = 60.30%\n",
            "Epoch 14: Total Loss = 1.1231, Total Accuracy = 60.30%\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "Batch 0: Benign Loss = 1.2040, Adversarial Loss = 1.2040\n",
            "Batch 10: Benign Loss = 1.0658, Adversarial Loss = 1.0658\n",
            "Batch 20: Benign Loss = 1.1600, Adversarial Loss = 1.1600\n",
            "Batch 30: Benign Loss = 1.0806, Adversarial Loss = 1.0806\n",
            "Batch 40: Benign Loss = 0.9796, Adversarial Loss = 0.9796\n",
            "Batch 50: Benign Loss = 1.1177, Adversarial Loss = 1.1177\n",
            "Batch 60: Benign Loss = 1.1355, Adversarial Loss = 1.1355\n",
            "Batch 70: Benign Loss = 1.0944, Adversarial Loss = 1.0944\n",
            "Batch 80: Benign Loss = 1.0219, Adversarial Loss = 1.0219\n",
            "Batch 90: Benign Loss = 1.0743, Adversarial Loss = 1.0743\n",
            "Epoch 14: Benign Accuracy = 23.57%, Adversarial Accuracy = 61.25%\n",
            "Benign Loss = 3.1594, Adversarial Loss = 1.1182\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "Batch 0: Loss = 1.0882, Accuracy = 67.19%\n",
            "Batch 10: Loss = 1.0104, Accuracy = 61.29%\n",
            "Batch 20: Loss = 1.2369, Accuracy = 60.68%\n",
            "Batch 30: Loss = 1.2631, Accuracy = 59.85%\n",
            "Batch 40: Loss = 1.1728, Accuracy = 60.18%\n",
            "Batch 50: Loss = 1.1978, Accuracy = 60.06%\n",
            "Batch 60: Loss = 1.1911, Accuracy = 60.51%\n",
            "Batch 70: Loss = 1.0438, Accuracy = 60.46%\n",
            "Batch 80: Loss = 0.9439, Accuracy = 60.63%\n",
            "Batch 90: Loss = 1.1525, Accuracy = 60.66%\n",
            "Batch 100: Loss = 1.1147, Accuracy = 60.58%\n",
            "Batch 110: Loss = 0.9563, Accuracy = 60.68%\n",
            "Batch 120: Loss = 1.1505, Accuracy = 60.61%\n",
            "Batch 130: Loss = 1.0303, Accuracy = 60.58%\n",
            "Batch 140: Loss = 1.0099, Accuracy = 60.65%\n",
            "Batch 150: Loss = 1.1620, Accuracy = 60.67%\n",
            "Batch 160: Loss = 1.0689, Accuracy = 60.63%\n",
            "Batch 170: Loss = 1.1227, Accuracy = 60.69%\n",
            "Batch 180: Loss = 0.9677, Accuracy = 60.66%\n",
            "Batch 190: Loss = 1.0875, Accuracy = 60.69%\n",
            "Batch 200: Loss = 1.2381, Accuracy = 60.71%\n",
            "Batch 210: Loss = 1.0661, Accuracy = 60.68%\n",
            "Batch 220: Loss = 0.9942, Accuracy = 60.66%\n",
            "Batch 230: Loss = 1.0935, Accuracy = 60.67%\n",
            "Batch 240: Loss = 0.9944, Accuracy = 60.71%\n",
            "Batch 250: Loss = 1.0935, Accuracy = 60.69%\n",
            "Batch 260: Loss = 0.9662, Accuracy = 60.64%\n",
            "Batch 270: Loss = 1.0667, Accuracy = 60.68%\n",
            "Batch 280: Loss = 1.0513, Accuracy = 60.61%\n",
            "Batch 290: Loss = 1.2244, Accuracy = 60.68%\n",
            "Batch 300: Loss = 1.1723, Accuracy = 60.65%\n",
            "Batch 310: Loss = 1.0357, Accuracy = 60.68%\n",
            "Batch 320: Loss = 1.2427, Accuracy = 60.66%\n",
            "Batch 330: Loss = 1.1147, Accuracy = 60.65%\n",
            "Batch 340: Loss = 1.1816, Accuracy = 60.64%\n",
            "Batch 350: Loss = 1.2687, Accuracy = 60.63%\n",
            "Batch 360: Loss = 1.2326, Accuracy = 60.58%\n",
            "Batch 370: Loss = 1.0797, Accuracy = 60.59%\n",
            "Batch 380: Loss = 1.0832, Accuracy = 60.51%\n",
            "Batch 390: Loss = 1.0600, Accuracy = 60.53%\n",
            "Epoch 15: Total Loss = 1.1186, Total Accuracy = 60.53%\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "Batch 0: Benign Loss = 1.1712, Adversarial Loss = 1.1712\n",
            "Batch 10: Benign Loss = 1.0868, Adversarial Loss = 1.0868\n",
            "Batch 20: Benign Loss = 1.1615, Adversarial Loss = 1.1615\n",
            "Batch 30: Benign Loss = 1.1023, Adversarial Loss = 1.1023\n",
            "Batch 40: Benign Loss = 1.0002, Adversarial Loss = 1.0002\n",
            "Batch 50: Benign Loss = 1.1199, Adversarial Loss = 1.1199\n",
            "Batch 60: Benign Loss = 1.1049, Adversarial Loss = 1.1049\n",
            "Batch 70: Benign Loss = 1.1335, Adversarial Loss = 1.1335\n",
            "Batch 80: Benign Loss = 1.0424, Adversarial Loss = 1.0424\n",
            "Batch 90: Benign Loss = 1.0570, Adversarial Loss = 1.0570\n",
            "Epoch 15: Benign Accuracy = 23.88%, Adversarial Accuracy = 60.82%\n",
            "Benign Loss = 2.6936, Adversarial Loss = 1.1186\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "Batch 0: Loss = 0.9829, Accuracy = 64.84%\n",
            "Batch 10: Loss = 1.1659, Accuracy = 60.30%\n",
            "Batch 20: Loss = 1.0129, Accuracy = 60.71%\n",
            "Batch 30: Loss = 1.2062, Accuracy = 60.86%\n",
            "Batch 40: Loss = 1.0470, Accuracy = 60.61%\n",
            "Batch 50: Loss = 1.1871, Accuracy = 60.63%\n",
            "Batch 60: Loss = 1.0732, Accuracy = 60.34%\n",
            "Batch 70: Loss = 1.1153, Accuracy = 60.56%\n",
            "Batch 80: Loss = 1.2087, Accuracy = 60.50%\n",
            "Batch 90: Loss = 1.0987, Accuracy = 60.56%\n",
            "Batch 100: Loss = 0.9862, Accuracy = 60.88%\n",
            "Batch 110: Loss = 1.1369, Accuracy = 60.83%\n",
            "Batch 120: Loss = 1.1719, Accuracy = 60.73%\n",
            "Batch 130: Loss = 1.0743, Accuracy = 60.72%\n",
            "Batch 140: Loss = 1.3400, Accuracy = 60.84%\n",
            "Batch 150: Loss = 1.1146, Accuracy = 60.84%\n",
            "Batch 160: Loss = 1.1334, Accuracy = 60.71%\n",
            "Batch 170: Loss = 1.2690, Accuracy = 60.66%\n",
            "Batch 180: Loss = 1.1403, Accuracy = 60.64%\n",
            "Batch 190: Loss = 1.0747, Accuracy = 60.59%\n",
            "Batch 200: Loss = 1.1136, Accuracy = 60.59%\n",
            "Batch 210: Loss = 0.9537, Accuracy = 60.57%\n",
            "Batch 220: Loss = 1.1323, Accuracy = 60.52%\n",
            "Batch 230: Loss = 1.1856, Accuracy = 60.53%\n",
            "Batch 240: Loss = 0.9988, Accuracy = 60.53%\n",
            "Batch 250: Loss = 1.0641, Accuracy = 60.51%\n",
            "Batch 260: Loss = 1.1642, Accuracy = 60.58%\n",
            "Batch 270: Loss = 1.1291, Accuracy = 60.57%\n",
            "Batch 280: Loss = 1.2239, Accuracy = 60.53%\n",
            "Batch 290: Loss = 1.0409, Accuracy = 60.62%\n",
            "Batch 300: Loss = 1.1553, Accuracy = 60.50%\n",
            "Batch 310: Loss = 1.1496, Accuracy = 60.53%\n",
            "Batch 320: Loss = 1.2529, Accuracy = 60.50%\n",
            "Batch 330: Loss = 1.3128, Accuracy = 60.51%\n",
            "Batch 340: Loss = 1.1922, Accuracy = 60.49%\n",
            "Batch 350: Loss = 1.0204, Accuracy = 60.45%\n",
            "Batch 360: Loss = 1.0824, Accuracy = 60.52%\n",
            "Batch 370: Loss = 1.0909, Accuracy = 60.51%\n",
            "Batch 380: Loss = 1.1293, Accuracy = 60.63%\n",
            "Batch 390: Loss = 1.3654, Accuracy = 60.61%\n",
            "Epoch 16: Total Loss = 1.1196, Total Accuracy = 60.61%\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "Batch 0: Benign Loss = 1.2174, Adversarial Loss = 1.2174\n",
            "Batch 10: Benign Loss = 1.0670, Adversarial Loss = 1.0670\n",
            "Batch 20: Benign Loss = 1.1220, Adversarial Loss = 1.1220\n",
            "Batch 30: Benign Loss = 1.1139, Adversarial Loss = 1.1139\n",
            "Batch 40: Benign Loss = 0.9932, Adversarial Loss = 0.9932\n",
            "Batch 50: Benign Loss = 1.0836, Adversarial Loss = 1.0836\n",
            "Batch 60: Benign Loss = 1.1271, Adversarial Loss = 1.1271\n",
            "Batch 70: Benign Loss = 1.1230, Adversarial Loss = 1.1230\n",
            "Batch 80: Benign Loss = 1.0100, Adversarial Loss = 1.0100\n",
            "Batch 90: Benign Loss = 1.0883, Adversarial Loss = 1.0883\n",
            "Epoch 16: Benign Accuracy = 24.01%, Adversarial Accuracy = 60.58%\n",
            "Benign Loss = 2.5261, Adversarial Loss = 1.1211\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "Batch 0: Loss = 0.9649, Accuracy = 67.97%\n",
            "Batch 10: Loss = 1.1803, Accuracy = 61.65%\n",
            "Batch 20: Loss = 1.1021, Accuracy = 61.38%\n",
            "Batch 30: Loss = 1.1099, Accuracy = 61.49%\n",
            "Batch 40: Loss = 1.0855, Accuracy = 61.24%\n",
            "Batch 50: Loss = 1.2311, Accuracy = 60.91%\n",
            "Batch 60: Loss = 1.1089, Accuracy = 60.46%\n",
            "Batch 70: Loss = 1.2950, Accuracy = 60.84%\n",
            "Batch 80: Loss = 1.1409, Accuracy = 60.58%\n",
            "Batch 90: Loss = 1.1379, Accuracy = 60.29%\n",
            "Batch 100: Loss = 1.0227, Accuracy = 60.40%\n",
            "Batch 110: Loss = 1.1061, Accuracy = 60.40%\n",
            "Batch 120: Loss = 1.0146, Accuracy = 60.60%\n",
            "Batch 130: Loss = 1.0211, Accuracy = 60.63%\n",
            "Batch 140: Loss = 1.1146, Accuracy = 60.62%\n",
            "Batch 150: Loss = 1.0296, Accuracy = 60.69%\n",
            "Batch 160: Loss = 1.0689, Accuracy = 60.64%\n",
            "Batch 170: Loss = 1.3141, Accuracy = 60.70%\n",
            "Batch 180: Loss = 1.1928, Accuracy = 60.66%\n",
            "Batch 190: Loss = 1.0367, Accuracy = 60.63%\n",
            "Batch 200: Loss = 1.0910, Accuracy = 60.63%\n",
            "Batch 210: Loss = 1.1868, Accuracy = 60.62%\n",
            "Batch 220: Loss = 1.0387, Accuracy = 60.73%\n",
            "Batch 230: Loss = 1.0961, Accuracy = 60.68%\n",
            "Batch 240: Loss = 1.1157, Accuracy = 60.68%\n",
            "Batch 250: Loss = 1.1530, Accuracy = 60.77%\n",
            "Batch 260: Loss = 1.0392, Accuracy = 60.84%\n",
            "Batch 270: Loss = 1.1916, Accuracy = 60.78%\n",
            "Batch 280: Loss = 1.3271, Accuracy = 60.82%\n",
            "Batch 290: Loss = 1.1305, Accuracy = 60.79%\n",
            "Batch 300: Loss = 1.0425, Accuracy = 60.73%\n",
            "Batch 310: Loss = 1.0955, Accuracy = 60.71%\n",
            "Batch 320: Loss = 1.1689, Accuracy = 60.69%\n",
            "Batch 330: Loss = 0.9813, Accuracy = 60.67%\n",
            "Batch 340: Loss = 1.1185, Accuracy = 60.68%\n",
            "Batch 350: Loss = 1.1362, Accuracy = 60.63%\n",
            "Batch 360: Loss = 1.1263, Accuracy = 60.59%\n",
            "Batch 370: Loss = 1.0130, Accuracy = 60.56%\n",
            "Batch 380: Loss = 1.1964, Accuracy = 60.61%\n",
            "Batch 390: Loss = 1.0991, Accuracy = 60.60%\n",
            "Epoch 17: Total Loss = 1.1166, Total Accuracy = 60.60%\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "Batch 0: Benign Loss = 1.1990, Adversarial Loss = 1.1990\n",
            "Batch 10: Benign Loss = 1.0747, Adversarial Loss = 1.0747\n",
            "Batch 20: Benign Loss = 1.1202, Adversarial Loss = 1.1202\n",
            "Batch 30: Benign Loss = 1.1290, Adversarial Loss = 1.1290\n",
            "Batch 40: Benign Loss = 0.9952, Adversarial Loss = 0.9952\n",
            "Batch 50: Benign Loss = 1.1159, Adversarial Loss = 1.1159\n",
            "Batch 60: Benign Loss = 1.0920, Adversarial Loss = 1.0920\n",
            "Batch 70: Benign Loss = 1.0979, Adversarial Loss = 1.0979\n",
            "Batch 80: Benign Loss = 1.0043, Adversarial Loss = 1.0043\n",
            "Batch 90: Benign Loss = 1.0679, Adversarial Loss = 1.0679\n",
            "Epoch 17: Benign Accuracy = 23.19%, Adversarial Accuracy = 60.94%\n",
            "Benign Loss = 2.7402, Adversarial Loss = 1.1169\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "Batch 0: Loss = 1.2893, Accuracy = 58.59%\n",
            "Batch 10: Loss = 1.0096, Accuracy = 60.30%\n",
            "Batch 20: Loss = 1.0841, Accuracy = 60.94%\n",
            "Batch 30: Loss = 0.9718, Accuracy = 61.44%\n",
            "Batch 40: Loss = 1.1991, Accuracy = 61.36%\n",
            "Batch 50: Loss = 1.2181, Accuracy = 61.06%\n",
            "Batch 60: Loss = 1.0948, Accuracy = 61.14%\n",
            "Batch 70: Loss = 1.0644, Accuracy = 61.30%\n",
            "Batch 80: Loss = 1.1919, Accuracy = 61.48%\n",
            "Batch 90: Loss = 1.1817, Accuracy = 61.18%\n",
            "Batch 100: Loss = 1.1518, Accuracy = 61.12%\n",
            "Batch 110: Loss = 1.4406, Accuracy = 61.02%\n",
            "Batch 120: Loss = 1.1181, Accuracy = 61.10%\n",
            "Batch 130: Loss = 1.3391, Accuracy = 60.98%\n",
            "Batch 140: Loss = 1.1071, Accuracy = 60.90%\n",
            "Batch 150: Loss = 1.2117, Accuracy = 60.76%\n",
            "Batch 160: Loss = 1.0436, Accuracy = 60.74%\n",
            "Batch 170: Loss = 1.1378, Accuracy = 60.64%\n",
            "Batch 180: Loss = 1.1783, Accuracy = 60.61%\n",
            "Batch 190: Loss = 1.1611, Accuracy = 60.67%\n",
            "Batch 200: Loss = 0.9943, Accuracy = 60.73%\n",
            "Batch 210: Loss = 1.2544, Accuracy = 60.70%\n",
            "Batch 220: Loss = 1.0591, Accuracy = 60.65%\n",
            "Batch 230: Loss = 1.0301, Accuracy = 60.70%\n",
            "Batch 240: Loss = 1.2432, Accuracy = 60.66%\n",
            "Batch 250: Loss = 1.1372, Accuracy = 60.62%\n",
            "Batch 260: Loss = 1.3426, Accuracy = 60.60%\n",
            "Batch 270: Loss = 1.0567, Accuracy = 60.56%\n",
            "Batch 280: Loss = 0.9530, Accuracy = 60.66%\n",
            "Batch 290: Loss = 1.3529, Accuracy = 60.56%\n",
            "Batch 300: Loss = 1.0356, Accuracy = 60.54%\n",
            "Batch 310: Loss = 1.2167, Accuracy = 60.51%\n",
            "Batch 320: Loss = 1.1899, Accuracy = 60.44%\n",
            "Batch 330: Loss = 1.0762, Accuracy = 60.40%\n",
            "Batch 340: Loss = 1.1908, Accuracy = 60.38%\n",
            "Batch 350: Loss = 1.2296, Accuracy = 60.37%\n",
            "Batch 360: Loss = 1.2771, Accuracy = 60.34%\n",
            "Batch 370: Loss = 1.0481, Accuracy = 60.35%\n",
            "Batch 380: Loss = 1.1053, Accuracy = 60.31%\n",
            "Batch 390: Loss = 1.0687, Accuracy = 60.26%\n",
            "Epoch 18: Total Loss = 1.1232, Total Accuracy = 60.26%\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "Batch 0: Benign Loss = 1.2030, Adversarial Loss = 1.2030\n",
            "Batch 10: Benign Loss = 1.0977, Adversarial Loss = 1.0977\n",
            "Batch 20: Benign Loss = 1.1438, Adversarial Loss = 1.1438\n",
            "Batch 30: Benign Loss = 1.0797, Adversarial Loss = 1.0797\n",
            "Batch 40: Benign Loss = 1.0116, Adversarial Loss = 1.0116\n",
            "Batch 50: Benign Loss = 1.0912, Adversarial Loss = 1.0912\n",
            "Batch 60: Benign Loss = 1.1373, Adversarial Loss = 1.1373\n",
            "Batch 70: Benign Loss = 1.1631, Adversarial Loss = 1.1631\n",
            "Batch 80: Benign Loss = 1.0424, Adversarial Loss = 1.0424\n",
            "Batch 90: Benign Loss = 1.0992, Adversarial Loss = 1.0992\n",
            "Epoch 18: Benign Accuracy = 23.56%, Adversarial Accuracy = 60.81%\n",
            "Benign Loss = 2.3955, Adversarial Loss = 1.1332\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "Batch 0: Loss = 1.0328, Accuracy = 59.38%\n",
            "Batch 10: Loss = 1.0455, Accuracy = 59.87%\n",
            "Batch 20: Loss = 1.1211, Accuracy = 60.19%\n",
            "Batch 30: Loss = 1.0639, Accuracy = 59.85%\n",
            "Batch 40: Loss = 1.1635, Accuracy = 59.95%\n",
            "Batch 50: Loss = 1.1353, Accuracy = 60.11%\n",
            "Batch 60: Loss = 1.1140, Accuracy = 59.95%\n",
            "Batch 70: Loss = 1.3807, Accuracy = 59.86%\n",
            "Batch 80: Loss = 1.0927, Accuracy = 60.21%\n",
            "Batch 90: Loss = 1.1486, Accuracy = 60.57%\n",
            "Batch 100: Loss = 1.1387, Accuracy = 60.54%\n",
            "Batch 110: Loss = 1.0756, Accuracy = 60.44%\n",
            "Batch 120: Loss = 0.9760, Accuracy = 60.38%\n",
            "Batch 130: Loss = 1.0666, Accuracy = 60.46%\n",
            "Batch 140: Loss = 0.9708, Accuracy = 60.42%\n",
            "Batch 150: Loss = 1.2098, Accuracy = 60.38%\n",
            "Batch 160: Loss = 1.0091, Accuracy = 60.27%\n",
            "Batch 170: Loss = 1.0219, Accuracy = 60.26%\n",
            "Batch 180: Loss = 1.0659, Accuracy = 60.29%\n",
            "Batch 190: Loss = 1.0736, Accuracy = 60.31%\n",
            "Batch 200: Loss = 1.2012, Accuracy = 60.39%\n",
            "Batch 210: Loss = 1.1068, Accuracy = 60.41%\n",
            "Batch 220: Loss = 1.0961, Accuracy = 60.38%\n",
            "Batch 230: Loss = 0.9107, Accuracy = 60.35%\n",
            "Batch 240: Loss = 0.9784, Accuracy = 60.34%\n",
            "Batch 250: Loss = 1.1922, Accuracy = 60.30%\n",
            "Batch 260: Loss = 0.8699, Accuracy = 60.37%\n",
            "Batch 270: Loss = 1.0838, Accuracy = 60.42%\n",
            "Batch 280: Loss = 1.0661, Accuracy = 60.43%\n",
            "Batch 290: Loss = 1.0708, Accuracy = 60.38%\n",
            "Batch 300: Loss = 1.2229, Accuracy = 60.42%\n",
            "Batch 310: Loss = 1.0539, Accuracy = 60.47%\n",
            "Batch 320: Loss = 1.1344, Accuracy = 60.50%\n",
            "Batch 330: Loss = 0.9665, Accuracy = 60.50%\n",
            "Batch 340: Loss = 1.1135, Accuracy = 60.48%\n",
            "Batch 350: Loss = 1.0517, Accuracy = 60.48%\n",
            "Batch 360: Loss = 1.0557, Accuracy = 60.50%\n",
            "Batch 370: Loss = 0.9971, Accuracy = 60.48%\n",
            "Batch 380: Loss = 0.9293, Accuracy = 60.49%\n",
            "Batch 390: Loss = 0.9779, Accuracy = 60.44%\n",
            "Epoch 19: Total Loss = 1.1149, Total Accuracy = 60.44%\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "Batch 0: Benign Loss = 1.2354, Adversarial Loss = 1.2354\n",
            "Batch 10: Benign Loss = 1.0921, Adversarial Loss = 1.0921\n",
            "Batch 20: Benign Loss = 1.0786, Adversarial Loss = 1.0786\n",
            "Batch 30: Benign Loss = 1.0746, Adversarial Loss = 1.0746\n",
            "Batch 40: Benign Loss = 0.9932, Adversarial Loss = 0.9932\n",
            "Batch 50: Benign Loss = 1.0884, Adversarial Loss = 1.0884\n",
            "Batch 60: Benign Loss = 1.1094, Adversarial Loss = 1.1094\n",
            "Batch 70: Benign Loss = 1.1462, Adversarial Loss = 1.1462\n",
            "Batch 80: Benign Loss = 1.0322, Adversarial Loss = 1.0322\n",
            "Batch 90: Benign Loss = 1.0855, Adversarial Loss = 1.0855\n",
            "Epoch 19: Benign Accuracy = 22.64%, Adversarial Accuracy = 61.37%\n",
            "Benign Loss = 2.6680, Adversarial Loss = 1.1043\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "Batch 0: Loss = 1.2029, Accuracy = 54.69%\n",
            "Batch 10: Loss = 0.9908, Accuracy = 60.51%\n",
            "Batch 20: Loss = 1.0148, Accuracy = 60.27%\n",
            "Batch 30: Loss = 1.0699, Accuracy = 60.48%\n",
            "Batch 40: Loss = 1.0287, Accuracy = 60.84%\n",
            "Batch 50: Loss = 1.0894, Accuracy = 60.71%\n",
            "Batch 60: Loss = 1.0708, Accuracy = 60.69%\n",
            "Batch 70: Loss = 1.1384, Accuracy = 60.45%\n",
            "Batch 80: Loss = 1.2583, Accuracy = 60.43%\n",
            "Batch 90: Loss = 1.2445, Accuracy = 60.42%\n",
            "Batch 100: Loss = 0.9735, Accuracy = 60.56%\n",
            "Batch 110: Loss = 1.0931, Accuracy = 60.43%\n",
            "Batch 120: Loss = 1.0524, Accuracy = 60.34%\n",
            "Batch 130: Loss = 1.0963, Accuracy = 60.18%\n",
            "Batch 140: Loss = 1.0863, Accuracy = 60.21%\n",
            "Batch 150: Loss = 1.0922, Accuracy = 60.30%\n",
            "Batch 160: Loss = 1.1769, Accuracy = 60.26%\n",
            "Batch 170: Loss = 1.1254, Accuracy = 60.26%\n",
            "Batch 180: Loss = 1.2066, Accuracy = 60.30%\n",
            "Batch 190: Loss = 1.2627, Accuracy = 60.22%\n",
            "Batch 200: Loss = 1.1397, Accuracy = 60.20%\n",
            "Batch 210: Loss = 1.0610, Accuracy = 60.38%\n",
            "Batch 220: Loss = 1.1940, Accuracy = 60.35%\n",
            "Batch 230: Loss = 0.9856, Accuracy = 60.43%\n",
            "Batch 240: Loss = 1.2714, Accuracy = 60.37%\n",
            "Batch 250: Loss = 0.9925, Accuracy = 60.35%\n",
            "Batch 260: Loss = 1.0480, Accuracy = 60.31%\n",
            "Batch 270: Loss = 1.0269, Accuracy = 60.30%\n",
            "Batch 280: Loss = 1.2209, Accuracy = 60.36%\n",
            "Batch 290: Loss = 1.3395, Accuracy = 60.34%\n",
            "Batch 300: Loss = 0.8353, Accuracy = 60.31%\n",
            "Batch 310: Loss = 1.1400, Accuracy = 60.37%\n",
            "Batch 320: Loss = 1.2306, Accuracy = 60.30%\n",
            "Batch 330: Loss = 1.2587, Accuracy = 60.21%\n",
            "Batch 340: Loss = 0.9839, Accuracy = 60.28%\n",
            "Batch 350: Loss = 1.2657, Accuracy = 60.29%\n",
            "Batch 360: Loss = 1.2454, Accuracy = 60.27%\n",
            "Batch 370: Loss = 1.1498, Accuracy = 60.28%\n",
            "Batch 380: Loss = 1.1144, Accuracy = 60.36%\n",
            "Batch 390: Loss = 1.1936, Accuracy = 60.33%\n",
            "Epoch 20: Total Loss = 1.1203, Total Accuracy = 60.33%\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "Batch 0: Benign Loss = 1.1972, Adversarial Loss = 1.1972\n",
            "Batch 10: Benign Loss = 1.1564, Adversarial Loss = 1.1564\n",
            "Batch 20: Benign Loss = 1.1154, Adversarial Loss = 1.1154\n",
            "Batch 30: Benign Loss = 1.0690, Adversarial Loss = 1.0690\n",
            "Batch 40: Benign Loss = 1.0051, Adversarial Loss = 1.0051\n",
            "Batch 50: Benign Loss = 1.1130, Adversarial Loss = 1.1130\n",
            "Batch 60: Benign Loss = 1.1464, Adversarial Loss = 1.1464\n",
            "Batch 70: Benign Loss = 1.0846, Adversarial Loss = 1.0846\n",
            "Batch 80: Benign Loss = 1.0218, Adversarial Loss = 1.0218\n",
            "Batch 90: Benign Loss = 1.0970, Adversarial Loss = 1.0970\n",
            "Epoch 20: Benign Accuracy = 24.69%, Adversarial Accuracy = 61.00%\n",
            "Benign Loss = 2.7285, Adversarial Loss = 1.1234\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "Batch 0: Loss = 1.1099, Accuracy = 60.94%\n",
            "Batch 10: Loss = 1.2231, Accuracy = 61.01%\n",
            "Batch 20: Loss = 1.0142, Accuracy = 60.90%\n",
            "Batch 30: Loss = 1.0662, Accuracy = 61.16%\n",
            "Batch 40: Loss = 1.0192, Accuracy = 61.36%\n",
            "Batch 50: Loss = 1.2422, Accuracy = 61.04%\n",
            "Batch 60: Loss = 1.1041, Accuracy = 61.08%\n",
            "Batch 70: Loss = 1.1617, Accuracy = 61.12%\n",
            "Batch 80: Loss = 0.9755, Accuracy = 61.13%\n",
            "Batch 90: Loss = 1.0774, Accuracy = 61.10%\n",
            "Batch 100: Loss = 1.1761, Accuracy = 60.99%\n",
            "Batch 110: Loss = 1.1622, Accuracy = 61.06%\n",
            "Batch 120: Loss = 0.9424, Accuracy = 61.00%\n",
            "Batch 130: Loss = 1.1006, Accuracy = 60.93%\n",
            "Batch 140: Loss = 1.2682, Accuracy = 60.68%\n",
            "Batch 150: Loss = 1.1335, Accuracy = 60.55%\n",
            "Batch 160: Loss = 1.1878, Accuracy = 60.44%\n",
            "Batch 170: Loss = 1.0181, Accuracy = 60.42%\n",
            "Batch 180: Loss = 1.0696, Accuracy = 60.51%\n",
            "Batch 190: Loss = 1.2298, Accuracy = 60.54%\n",
            "Batch 200: Loss = 1.0077, Accuracy = 60.61%\n",
            "Batch 210: Loss = 1.0827, Accuracy = 60.55%\n",
            "Batch 220: Loss = 0.9777, Accuracy = 60.70%\n",
            "Batch 230: Loss = 1.1110, Accuracy = 60.67%\n",
            "Batch 240: Loss = 1.5251, Accuracy = 60.54%\n",
            "Batch 250: Loss = 1.0846, Accuracy = 60.45%\n",
            "Batch 260: Loss = 1.1751, Accuracy = 60.50%\n",
            "Batch 270: Loss = 1.0800, Accuracy = 60.41%\n",
            "Batch 280: Loss = 1.0623, Accuracy = 60.41%\n",
            "Batch 290: Loss = 1.1200, Accuracy = 60.34%\n",
            "Batch 300: Loss = 1.2237, Accuracy = 60.29%\n",
            "Batch 310: Loss = 1.2117, Accuracy = 60.38%\n",
            "Batch 320: Loss = 1.2522, Accuracy = 60.32%\n",
            "Batch 330: Loss = 1.2894, Accuracy = 60.28%\n",
            "Batch 340: Loss = 1.1086, Accuracy = 60.27%\n",
            "Batch 350: Loss = 1.0918, Accuracy = 60.28%\n",
            "Batch 360: Loss = 1.1734, Accuracy = 60.32%\n",
            "Batch 370: Loss = 1.1338, Accuracy = 60.36%\n",
            "Batch 380: Loss = 1.1175, Accuracy = 60.37%\n",
            "Batch 390: Loss = 1.1836, Accuracy = 60.40%\n",
            "Epoch 21: Total Loss = 1.1173, Total Accuracy = 60.40%\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "Batch 0: Benign Loss = 1.1629, Adversarial Loss = 1.1629\n",
            "Batch 10: Benign Loss = 1.1115, Adversarial Loss = 1.1115\n",
            "Batch 20: Benign Loss = 1.1718, Adversarial Loss = 1.1718\n",
            "Batch 30: Benign Loss = 1.0810, Adversarial Loss = 1.0810\n",
            "Batch 40: Benign Loss = 1.0206, Adversarial Loss = 1.0206\n",
            "Batch 50: Benign Loss = 1.0740, Adversarial Loss = 1.0740\n",
            "Batch 60: Benign Loss = 1.2078, Adversarial Loss = 1.2078\n",
            "Batch 70: Benign Loss = 1.1522, Adversarial Loss = 1.1522\n",
            "Batch 80: Benign Loss = 1.0248, Adversarial Loss = 1.0248\n",
            "Batch 90: Benign Loss = 1.0818, Adversarial Loss = 1.0818\n",
            "Epoch 21: Benign Accuracy = 23.33%, Adversarial Accuracy = 60.81%\n",
            "Benign Loss = 2.9665, Adversarial Loss = 1.1270\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "Batch 0: Loss = 1.3640, Accuracy = 50.00%\n",
            "Batch 10: Loss = 1.0219, Accuracy = 62.29%\n",
            "Batch 20: Loss = 1.0993, Accuracy = 62.17%\n",
            "Batch 30: Loss = 1.0477, Accuracy = 62.15%\n",
            "Batch 40: Loss = 0.9624, Accuracy = 62.46%\n",
            "Batch 50: Loss = 1.1773, Accuracy = 62.19%\n",
            "Batch 60: Loss = 1.1237, Accuracy = 61.97%\n",
            "Batch 70: Loss = 1.0289, Accuracy = 61.75%\n",
            "Batch 80: Loss = 1.1044, Accuracy = 61.59%\n",
            "Batch 90: Loss = 1.2561, Accuracy = 61.26%\n",
            "Batch 100: Loss = 1.1385, Accuracy = 61.39%\n",
            "Batch 110: Loss = 0.9319, Accuracy = 61.32%\n",
            "Batch 120: Loss = 1.0137, Accuracy = 61.22%\n",
            "Batch 130: Loss = 1.1035, Accuracy = 61.11%\n",
            "Batch 140: Loss = 1.1022, Accuracy = 61.11%\n",
            "Batch 150: Loss = 1.0701, Accuracy = 61.05%\n",
            "Batch 160: Loss = 0.9529, Accuracy = 61.24%\n",
            "Batch 170: Loss = 1.1189, Accuracy = 61.16%\n",
            "Batch 180: Loss = 1.2313, Accuracy = 61.23%\n",
            "Batch 190: Loss = 1.0810, Accuracy = 61.11%\n",
            "Batch 200: Loss = 1.1154, Accuracy = 61.13%\n",
            "Batch 210: Loss = 1.0909, Accuracy = 61.13%\n",
            "Batch 220: Loss = 1.2917, Accuracy = 61.04%\n",
            "Batch 230: Loss = 1.1988, Accuracy = 61.03%\n",
            "Batch 240: Loss = 1.1881, Accuracy = 60.97%\n",
            "Batch 250: Loss = 1.1632, Accuracy = 61.03%\n",
            "Batch 260: Loss = 1.1740, Accuracy = 60.99%\n",
            "Batch 270: Loss = 1.2615, Accuracy = 60.95%\n",
            "Batch 280: Loss = 1.1130, Accuracy = 60.88%\n",
            "Batch 290: Loss = 1.0656, Accuracy = 60.87%\n",
            "Batch 300: Loss = 1.2845, Accuracy = 60.84%\n",
            "Batch 310: Loss = 1.0778, Accuracy = 60.87%\n",
            "Batch 320: Loss = 1.1070, Accuracy = 60.80%\n",
            "Batch 330: Loss = 1.1220, Accuracy = 60.76%\n",
            "Batch 340: Loss = 1.3745, Accuracy = 60.72%\n",
            "Batch 350: Loss = 1.2409, Accuracy = 60.69%\n",
            "Batch 360: Loss = 1.1448, Accuracy = 60.70%\n",
            "Batch 370: Loss = 1.1184, Accuracy = 60.73%\n",
            "Batch 380: Loss = 1.1869, Accuracy = 60.74%\n",
            "Batch 390: Loss = 1.0406, Accuracy = 60.73%\n",
            "Epoch 22: Total Loss = 1.1167, Total Accuracy = 60.73%\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "Batch 0: Benign Loss = 1.1795, Adversarial Loss = 1.1795\n",
            "Batch 10: Benign Loss = 1.0339, Adversarial Loss = 1.0339\n",
            "Batch 20: Benign Loss = 1.1314, Adversarial Loss = 1.1314\n",
            "Batch 30: Benign Loss = 1.0955, Adversarial Loss = 1.0955\n",
            "Batch 40: Benign Loss = 1.0121, Adversarial Loss = 1.0121\n",
            "Batch 50: Benign Loss = 1.1258, Adversarial Loss = 1.1258\n",
            "Batch 60: Benign Loss = 1.1321, Adversarial Loss = 1.1321\n",
            "Batch 70: Benign Loss = 1.1519, Adversarial Loss = 1.1519\n",
            "Batch 80: Benign Loss = 1.0377, Adversarial Loss = 1.0377\n",
            "Batch 90: Benign Loss = 1.0904, Adversarial Loss = 1.0904\n",
            "Epoch 22: Benign Accuracy = 21.46%, Adversarial Accuracy = 60.90%\n",
            "Benign Loss = 3.0247, Adversarial Loss = 1.1191\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "Batch 0: Loss = 0.8966, Accuracy = 71.09%\n",
            "Batch 10: Loss = 1.1170, Accuracy = 59.94%\n",
            "Batch 20: Loss = 1.0443, Accuracy = 60.79%\n",
            "Batch 30: Loss = 1.1421, Accuracy = 60.79%\n",
            "Batch 40: Loss = 1.1232, Accuracy = 60.56%\n",
            "Batch 50: Loss = 1.1813, Accuracy = 60.68%\n",
            "Batch 60: Loss = 1.0106, Accuracy = 60.58%\n",
            "Batch 70: Loss = 1.0817, Accuracy = 60.72%\n",
            "Batch 80: Loss = 1.2007, Accuracy = 60.62%\n",
            "Batch 90: Loss = 1.1187, Accuracy = 60.55%\n",
            "Batch 100: Loss = 1.0868, Accuracy = 60.79%\n",
            "Batch 110: Loss = 1.0468, Accuracy = 60.94%\n",
            "Batch 120: Loss = 1.1544, Accuracy = 60.89%\n",
            "Batch 130: Loss = 1.0804, Accuracy = 60.81%\n",
            "Batch 140: Loss = 1.1507, Accuracy = 60.74%\n",
            "Batch 150: Loss = 1.0410, Accuracy = 60.81%\n",
            "Batch 160: Loss = 1.2513, Accuracy = 60.65%\n",
            "Batch 170: Loss = 1.1348, Accuracy = 60.61%\n",
            "Batch 180: Loss = 1.1562, Accuracy = 60.64%\n",
            "Batch 190: Loss = 1.1969, Accuracy = 60.53%\n",
            "Batch 200: Loss = 1.1587, Accuracy = 60.65%\n",
            "Batch 210: Loss = 1.1289, Accuracy = 60.68%\n",
            "Batch 220: Loss = 1.2822, Accuracy = 60.64%\n",
            "Batch 230: Loss = 1.1409, Accuracy = 60.65%\n",
            "Batch 240: Loss = 1.0285, Accuracy = 60.68%\n",
            "Batch 250: Loss = 0.9589, Accuracy = 60.71%\n",
            "Batch 260: Loss = 1.2068, Accuracy = 60.73%\n",
            "Batch 270: Loss = 1.2163, Accuracy = 60.73%\n",
            "Batch 280: Loss = 1.1426, Accuracy = 60.70%\n",
            "Batch 290: Loss = 0.9794, Accuracy = 60.79%\n",
            "Batch 300: Loss = 1.0386, Accuracy = 60.81%\n",
            "Batch 310: Loss = 1.2589, Accuracy = 60.86%\n",
            "Batch 320: Loss = 1.2361, Accuracy = 60.80%\n",
            "Batch 330: Loss = 1.2294, Accuracy = 60.86%\n",
            "Batch 340: Loss = 1.1632, Accuracy = 60.85%\n",
            "Batch 350: Loss = 1.1179, Accuracy = 60.86%\n",
            "Batch 360: Loss = 0.9685, Accuracy = 60.89%\n",
            "Batch 370: Loss = 1.2041, Accuracy = 60.87%\n",
            "Batch 380: Loss = 0.9813, Accuracy = 60.91%\n",
            "Batch 390: Loss = 1.1041, Accuracy = 60.93%\n",
            "Epoch 23: Total Loss = 1.1116, Total Accuracy = 60.93%\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "Batch 0: Benign Loss = 1.1809, Adversarial Loss = 1.1809\n",
            "Batch 10: Benign Loss = 1.0457, Adversarial Loss = 1.0457\n",
            "Batch 20: Benign Loss = 1.1457, Adversarial Loss = 1.1457\n",
            "Batch 30: Benign Loss = 1.0706, Adversarial Loss = 1.0706\n",
            "Batch 40: Benign Loss = 0.9845, Adversarial Loss = 0.9845\n",
            "Batch 50: Benign Loss = 1.0923, Adversarial Loss = 1.0923\n",
            "Batch 60: Benign Loss = 1.1120, Adversarial Loss = 1.1120\n",
            "Batch 70: Benign Loss = 1.1395, Adversarial Loss = 1.1395\n",
            "Batch 80: Benign Loss = 1.0601, Adversarial Loss = 1.0601\n",
            "Batch 90: Benign Loss = 1.0477, Adversarial Loss = 1.0477\n",
            "Epoch 23: Benign Accuracy = 23.12%, Adversarial Accuracy = 61.76%\n",
            "Benign Loss = 2.5092, Adversarial Loss = 1.1064\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "Batch 0: Loss = 1.2191, Accuracy = 56.25%\n",
            "Batch 10: Loss = 1.2386, Accuracy = 59.23%\n",
            "Batch 20: Loss = 1.2396, Accuracy = 59.23%\n",
            "Batch 30: Loss = 1.1205, Accuracy = 59.43%\n",
            "Batch 40: Loss = 1.0441, Accuracy = 59.79%\n",
            "Batch 50: Loss = 1.2636, Accuracy = 59.79%\n",
            "Batch 60: Loss = 1.0691, Accuracy = 59.75%\n",
            "Batch 70: Loss = 1.2378, Accuracy = 59.88%\n",
            "Batch 80: Loss = 1.2436, Accuracy = 60.24%\n",
            "Batch 90: Loss = 1.2761, Accuracy = 60.10%\n",
            "Batch 100: Loss = 1.1227, Accuracy = 60.16%\n",
            "Batch 110: Loss = 1.2288, Accuracy = 60.36%\n",
            "Batch 120: Loss = 1.0460, Accuracy = 60.29%\n",
            "Batch 130: Loss = 1.1425, Accuracy = 60.25%\n",
            "Batch 140: Loss = 1.1621, Accuracy = 60.25%\n",
            "Batch 150: Loss = 1.1310, Accuracy = 60.17%\n",
            "Batch 160: Loss = 1.0755, Accuracy = 60.11%\n",
            "Batch 170: Loss = 1.0537, Accuracy = 60.14%\n",
            "Batch 180: Loss = 1.1853, Accuracy = 60.00%\n",
            "Batch 190: Loss = 1.2658, Accuracy = 59.97%\n",
            "Batch 200: Loss = 1.0764, Accuracy = 60.13%\n",
            "Batch 210: Loss = 1.0706, Accuracy = 60.06%\n",
            "Batch 220: Loss = 0.9580, Accuracy = 60.10%\n",
            "Batch 230: Loss = 0.9988, Accuracy = 60.20%\n",
            "Batch 240: Loss = 1.0995, Accuracy = 60.27%\n",
            "Batch 250: Loss = 1.1944, Accuracy = 60.31%\n",
            "Batch 260: Loss = 1.2174, Accuracy = 60.25%\n",
            "Batch 270: Loss = 1.1592, Accuracy = 60.25%\n",
            "Batch 280: Loss = 0.9917, Accuracy = 60.30%\n",
            "Batch 290: Loss = 1.0216, Accuracy = 60.29%\n",
            "Batch 300: Loss = 1.1348, Accuracy = 60.31%\n",
            "Batch 310: Loss = 1.1632, Accuracy = 60.30%\n",
            "Batch 320: Loss = 1.3294, Accuracy = 60.31%\n",
            "Batch 330: Loss = 1.0968, Accuracy = 60.30%\n",
            "Batch 340: Loss = 1.2014, Accuracy = 60.25%\n",
            "Batch 350: Loss = 1.0478, Accuracy = 60.25%\n",
            "Batch 360: Loss = 0.9351, Accuracy = 60.27%\n",
            "Batch 370: Loss = 1.1070, Accuracy = 60.34%\n",
            "Batch 380: Loss = 0.9931, Accuracy = 60.34%\n",
            "Batch 390: Loss = 0.9222, Accuracy = 60.39%\n",
            "Epoch 24: Total Loss = 1.1151, Total Accuracy = 60.39%\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "Batch 0: Benign Loss = 1.1840, Adversarial Loss = 1.1840\n",
            "Batch 10: Benign Loss = 1.0471, Adversarial Loss = 1.0471\n",
            "Batch 20: Benign Loss = 1.1086, Adversarial Loss = 1.1086\n",
            "Batch 30: Benign Loss = 1.0591, Adversarial Loss = 1.0591\n",
            "Batch 40: Benign Loss = 0.9820, Adversarial Loss = 0.9820\n",
            "Batch 50: Benign Loss = 1.1254, Adversarial Loss = 1.1254\n",
            "Batch 60: Benign Loss = 1.1208, Adversarial Loss = 1.1208\n",
            "Batch 70: Benign Loss = 1.1022, Adversarial Loss = 1.1022\n",
            "Batch 80: Benign Loss = 1.0563, Adversarial Loss = 1.0563\n",
            "Batch 90: Benign Loss = 1.0649, Adversarial Loss = 1.0649\n",
            "Epoch 24: Benign Accuracy = 26.81%, Adversarial Accuracy = 61.35%\n",
            "Benign Loss = 2.3764, Adversarial Loss = 1.1008\n",
            "Training complete in 6659.55 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_adv_accuracy</td><td>▁▁▂▄▄▃▄▅▇▆▅▆▆▃▇▆▅▆▆▇▆▆▆█▇</td></tr><tr><td>test_adv_loss</td><td>█▇▆▅▅▅▅▃▂▂▃▃▂▅▃▃▃▃▄▁▃▃▃▂▁</td></tr><tr><td>test_benign_accuracy</td><td>▁▃▄▇▆▇▅▂▄▄▃▃▂▅▄▄▄▃▄▃▅▃▁▃█</td></tr><tr><td>test_benign_loss</td><td>▃▄▄▁▂▂▄▅▃▃█▅▄▃█▅▃▅▂▄▅▇▇▃▂</td></tr><tr><td>train_adv_accuracy</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_adv_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>test_adv_accuracy</td><td>61.35</td></tr><tr><td>test_adv_loss</td><td>1.10083</td></tr><tr><td>test_benign_accuracy</td><td>26.81</td></tr><tr><td>test_benign_loss</td><td>2.37642</td></tr><tr><td>train_adv_accuracy</td><td>1.11513</td></tr><tr><td>train_adv_loss</td><td>0.32405</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-finetuned-training</strong> at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/rtdh0yd1' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training/runs/rtdh0yd1</a><br/> View project at: <a href='https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training' target=\"_blank\">https://wandb.ai/anakhag07-massachusetts-institute-of-technology/layer-freezing-adversarial-training</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241210_014427-rtdh0yd1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(resnet18_finetuned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYqPrPMZ8VBa",
        "outputId": "c8f41e89-16a6-4201-d935-a1c48e03f99a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benign Accuracy: 26.00%\n",
            "Adversarial Accuracy: 26.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.999999046325684, 25.999999046325684)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}